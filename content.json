{"meta":{"title":"厽乂彐","subtitle":"记录生活中的点点滴滴","description":"直到这一刻微笑着说话为止，我至少留下了一公升眼泪","author":"张磊","url":"http://laxe.top","root":"/"},"pages":[],"posts":[{"title":"xtrabackup备份mysql","slug":"使用xtrabackup进行备份","date":"2019-12-26T00:27:30.314Z","updated":"2019-12-26T00:34:38.211Z","comments":true,"path":"2019/12/26/使用xtrabackup进行备份/","link":"","permalink":"http://laxe.top/2019/12/26/使用xtrabackup进行备份/","excerpt":"使用xtrabackup备份mysql简介（Percona XtraBackup ）简称PXB## Xtrabackup是由percona开源的免费数据库热备份软件，它能对Innodb数据库和Xtradb存储引擎的数据库非阻塞地备份。（对于Myisam的备份同样需要加表锁），mysqldump备份方式是采用的逻辑备份，其最大的缺陷是备份和恢复速度较慢，如果数据库大于50G，mysqldump备份就不太适合。","text":"使用xtrabackup备份mysql简介（Percona XtraBackup ）简称PXB## Xtrabackup是由percona开源的免费数据库热备份软件，它能对Innodb数据库和Xtradb存储引擎的数据库非阻塞地备份。（对于Myisam的备份同样需要加表锁），mysqldump备份方式是采用的逻辑备份，其最大的缺陷是备份和恢复速度较慢，如果数据库大于50G，mysqldump备份就不太适合。 优点## 备份速度快，物理备份可靠 备份过程不会打断正在执行的事务（无需锁表） 能够基于压缩等功能节约磁盘空间和流量 自动备份校验 还原速度快 可以流传将备份传输到另一台机器上 在不增加服务器负载的情况下备份数据 原理## ​ 备份开始的时候，首先会开启一个后台检测进程，实时检测mysql redo到的变化，一旦发现有新的日志写入，立刻将日志记入后台日志文件xtrabackup_log中，之后赋值innodb的数据文件，系统表空间文件ibdatax，复制后，将上锁（读锁），flush tables with read lock，让后复制.frm MYI MYD等文件，最后执行 unlock tables（释放锁），最终停止xtrabackup_log。 ​ 扩展## ​ 在innodb内部会维护一个redo日志文件，我们也可以叫做事务日志文 件，事务日志会存储每一个Innodb表数据的记录修改。当Innodb启动时，Innodb会检查数据文件和事务日志。并执行两个步骤：它应用（前滚）已经提交的事务日志到数据文件，并将修改过但没有提交的数据进行回滚操作。 ​ xtrabackup在启动时会记住log sequence number（LSN），并且复制所有数据文件，复制过程需要一些时间，所以这期间如果数据文件有改动，那么将会使数据库处于一个不同的时间点。这时，Xtrabackup会运行一个后台进程，用于监测事务日志，并从事务日志复制最新的修改。xtrabackup必须持续的做这个操作，因为事务日志是会轮转重复的写入，并且事务日志可以被重用。所以xtrabackup自启动开始，就不停的将事务日志中每个数据文件的修改都记录下来。这就是xtrabackup的备份过程。 ​ 接下来是准备（prepare）过程。在这个过程中，xtrabackup使用之前复制的事务日志。对各个数据文件执行灾难恢复（就像mysql刚启动时要做的一样）。当这个过程结束后，数据库就可以做恢复还原了。 ​ 整个过程就是-备份-》准备。先将文件全部复制过来，在根据事务日志对部分操作进行回滚。 ​ 程序innobbackupex可以允许我们备份Myisam表和文件从而增加了便捷和功能。 ​ innobbackupex会启动xtrabackup，直到xtrabackup复制数据文件后，然后执行FLUSH TABLES WITH READ LOCK 来阻止新的写入刷新到磁盘上。之后复制Myisam数据文件。最后UNLOCK TABLES （释放锁）。 ​ 备份Myisam和Innodb表最终会处于一致，在准备（prepare）过程结束后，Innodb表数据已经前滚到整个备份结束点，而不是回滚到xtrabackup感刚开始的点。这个时间点与执行FLUSH TABLES WITH READ LOCK的时间点相同，所以Myisam表数据与Innodb表数据是同步的。 xtrabackup增量备份 原理 ​ 首先是建立在完全备份的基础上，记录下此时的检查点LSN ​ 在进行增量备份时，比较表空间中每个页的LSN是否大于上次备份的LSN，若是则备份该页并记录当前检查点的LSN。 优点： 数据库太大没有足够的空间全量备份，增量备份能有效节省空间，并且效率高 支持热备份，备份过程不锁表（针对Innodb而言），不阻塞数据库读写。 每日备份只产生少量数据，也可采用远程备份，节省本地空间 备份恢复基于文件操作，降低直接对数据库操作风险 备份效率更高，恢复效率更高。 工具集软件包安装完后一共有4个可执行文件，如下： 123456usr├── bin│ ├── innobackupex│ ├── xbcrypt #用来加密或解密备份的数据│ ├── xbstream #用来解压或压缩xbstream格式的文件│ └── xtrabackup 其中最主要的是 innobackupex 和 xtrabackup，前者是一个 perl 脚本，后者是 C/C++ 编译的二进制。 xtrabackup 是用来备份 InnoDB 表的，不能备份非 InnoDB 表，和 mysqld server 没有交互；innobackupex 脚本用来备份非 InnoDB 表，同时会调用 xtrabackup 命令来备份 InnoDB 表，还会和 mysqld server 发送命令进行交互，如加读锁（FTWRL）、获取位点（SHOW SLAVE STATUS）等。简单来说，innobackupex 在 xtrabackup 之上做了一层封装。 一般情况下，我们是希望能备份 MyISAM 表的，虽然我们可能自己不用 MyISAM 表，但是 mysql 库下的系统表是 MyISAM 的，因此备份基本都通过 innobackupex 命令进行；另外一个原因是我们可能需要保存位点信息。 另外2个工具相对小众些，xbcrypt 是加解密用的；xbstream 类似于tar，是 Percona 自己实现的一种支持并发写的流文件格式。两都在备份和解压时都会用到（如果备份用了加密和并发）。 本文的介绍的主角是 innobackupex 和 xtrabackup。 下载## 安装percona仓库 1yum -y install http://www.percona.com/downloads/percona-release/redhat/0.1-4/percona-release-0.1-4.noarch.rpm 安装xtrabackup 1yum install percona-xtrabackup -y 创建备份用户及设置权限（也可以直接使用root用户） 123CREATE USER ‘用户名’@'localhost' IDENTIFIED BY '密码';#创建GRANT RELOAD,LOCK TABLES,PROCESS,REPLICATION CLIENT ON *.* TO '用户名'@'localhost';#设置权限FLUSH PRIVILEGES;#刷新权限 配置xtrabackup（可配置也可以已参数的形式写入） 1234567vim /root/.my.cnf[xtrabackup]user=创建的用户名password=密码 创建备份使用的文件夹 1mkdir /data/backup/mysql 基于xtrabackup的备份和恢复## xtrabackup 只支持innodb引擎和xtradb引擎 语法： –backup 表示该操作代表备份操作 –target-dir 指定备份文件的路径 –user 备份的用户 （设定配置文件后，无需指定） –password 用户密码（同上） –socket 指定socket启动文件路径（不添加使用默认路径） –incremental-basedir 表示在某个全量备份的基础上进行增备 全量备份 123456789101112131415161718192021[root@ax mysql]# xtrabackup --backup --target-dir=/data/backup/mysql#以下是返回的结果191221 13:49:02 version_check Connecting to MySQL server with DSN 'dbi:mysql:;mysql_read_default_group=xtrabackup' as 'backuper' (using password: YES).191221 13:49:02 version_check Connected to MySQL server191221 13:49:02 version_check Executing a version check against the server...191221 13:49:02 version_check Done.191221 13:49:02 Connecting to MySQL server host: localhost, user: backuper, password: set, port: not set, socket: not setUsing server version 5.5.64-MariaDBxtrabackup version 2.3.10 based on MySQL server 5.6.24 Linux (x86_64) (revision id: bd0d4403f36)xtrabackup: uses posix_fadvise().xtrabackup: cd to /var/lib/mysqlxtrabackup: open files limit requested 0, set to 65535xtrabackup: using the following InnoDB configuration:#省略.....MySQL binlog position: filename 'mysql-bin.000001', position '245'191221 13:49:03 [00] Writing backup-my.cnf191221 13:49:03 [00] ...done191221 13:49:03 [00] Writing xtrabackup_info191221 13:49:03 [00] ...donextrabackup: Transaction log of lsn (8622624) to (8622624) was copied.191221 13:49:04 completed OK!#代表成功全量备份 在全量备份的基础上进行增量备份 123456789101112131415161718192021222324252627#xtrabackup --backup --target-dir=/data/mysql/增量备份文件夹的名字（自定义）--incremental-basedir=/全量备份文件路径[root@ax mysql]# xtrabackup --backup --target-dir=/data/backup/mysql/mysql_increment1 --incremental-basedir=/data/backup/mysql191221 14:00:43 version_check Connecting to MySQL server with DSN 'dbi:mysql:;mysql_read_default_group=xtrabackup' as 'backuper' (using password: YES).191221 14:00:43 version_check Connected to MySQL server191221 14:00:43 version_check Executing a version check against the server...191221 14:00:43 version_check Done.191221 14:00:43 Connecting to MySQL server host: localhost, user: backuper, password: set, port: not set, socket: not setUsing server version 5.5.64-MariaDBxtrabackup version 2.3.10 based on MySQL server 5.6.24 Linux (x86_64) (revision id: bd0d4403f36)incremental backup from 8622624 is enabled.xtrabackup: uses posix_fadvise().xtrabackup: cd to /var/lib/mysqlxtrabackup: open files limit requested 0, set to 65535#省略....xtrabackup: Stopping log copying thread..191221 14:00:45 &gt;&gt; log scanned up to (8622624)191221 14:00:45 Executing UNLOCK TABLES191221 14:00:45 All tables unlocked191221 14:00:45 Backup created in directory '/data/backup/mysql/mysql_increment1/'MySQL binlog position: filename 'mysql-bin.000001', position '245'191221 14:00:45 [00] Writing backup-my.cnf191221 14:00:45 [00] ...done191221 14:00:45 [00] Writing xtrabackup_info191221 14:00:45 [00] ...donextrabackup: Transaction log of lsn (8622624) to (8622624) was copied.191221 14:00:45 completed OK!#代表增量备份成功 在增量备份的基础上继续增量备份 123456789101112131415161718192021#在第一次增量备份后，以后的每一次增量备份都是以上一次增量备份为基准#xtrabackup --backup --target-dir=增量备份文件路径 --incremental-basedir=上次增量备份的文件位置[root@ax ~]# xtrabackup --backup --target-dir=/data/backup/mysql_increment2 --incremental-basedir=/data/backup/mysql/mysql_increment1191221 18:39:28 version_check Connecting to MySQL server with DSN 'dbi:mysql:;mysql_read_default_group=xtrabackup' as 'backuper' (using password: YES).191221 18:39:28 version_check Connected to MySQL server191221 18:39:28 version_check Executing a version check against the server...191221 18:39:28 version_check Done.191221 18:39:28 Connecting to MySQL server host: localhost, user: backuper, password: set, port: not set, socket: not setUsing server version 5.5.64-MariaDBxtrabackup version 2.3.10 based on MySQL server 5.6.24 #省略...191221 18:39:32 Executing UNLOCK TABLES191221 18:39:32 All tables unlocked191221 18:39:32 Backup created in directory '/data/backup/mysql_increment2/'MySQL binlog position: filename 'mysql-bin.000001', position '245'191221 18:39:32 [00] Writing backup-my.cnf191221 18:39:32 [00] ...done191221 18:39:32 [00] Writing xtrabackup_info191221 18:39:32 [00] ...donextrabackup: Transaction log of lsn (8622624) to (8622624) was copied.191221 18:39:32 completed OK!#代表成功 使用xtrabackup恢复## 语法： xtrabackup –prepare –apply-log-only –target-dir=全量备份文件路径 –prepare 表示还原 –apply-log-only 表示不回滚事务，因为后面有基于全备的增量备份，所以不需要回滚，如果没有增量备份则可以不添加。 将第一次增量备份加载至全备中（增量备份多每次都要以上一次加载的备份文件为基准，命令相同，只需修改增量备份文件的路径即可。） 在加载最后一次的增量备份文件时，不需要添加–apply-log-only，因为增量备份都加载完成了，所以需要事务回滚。 123456789101112131415161718#xtrabackup --prepare --apply-log-only --target-dir=全量备份文件路径 --incremental-dir=增量备份文件路径[root@ax ~]# xtrabackup --prepare --apply-log-only --target-dir=/data/backup/mysql --incremental-dir=/data/backup/mysql_increment1xtrabackup version 2.3.10 based on MySQL server 5.6.24 Linux (x86_64) (revision id: bd0d4403f36)incremental backup from 8622624 is enabled.xtrabackup: cd to /data/backup/mysql/xtrabackup: This target seems to be already #省略...191221 18:56:43 [01] ...done191221 18:56:43 [01] Copying /data/backup/mysql_increment1/mysql/db.MYD to ./mysql/db.MYD191221 18:56:43 [01] ...done191221 18:56:43 [00] Copying /data/backup/mysql_increment1//xtrabackup_binlog_info to ./xtrabackup_binlog_info191221 18:56:43 [00] ...done191221 18:56:43 [00] Copying /data/backup/mysql_increment1//xtrabackup_info to ./xtrabackup_info191221 18:56:43 [00] ...done191221 18:56:43 completed OK!#代表成功#最后一加载增量备份到全量备份[root@ax ~]# xtrabackup --prepare --target-dir=/data/backup/mysql --incremental-dir=/data/backup/mysql_increment2#返回也上面最后一行的结果代表成功 恢复 停止mysql服务 清空mysql的数据目录 12345678MariaDB [(none)]&gt; show variables like &apos;datadir&apos;; #查询数据目录+---------------+-----------------+| Variable_name | Value |+---------------+-----------------+| datadir | /var/lib/mysql/ |+---------------+-----------------+1 row in set (0.00 sec)#cd到指定目录 rm -rf ./* 这是模拟数据库损坏 恢复 xtrabackup --copy-back --target-dir=/data/backup/mysql –copy-back 将备份的数据目录下 1234567[root@ax ~]# xtrabackup --copy-back --target-dir=/data/backup/mysqlxtrabackup version 2.3.10 based on MySQL server 5.6.24 Linux (x86_64) (revision id: bd0d4403f36)191221 19:23:55 [01] Copying ib_logfile0 to /var/lib/mysql/ib_logfile0191221 19:23:55 [01] ...done191221 19:23:55 [01] Copying ib_logfile1 to /var/lib/mysql/ib_logfile1191221 19:23:55 [01] ...done191221 19:23:55 [01] Copying ibdata1 to /var/ 恢复后的数据目录下的文件及文件夹，用户数属于root的,mysql用户是没有权限使用的，所以需要重新赋予权限 12345678910111213141516171819202122232425262728[root@ax mysql]# lltotal 36896drwx------ 2 root root 4096 Dec 21 19:23 exam-rw-r----- 1 root root 27262976 Dec 21 19:23 ibdata1-rw-r----- 1 root root 5242880 Dec 21 19:23 ib_logfile0-rw-r----- 1 root root 5242880 Dec 21 19:23 ib_logfile1drwx------ 2 root root 4096 Dec 21 19:23 mysqldrwx------ 2 root root 4096 Dec 21 19:23 nextclouddrwx------ 2 root root 4096 Dec 21 19:23 performance_schemadrwx------ 2 root root 4096 Dec 21 19:23 siyouyundrwx------ 2 root root 4096 Dec 21 19:23 text-rw-r----- 1 root root 23 Dec 21 19:23 xtrabackup_binlog_pos_innodb-rw-r----- 1 root root 548 Dec 21 19:23 xtrabackup_info#重新赋予权限，所属者和所属组改为mysql[root@ax mysql]# chown -R mysql:mysql ../mysql[root@ax mysql]# lltotal 36896drwx------ 2 mysql mysql 4096 Dec 21 19:23 exam-rw-r----- 1 mysql mysql 27262976 Dec 21 19:23 ibdata1-rw-r----- 1 mysql mysql 5242880 Dec 21 19:23 ib_logfile0-rw-r----- 1 mysql mysql 5242880 Dec 21 19:23 ib_logfile1drwx------ 2 mysql mysql 4096 Dec 21 19:23 mysqldrwx------ 2 mysql mysql 4096 Dec 21 19:23 nextclouddrwx------ 2 mysql mysql 4096 Dec 21 19:23 performance_schemadrwx------ 2 mysql mysql 4096 Dec 21 19:23 siyouyundrwx------ 2 mysql mysql 4096 Dec 21 19:23 text-rw-r----- 1 mysql mysql 23 Dec 21 19:23 xtrabackup_binlog_pos_innodb-rw-r----- 1 mysql mysql 548 Dec 21 19:23 xtrabackup_info 重新启动mysql服务查看 123456789101112131415161718192021222324252627[root@ax mysql]# systemctl restart mariadb[root@ax mysql]# mysql -uroot -pEnter password: Welcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 2Server version: 5.5.64-MariaDB MariaDB ServerCopyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.MariaDB [(none)]&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || exam || mysql || nextcloud || performance_schema || siyouyun || text |+--------------------+7 rows in set (0.00 sec)MariaDB [(none)]&gt; #恢复成功 单表/单库备份 123456单表：xtrabackup --backup --datadir=数据目录路径 --tables='库名.表名' --target-dir=备份文件路径--tables:单引号中填写databases.tables单库：trabackup --backup --databases=数据库名 --target-dir=备份文件路径 --databases:库名（database） 12345678[root@ax ~]# xtrabackup --backup --datadir=/var/lib/mysql --target-dir=/data/backup/mysql --tables='exam.a1';#还原也需要进行事务回滚[root@ax exam]# xtrabackup --prepare --target-dir=单表或单库备份文件#停止数据库#数据目录中的原表删除，复制备份文件中单表或单库文件到数据目录#重置所属用户和组到mysql#重启数据库#成功 ##使用innobackupex的备份与恢复 innobackupex封装了xtrabackup，支持Myisam的数据表 innobackupex完整备份后生成的几个重要文件： 记录当前最新的Log position xtrabackup_binlog_pos_innodb:innodb log position xtrabackup_checkpoints:存放备份的起始LSN（beginlsn），和结束的位置LSN（endlsn） 增量备份需要上次备份的endlsn innobackupex命令相当于冷备份，复制数据目录的索引，数据结构文件，为保证数据一致，需要短暂的锁表（时间的长短依赖于Myisam表的大小。） 参数解释（同样适用于xtrabackup） 1234567891011#--defaults-file：指定my.cnf参数文件的位置[此配置文件里必须指定datadir]#--apply-log：同xtrabackup的--prepare参数,一般情况下,在备份完成后，数据尚且不能用于恢复操作，因为备份的数据中可能会包含尚未提交的事务或已经提交但尚未同步至数据文件中的事务。因此，此时数据 文件仍处理不一致状态。--apply-log的作用是通过回滚未提交的事务及同步已经提交的事务至数据文件使数据文件处于一致性状态。#--copy-back：做数据恢复时将备份数据文件拷贝到MySQL服务器的datadir#--remote-host=HOSTNAME： 通过ssh将备份数据存储到进程服务器上#--stream=[tar]：备份文件输出格式, 该文件可在XtarBackup binary文件中获得. 在使用参数stream=tar备份的时候,你的xtrabackup_logfile可能会临时放在/tmp目录下,如果你备份的时候并发写入较大的话,xtrabackup_logfile可能会很大(5G+),很可能会撑满你的/tmp目录,可以通过参数--tmpdir指定目录来解决这个问题.#--tmpdir=DIRECTORY：当有指定--remote-host or --stream时, 事务日志临时存储的目录, 默认采用MySQL配置文件中所指定的临时目录tmpdir#--redo-only --apply-log：强制备份日志时只redo,跳过rollback,这在做增量备份时非常必要#--use-memory=*：该参数在prepare的时候使用,控制prepare时innodb实例使用的内存#--databases=LIST：列出需要备份的databases,如果没有指定该参数,所有包含MyISAM和InnoDB表的database都会被备份#--slave-info：备份从库, 加上--slave-info备份目录下会多生成一个xtrabackup_slave_info 文件, 这里会保存主日志文件以及偏移, 文件内容类似于:CHANGE MASTER TO MASTER_LOG_FILE='', MASTER_LOG_POS=0#--socket=SOCKET：指定mysql.sock所在位置，以便备份进程登录mysql. 全量备份 12345678[root@ax backup]# innobackupex --user=备份账户 --password=密码 备份文件存储路径191223 10:08:18 innobackupex: Starting the backup operationIMPORTANT: Please check that the backup run completes successfully. At the end of a successful backup run innobackupex prints \"completed OK!\".#省略...191223 10:08:20 completed OK!#代表成功 全量恢复 123456789101112131415#执行innobackupex --apply-log --use-memory=size（可加可不加） 备份文件路径 这一步是准备操作。apply-only在上面介绍过。[root@ax backup]# innobackupex --apply-only --use-memory=4G /data/backup/2019-12-23_10-08-18191223 10:16:02 innobackupex: Starting the backup operationIMPORTANT: Please check that the backup run completes successfully. At the end of a successful backup run innobackupex prints \"completed OK!\".#省略...191223 10:16:04 completed OK!#代表成功#接下来是恢复#关闭mysql服务,模拟数据库损坏，清空数据目录（不清空会报错）#执行 innobackupex --copy-back 备份文件路径#给予mysql数据目录下所有文件的操作权限#启动mysql 增量备份（所有的增量备份都是在全量备份的基础上进行的） 1234#执行 innobackupex --incremental 指定增量文件存储路径 --incremental-basedir=第一次是全量备份的文件路径/在增量的备份的基础上继续增量这里就需要填写上次增量备份文件的路径[root@ax backup]# innobackupex --incremental /data/backup/ --incremental-basedir=/data/backup/2019-12-23_11-25-13/xtrabackup: Transaction log of lsn (8626208) to (8626208) was copied.191223 11:34:20 completed OK!#代表成功 恢复：（将各个增量备份的数据文件合并到全量备份的目录下，最终是从全量备份的这个目录上进行恢复的） 12345678910#准备工作#innobackupex --apply-log --redo-only 全被文件路径#innobackupex --apply-log --redo-only 全备路径 --incremental-dir=第一次增备路径#innobackupex --apply-log --redo-only 全备文件路径 --incremental-dir=第二次增备路径 #多次增备执行多次#innobackupex --apply-log 全备路径 --incremental-dir=最后一次增备路径 最后一次不需要填加--redo-only参数#恢复#关闭mysql服务,模拟数据库损坏，清空数据目录（不清空会报错）#innobackupex --copy-back 全量备份路径 #给予mysql数据目录下所有文件的操作权限#启动mysql","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://laxe.top/tags/MySQL/"}]},{"title":"nginx负载均衡","slug":"负载均衡","date":"2019-12-26T00:27:23.465Z","updated":"2019-12-26T00:35:22.927Z","comments":true,"path":"2019/12/26/负载均衡/","link":"","permalink":"http://laxe.top/2019/12/26/负载均衡/","excerpt":"修改nginx.conf配置文件1234567891011121314151617181920212223242526272829303132333435user root;worker_processes 1;error_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; upstream mytest &#123; server 114.55.39.15; #负载均衡服务器群 server 47.98.237.5; &#125; include /etc/nginx/conf.d/*.conf;&#125;","text":"修改nginx.conf配置文件1234567891011121314151617181920212223242526272829303132333435user root;worker_processes 1;error_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; upstream mytest &#123; server 114.55.39.15; #负载均衡服务器群 server 47.98.237.5; &#125; include /etc/nginx/conf.d/*.conf;&#125; 假如有default.conf修改为： 123456789101112131415161718server &#123; listen 80; server_name localhost; access_log /root/myweb_access.log; error_log /root/myweb_error.log; client_max_body_size 75M; location / &#123; proxy_pass http://mytest; proxy_redirect default; root /root/public; index index.html; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950511、轮询（默认）每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。upstream backserver &#123; server 192.168.0.14; server 192.168.0.15;&#125;2、权重 weight指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。upstream backserver &#123; server 192.168.0.14 weight=3; server 192.168.0.15 weight=7;&#125;3、ip_hash（ IP绑定）上述方式存在一个问题就是说，在负载均衡系统中，假如用户在某台服务器上登录了，那么该用户第二次请求的时候，因为我们是负载均衡系统，每次请求都会重新定位到服务器集群中的某一个，那么已经登录某一个服务器的用户再重新定位到另一个服务器，其登录信息将会丢失，这样显然是不妥的。我们可以采用ip_hash指令解决这个问题，如果客户已经访问了某个服务器，当用户再次访问时，会将该请求通过哈希算法，自动定位到该服务器。每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。upstream backserver &#123; ip_hash; server 192.168.0.14:88; server 192.168.0.15:80;&#125;4、fair（第三方插件）按后端服务器的响应时间来分配请求，响应时间短的优先分配。upstream backserver &#123; server server1; server server2; fair;&#125;5、url_hash（第三方插件）按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。upstream backserver &#123; server squid1:3128; server squid2:3128; hash $request_uri; hash_method crc32;&#125;","categories":[],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://laxe.top/tags/nginx/"}]},{"title":"Redis主从复制","slug":"redis主从复制2","date":"2019-12-26T00:26:33.567Z","updated":"2019-12-26T00:33:17.519Z","comments":true,"path":"2019/12/26/redis主从复制2/","link":"","permalink":"http://laxe.top/2019/12/26/redis主从复制2/","excerpt":"Reids主从参考链接：Redis主从复制和哨兵 参考1Redis主从复制和哨兵 参考2Redis主从架构和主从从架构集群搭建详细步骤Redis主从复制原理Redis复制官方文档翻译 ​ 主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master/leader)，后者称为从节点(slave/follower)；数据的复制是单向的，只能由主节点到从节点。 ​ 默认情况下，每台Redis服务器都是主节点；且一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点。","text":"Reids主从参考链接：Redis主从复制和哨兵 参考1Redis主从复制和哨兵 参考2Redis主从架构和主从从架构集群搭建详细步骤Redis主从复制原理Redis复制官方文档翻译 ​ 主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master/leader)，后者称为从节点(slave/follower)；数据的复制是单向的，只能由主节点到从节点。 ​ 默认情况下，每台Redis服务器都是主节点；且一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点。 主从复制的作用 数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。 故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。 负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。 高可用基石：主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。 主从拓扑结构​ 一主一从： 这一结构主要用于主节点故障从节点，当主节点的“写”命令并发高且需要持久化，可以只在从节点开启AOF（主节点不需要），这样即保证了数据的安全性，也避免持久化对主节点的影响。 ​ 一主多从： 这一结构主要针对“读”较多的场景，“读”由多个从节点来分担，但节点越多，主节点同步到多节点的次数也越多，影响带宽，也加重主节点的稳定。 ​ 树状主从: 这一结构是对一主多从的补充，主节点只推送一次数据到slave1和slave2，再由从slave2推送到slave3和 slave4，减轻主节点推送的压力。 主从复制的实现原理主从复制过程大体可以分为3个阶段：连接建立阶段（即准备阶段）、数据同步阶段、命令传播阶段； 连接建立阶段step1：保存主节点信息​ 从节点服务器内部维护了两个字段，即masterhost和masterport字段，用于存储主节点的ip和port信息。 ​ slaveof是异步命令，从节点完成主节点ip和port的保存后，向发送slaveof命令的客户端直接返回OK，实际的复制操作在这之后才开始进行。 step2：建立socket连接​ 从节点每秒1次调用复制定时函数replicationCron()，如果发现了有主节点可以连接，便会根据主节点的ip和port，创建socket连接。 如果连接成功： ​ 从节点：为该socket建立一个专门处理复制工作的文件事件处理器，负责后续的复制工作，如接收RDB文件、接收命令传播等。 ​ 主节点：接收到从节点的socket连接后（即accept之后），为该socket创建相应的客户端状态，并将从节点看做是连接到主节点的一个客户端，后面的步骤会以从节点向主节点发送命令请求的形式来进行。 step3：发送ping命令​ 从节点成为主节点的客户端之后，发送ping命令进行首次请求，目的是：检查socket连接是否可用，以及主节点当前是否能够处理请求。 从节点发送ping命令后，可能出现3种情况： 返回pong：说明socket连接正常，且主节点当前可以处理请求，复制过程继续。 超时：一定时间后从节点仍未收到主节点的回复，说明socket连接不可用，则从节点断开socket连接，并重连。 返回pong以外的结果：如果主节点返回其他结果，如正在处理超时运行的脚本，说明主节点当前无法处理命令，则从节点断开socket连接，并重连。 step4：身份验证如果从节点中设置了masterauth选项，则从节点需要向主节点进行身份验证；没有设置该选项，则不需要验证。 从节点进行身份验证是通过向主节点发送auth命令进行的，auth命令的参数即为配置文件中的masterauth的值。 如果主节点设置密码的状态，与从节点masterauth的状态一致（一致是指都存在，且密码相同，或者都不存在），则身份验证通过，复制过程继续；如果不一致，则从节点断开socket连接，并重连。 step5：发送从节点端口信息身份验证之后，从节点会向主节点发送其监听的端口号，主节点将该信息保存到该从节点对应的客户端的slave_listening_port字段中；该端口信息除了在主节点中执行info Replication时显示以外，没有其他作用。 数据同步阶段主从节点之间的连接建立以后，便可以开始进行数据同步，该阶段可以理解为从节点数据的初始化。 具体执行的方式是：从节点向主节点发送psync命令，开始同步。 数据同步阶段是主从复制最核心的阶段，根据主从节点当前状态的不同，可以分为全量复制和部分复制。 在数据同步阶段之前，从节点是主节点的客户端，主节点不是从节点的客户端；而到了这一阶段及以后，主从节点互为客户端。原因在于：在此之前，主节点只需要响应从节点的请求即可，不需要主动发请求，而在数据同步阶段和后面的命令传播阶段，主节点需要主动向从节点发送请求（如推送缓冲区中的写命令），才能完成复制。 命令传播阶段​ 数据同步阶段完成后，主从节点进入命令传播阶段；在这个阶段主节点将自己执行的写命令发送给从节点，从节点接收命令并执行，从而保证主从节点数据的一致性。 ​ 在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING和REPLCONF ACK。 PS： ​ 延迟与不一致：命令传播是异步的过程，即主节点发送写命令后并不会等待从节点的回复；因此实际上主从节点之间很难保持实时的一致性，延迟在所难免。数据不一致的程度，与主从节点之间的网络状况、主节点写命令的执行频率、以及主节点中的repl-disable-tcp-nodelay配置等有关。 ​ repl-disable-tcp-nodelay no：该配置作用于命令传播阶段，控制主节点是否禁止与从节点的TCP_NODELAY；默认no，即不禁止TCP_NODELAY。当设置为yes时，TCP会对包进行合并从而减少带宽，但是发送的频率会降低，从节点数据延迟增加，一致性变差；具体发送频率与Linux内核的配置有关，默认配置为40ms。当设置为no时，TCP会立马将主节点的数据发送给从节点，带宽增加但延迟变小。一般来说，只有当应用对Redis数据不一致的容忍度较高，且主从节点之间网络状况不好时，才会设置为yes；多数情况使用默认值no。 【数据同步阶段】全量复制和部分复制在Redis2.8以前，从节点向主节点发送sync命令请求同步数据，此时的同步方式是全量复制； 在Redis2.8以后，从节点可以发送psync命令请求同步数据，此时根据主从节点当前状态的不同，同步方式可能是全量复制或部分复制。 全量复制：用于初次复制或其他无法进行部分复制的情况，将主节点中的所有数据都发送给从节点，是一个非常重型的操作。 部分复制：用于网络中断等情况后的复制，只将中断期间主节点执行的写命令发送给从节点，与全量复制相比更加高效。需要注意的是，如果网络中断时间过长，导致主节点没有能够完整地保存中断期间执行的写命令，则无法进行部分复制，仍使用全量复制。 全量复制Redis通过psync命令进行全量复制的过程如下： 从节点判断无法进行部分复制，向主节点发送全量复制的请求；或从节点发送部分复制的请求，但主节点判断无法进行全量复制； 主节点收到全量复制的命令后，执行bgsave，在后台生成RDB文件，并使用一个缓冲区（称为复制缓冲区）记录从现在开始执行的所有写命令。 主节点的bgsave执行完成后，将RDB文件发送给从节点；从节点首先清除自己的旧数据，然后载入接收的RDB文件，将数据库状态更新至主节点执行bgsave时的数据库状态。 主节点将前述复制缓冲区中的所有写命令发送给从节点，从节点执行这些写命令，将数据库状态更新至主节点的最新状态。 如果从节点开启了AOF，则会触发bgrewriteaof的执行，从而保证AOF文件更新至主节点的最新状态。 通过全量复制的过程可以看出，全量复制是非常重型的操作： 主节点通过bgsave命令fork子进程进行RDB持久化，该过程是非常消耗CPU、内存(页表复制)、硬盘IO的； 主节点通过网络将RDB文件发送给从节点，对主从节点的带宽都会带来很大的消耗。 从节点清空老数据、载入新RDB文件的过程是阻塞的，无法响应客户端的命令；如果从节点执行bgrewriteaof，也会带来额外的消耗。 部分复制​ 由于全量复制在主节点数据量较大时效率太低，因此Redis2.8开始提供部分复制，用于处理网络中断时的数据同步。 ​ 部分复制的实现，依赖于三个重要的概念：复制偏移量，复制积压缓冲区，服务器运行ID offset 复制偏移量​ 在主从复制的Master(主节点)和Slave(从节点)双方都会各自维持一个offset，代表的是主节点向从节点传递的字节数；Master成功发送N个字节的命令后会将Master的offset加上N，Slave在接收到N个字节命令后同样会将Slave的offset增加N。Master和Slave如果状态是一致的那么它的的offset也应该是一致的。 ​ offset用于判断主从节点的数据库状态是否一致：如果二者offset相同，则一致；如果offset不同，则不一致，此时可以根据两个offset找出从节点缺少的那部分数据。例如，如果主节点的offset是1000，而从节点的offset是500，那么部分复制就需要将offset为501-1000的数据传递给从节点。而offset为501-1000的数据存储的位置，就是下面要介绍的复制积压缓冲区。 复制积压缓冲区 复制积压缓冲区是由Master(主节点)维护的一个固定长度的FIFO队列(先进先出)，默认大小1MB；当主节点开始有从节点时创建，它的作用是缓存已经传播出去的命令。当Master进行命令传播时，不仅将命令发送给所有Slave，还会将命令写入到复制积压缓冲区里面。注意，无论主节点有一个还是多个从节点，都只需要一个复制积压缓冲区。 ​ 除了存储写命令，复制积压缓冲区中还存储了其中的每个字节对应的复制偏移量（offset）。由于复制积压缓冲区定长且是先进先出，所以它保存的是主节点最近执行的写命令；时间较早的写命令会被挤出缓冲区。 ​ 由于该缓冲区长度固定且有限，因此可以备份的写命令也有限，当主从节点offset的差距过大超过缓冲区长度时，将无法执行部分复制，只能执行全量复制。反过来说，为了提高网络中断时部分复制执行的概率，可以根据需要增大复制积压缓冲区的大小(通过配置repl-backlog-size)；例如如果网络中断的平均时间是60s，而主节点平均每秒产生的写命令(特定协议格式)所占的字节数为100KB，则复制积压缓冲区的平均需求为6MB，保险起见，可以设置为12MB，来保证绝大多数断线情况都可以使用部分复制。 从节点将offset发送给主节点后，主节点根据offset和缓冲区大小决定能否执行部分复制： 如果offset偏移量之后的数据，仍然都在复制积压缓冲区里，则执行部分复制； 如果offset偏移量之后的数据已不在复制积压缓冲区中（数据已被挤出），则执行全量复制。 runid 服务器运行ID​ 每个Redis服务器(无论主从)在启动时都会自动生成一个表明自己身份的随机ID(每次启动都不一样)，由40个随机的十六进制字符组成。在PSYNC中发送的这个ID是指之前连接的Master的ID，如果没保存这个ID，PSYNC命令会使用”PSYNC ? -1” 这种形式发送给Master，表示需要全量复制。 ​ 每个Redis节点，在启动时都会自动生成一个随机ID，由40个随机的十六进制字符组成； runid用来唯一识别一个Redis节点。通过info Server命令，可以查看节点的runid。 ​ 主从节点初次复制时，主节点将自己的runid发送给从节点，从节点将这个runid保存起来；当断线重连时，从节点会将这个runid发送给主节点； 主节点根据runid判断能否进行部分复制： 如果从节点保存的runid与主节点现在的runid相同，说明主从节点之前同步过，主节点会继续尝试使用部分复制(到底能不能部分复制还要看offset和复制积压缓冲区的情况)； 如果从节点保存的runid与主节点现在的runid不同，说明从节点在断线前同步的Redis节点并不是当前的主节点，只能进行全量复制。 PSYNC命令 Redis在2.8版本提供了PSYNC命令来带代替SYNC命令，为Redis主从复制提供了部分复制的能力。 PSYNC命令格式123PSYNC &lt;runid&gt; &lt;offset&gt;# runid:主服务器ID# offset:从服务器最后接收命令的偏移量 PSYNC执行过程中比较重要的概念有3个：runid、offset（复制偏移量）以及复制积压缓冲区。 psync命令的执行 首先从节点根据当前状态，决定如何调用psync命令： 如果从节点之前未执行过slaveof或最近执行了slaveof no one，则从节点发送命令为psync ? -1，向主节点请求全量复制； 如果从节点之前执行了slaveof，则发送命令为 psync **，其中runid为上次复制的主节点的runid，offset**为上次复制截止时从节点保存的复制偏移量。 主节点根据收到的psync命令，及当前服务器状态，决定执行全量复制还是部分复制： 如果主节点版本低于Redis2.8，则返回-ERR回复，此时从节点重新发送sync命令执行全量复制； 如果主节点版本够新，且runid与从节点发送的runid相同，且从节点发送的offset之后的数据在复制积压缓冲区中都存在，则回复+CONTINUE，表示将进行部分复制，从节点等待主节点发送其缺少的数据即可； 如果主节点版本够新，但是runid与从节点发送的runid不同，或从节点发送的offset之后的数据已不在复制积压缓冲区中(在队列中被挤出了)，则回复+FULLRESYNC ，表示要进行全量复制，其中runid表示主节点当前的runid，offset表示主节点当前的offset，从节点保存这两个值，以备使用。 【命令传播阶段】心跳机制在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING和REPLCONF ACK。心跳机制对于主从复制的超时判断、数据安全等有作用。 主-&gt;从：PING每隔指定的时间，主节点会向从节点发送PING命令，这个PING命令的作用，主要是为了让从节点进行超时判断。 PING发送的频率由 repl-ping-slave-period 参数控制，单位是秒，默认值是10s。 从-&gt;主：REPLCONF ACK在命令传播阶段，从节点会向主节点发送REPLCONF ACK命令，频率是每秒1次； 命令格式为： 1REPLCONF ACK &#123;offset&#125; # offset指从节点保存的复制偏移量。 REPLCONF ACK命令的作用包括： 实时监测主从节点网络状态：该命令会被主节点用于复制超时的判断。此外，在主节点中使用info Replication，可以看到其从节点的状态中的lag值，代表的是主节点上次收到该REPLCONF ACK命令的时间间隔，在正常情况下，该值应该是0或1。 检测命令丢失：从节点发送了自身的offset，主节点会与自己的offset对比，如果从节点数据缺失（如网络丢包），主节点会推送缺失的数据（这里也会利用复制积压缓冲区）。 注意：offset和复制积压缓冲区，不仅可以用于部分复制，也可以用于处理命令丢失等情形；区别在于前者是在断线重连后进行的，而后者是在主从节点没有断线的情况下进行的。 辅助保证从节点的数量和延迟：Redis主节点中使用min-slaves-to-write和min-slaves-max-lag参数，来保证主节点在不安全的情况下不会执行写命令；所谓不安全，是指从节点数量太少，或延迟过高。例如min-slaves-to-write和min-slaves-max-lag分别是3和10，含义是如果从节点数量小于3个，或所有从节点的延迟值都大于10s，则主节点拒绝执行写命令。而这里从节点延迟值的获取，就是通过主节点接收到REPLCONF ACK命令的时间来判断的，即前面所说的info Replication中的lag值。 开启主从复制从节点开启主从复制，有3种方式： 配置文件：在从服务器的配置文件中加入：slaveof 启动命令：redis-server启动命令后加入： –slaveof 客户端命令：Redis服务器启动后，直接通过客户端执行命令：slaveof ，则该Redis实例成为从节点。 修改配置文件方法：1. 配置从服务配置文件redis.conf1234567slaveof 192.168.1.9 6379 #添加属于某台主机的从 服务masterauth 123456 #从服务连接主服的密码（访问主服务器的密码）slave-read-only yes #从服务只读，不可在命令行写入数据5.0.4以后：replicaof &lt;masterip&gt; &lt;masterport&gt;replica-read-only yes 2. 重新启动从服务即实现主从连接121. ./bin/redis-cli # 启动redis客户端2. 输入 info replication # 查看与复制相关的状态，了解主从节点的当前状态 输入info replication 后显示的内容： 12345678910111213141516171819# Replicationrole:slave # 表示此台服务器是主是从master_host:39.107.38.62 # 主服务器ipmaster_port:6379 # 主服务器端口号master_link_status:up # 与主服务器是否连接成功 up为成功 down失败master_last_io_seconds_ago:9master_sync_in_progress:0slave_repl_offset:808slave_priority:100slave_read_only:1connected_slaves:0master_replid:ea5230cc485f9c6f372b2c89a65613fb075aff8bmaster_replid2:0000000000000000000000000000000000000000master_repl_offset:808second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:15repl_backlog_histlen:794 遇到的报错：1. Error condition on socket for SYNC: Connection refused 出现原因： ​ redis主服务器绑定了127.0.0.1，跨服务器IP的访问就会失败，只能本机才能访问，外部请求会被过滤。 1234解决方法：1. 主服务器绑定ip: bind 39.107.38.623. bind 0.0.0.02. 注释bind # 会报下面的错↓ 2. ‘-DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connec 出现原因： ​ 处于保护模式，只能本地链接。没有绑定ip 没有设置验证密码。 123解决方法：1. 主服务器绑定ip： bind 39.107.38.622. 设置主服务器访问密码：requirepass 12345 3. (error) READONLY You can’t write against a read only replica.​ 出现原因： ​ 从库只可读不可写 12解决方法：1. 设置slave-read-only no # 代表不限于只读 断开主从复制​ 通过slaveof 命令建立主从复制关系以后，可以通过slaveof no one断开。 从节点断开复制后，不会删除已有的数据，只是不再接受主节点新的数据变化。","categories":[],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://laxe.top/tags/Redis/"}]},{"title":"Redis持久化","slug":"redis持久化","date":"2019-12-26T00:26:08.965Z","updated":"2019-12-26T00:34:02.467Z","comments":true,"path":"2019/12/26/redis持久化/","link":"","permalink":"http://laxe.top/2019/12/26/redis持久化/","excerpt":"什么叫持久化？用一句话可以将持久化概括为：将数据（如内存中的对象）保存到可永久保存的存储设备中。持久化的主要应用是将内存中的对象存储在数据库中，或者存储在磁盘文件中、 XML 数据文件中等等。 从应用层与系统层理解持久化","text":"什么叫持久化？用一句话可以将持久化概括为：将数据（如内存中的对象）保存到可永久保存的存储设备中。持久化的主要应用是将内存中的对象存储在数据库中，或者存储在磁盘文件中、 XML 数据文件中等等。 从应用层与系统层理解持久化 同时，也可以从应用层和系统层这两个层面来理解持久化： 应用层：如果关闭( Close )你的应用然后重新启动则先前的数据依然存在。 系统层：如果关闭( Shutdown )你的系统（电脑）然后重新启动则先前的数据依然存在。 说白了，就是在指定的时间间隔内,将内存当中的数据快照写入磁盘,它恢复时是拷快照文件直接读到内存 什么意思呢? 我们都知道, 内存当中的数据, 如果我们一断电,那么数据必然会丢失,但是玩过redis的同学应该都知道,我们一关机之后再启动的时候数据是还在的,所以它必然是在redis启动的时候重新去加载了持久化的文件 redis提供两种方式进行持久化 一种是RDB持久化默认, 另一种 AOF (append only file) 持久化. Redis 为什么要持久化？Redis 中的数据类型都支持 push/pop、add/remove 及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。在此基础上，Redis 支持各种不同方式的排序。与 Memcached 一样，为了保证效率，数据都是缓存在内存中。 对，数据都是缓存在内存中的，当你重启系统或者关闭系统后，缓存在内存中的数据都会消失殆尽，再也找不回来了。所以，为了让数据能够长期保存，就要将 Redis 放在缓存中的数据做持久化存储。 redis持久化的意义，在于故障恢复比如你部署了一个redis，作为cache缓存，当然也可以保存一些较为重要的数据 如果没有持久化的话，redis遇到灾难性故障的时候，就会丢失所有的数据 如果通过持久化将数据搞一份儿在磁盘上去，然后定期比如说同步和备份到一些云存储服务上去，那么就可以保证数据不丢失全部，还是可以恢复一部分数据回来的 1.RDB是什么？ 原理是redis会单独创建(fork函数)（复制）一个与当前进程一模一样的子进程来进行持久化,这个子线程的所有数据(变量,环境变量,程序,程序计数器等)都和原进程一模一样,会先将数据写入到一个临时文件中,待持久化结束了,再用这个临时文件替换上次持久化好的文件,整个过程中,主进程不进行任何的IO操作,（用到了fork子进程来进行持久化）这就确保了极高的性能 1.这个持久化文件在哪里 vi /usr/local/redis/etc/redis.conf 找dbfilename dump.rdb 默认就是dump.rdb dir ./ (包括很多例如redis实例，只要是redis产生的实例都会丢到) ./ ===== 哪里启动，哪里生成。 注意： 要么写死目录 要么启动的位置就在同一个地方，地方不一样可能造成数据丢失。 2.他是什么时候fork子进程，或者什么时候触发rdb持久化机制 11./usr/local/redis/bin/redis-cli 12.SHUTDOWN 1/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf ## 开启redis shutdown时,如果没有开启aof,会触发 配置文件中默认的快照配置 执行命令save成者bgsave , save是只管保存,其他不管,全部阻塞 redis会在后台异步进行快照操作, 同时可以响应客户端的请求(默认调用bgsave来进行持久化) 1rm -f ./dump.rdb 12/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf ## 开启redis 12/usr/local/redis/bin/redis-cli ## 连接客户端 1set k1 v1 1keys * 1save ## dump.rdb 是只管保存,其他不管,全部阻塞 1bgsave ## dump.rdb redis会在后台异步进行快照操作 执行flushall命令但是里面是空的,无意义 1FLUSHALL ## 清空 在redis.conf中rdb持久化策略 集群save 900 1 ## 900秒之内执行了一次增删改操作就会触发 ， 查不算 save 300 10 save 60 10000 默认配置 redis 性能调优 集群 master节点肯定会把rdb 实际上关不掉的在主从复制上 要么就是就写一个save 要么就注掉 2.aof执行set k1 v1 保存命令 123set k1 v1set k2 v1 ## 保存到文件中 保存的是命令 是什么？ 原理是将Reids的操作日志以追加的方式写入文件,读操作是不记录的 1.这个持久化文件在哪里 产生的位置还是 ./dir 1vi /usr/local/redis/etc/redis.conf 1appendfilename \"appendonly.aof\" ## 文件名 redis 默认关闭，开启需要手动把no改为yes 1appendonly yes 1/usr/local/redis/bin/redis-cli 1set k1 v1 1SHUTDOWN 12/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf ## 开启redis 1ll ‘*’ 开头代表下面有两组命令 $ 字符串的长度 日志追加的方式保存到文件里。 2.触发机制（根据配置文件配置项） AOF_FSYNC_NO:表示等操作系统进行数据缓存同步到磁盘(快,持久化没保证) —–不能配置不可控 AOF_FSYNC_ALWAYS: 同步持久化,每次发生数据变更时,立即记录到磁盘(慢,安全) —-消耗性能 AOF_FSYNC_EVERYSEC: 表示每秒同步一次(默认值很快,但可能会丢失一秒以内的数据)–所以默认 同步策略在了解同步策略之前，需要先来了解两个三方法flushAppendOnlyFile、write和save： redis的服务器进程是一个事件循环，文件事件负责处理客户端的命令请求，而时间事件负责执行serverCron函数这样的定时运行的函数。在处理文件事件执行写命令，使得命令被追加到aof_buf中，然后在处理时间事件执行serverCron函数会调用flushAppendOnlyFile函数进行文件的写入和同步 write：根据条件，将aof_buf中的缓存写入到AOF文件 save：根据条件，调用fsync或fdatasync函数将AOF文件保存到磁盘 下面来介绍Redis支持的三种同步策略： AOF_FSYNC_NO：不保存（write和read命令都由主进程执行） AOF_FSYNC_EVERYSEC：每一秒钟保存一次（write由主进程完成，save由子进程完成） AOF_FSYNC_ALWAYS：每执行一个命令保存一次（write和read命令都由主进程执行） AOF_FSYNC_NO在这种策略下，每次flushAppendOnlyFile函数被调用的时候都会执行一次write方法，但是不会执行save方法。 只有下面三种情况下才会执行save方法： Redis被关闭 AOF功能被关闭 系统的写缓存被刷新（可能是缓存已经被写满，或者定期保存操作被执行） 这三种情况下的save操作都会引起Redis主进程阻塞，并且由于长时间没有执行save命令，所以save命令执行的时候，阻塞时间会很长 AOF_FSYNC_EVERYSEC在这种策略下，save操作原则上每隔一秒钟就会执行一次， 因为save操作是由后台子线程调用的， 所以它不会引起服务器主进程阻塞。 其实根据Redis的状态，每当 flushAppendOnlyFile函数被调用时，write命令和save命令的执行又分为四种不同情况： 根据以上图知道，在AOF_FSYNC_EVERYSEC策略下， 如果在情况1时发生故障停机， 那么用户最多损失小于2秒内所产生的数据；而如果在情况2时发生故障停机，堆积了很多save命令，那么用户损失的数据是可以超过 2 秒的。 AOF_FSYNC_ALWAYS在这种模式下，每次执行完一个命令之后，write和save命令都会被执行。 另外，因为save命令是由Redis主进程执行的，所以在save命令执行期间，主进程会被阻塞。 三种策略的优缺点AOF_FSYNC_NO策略虽然表面上看起来提升了性能，但是会存在每次save命令执行的时候相对长时间阻塞主进程的问题。并且数据的安全性的不到保证，如果Redis服务器突然宕机，那么没有从AOF缓存中保存到硬盘中的数据都会丢失。 AOF_FSYNC_ALWAYS策略的安全性的到了最大的保障，理论上最多丢失最后一次写操作，但是由于每个写操作都会阻塞主进程，所以Redis主进程的响应速度受到了很大的影响。 AOF_FSYNC_EVERYSEC策略是比较建议的配置，也是Redis的默认配置，相对来说兼顾安全性和性能。 AOF执行流程 所有的写命令都会追加到aof_buf（缓冲区）中。 可以使用不同的策略将AOF缓冲区中的命令写到AOF文件中。 随着AOF文件的越来越大，会对AOF文件进行重写。 当服务器重启的时候，会加载AOF文件并执行AOF文件中的命令用于恢复数据。 简单分析一下AOF执行流程中的一些问题： 因为Redis为了效率，使用单线程来响应命令，如果每次写命令都追加写硬盘的操作，那么Redis的响应速度还要取决于硬盘的IO效率，显然不现实，所以Redis将写命令先写到AOF缓冲区。 写道缓冲区还有一个好处是可以采用不同的策略来实现缓冲区到硬盘的同步，可以让用户自行在安全性和性能方面做出权衡。 3.aof重写机制我们以日志的方式,记录我们的命令记录到文件当中 如果我操作的特别频繁，文件肯定会特别大。 我写100万数据，持久化文件也会特别大 1/usr/local/redis/bin/redis-cli 1FLUSHALL ## 清空数据 1keys * ## 查看是否有数据 1INCR lock ## 加操作 1exit ## 退出 1vi appendonly.aof ## 查看文件 记录着 我可以直接执行一条命令set lock 11 重写就是将重复的剔除掉瘦身 1/usr/local/redis/bin/redis-cli 1BGREWRITEAOF ##手动调用重写命令 1exit ## 退出 1vi dump.rdb 是因为我这个版本是5.0的 当AOF文件增长到一定大小的时候Redis能够调用bgrewriteaof对日志文件进行重写。当AOF文件大小的增长率大于该配置项时自动开启重写(这里指超过原大小的100%) . auto-aof-rewrite-percentage 100 当AOF文件增长到一定大小的时候Redis能够调用bgrewriteaof对日志文件进行重写,当AOF文件大小大于该配置项时自动开启重写 auto-aof-rewrite-min-size 64mb incr lock 重写就是将重复的剔除掉瘦身 4.redis4.0后混合持久化机制开启混合持久化 4.0 版本是 像set lock 11 4.0版本的混合持久化默认关闭的,通过aof-use-rdb-preamble配置参数控制, yes则表示开启, no表示禁用, 5.0之后默认开启。 混合持久化是通过bgrewriteaof完成的,不同的是当开启混合持久化时, fork出的子进程先将共享的内存副本全量 以RDB方式写入aof文件,然后在将重写缓冲区的增量命令以AOF方式写入到文件,写入完成后通知主进程更新统计信息,并将新的含有RDB格式和AOF格式的AOF文件替换旧的AOF文件。 简单的说:新的AOF文件前半段是 RDB格式的全量数据后半段是AOF格式的增量数据, 优点:混合持久化结合了RDB持久化和AOF持久化的优点由于绝大部分都是RDB格式,加载速度快,同时结合 AOF,增量的数据以AOF方式保存了,数据更少的丢失. 缺点:兼容性差,一旦开启了混合持久化,在4.0之前版本都不识别该aof文件,同时由于前部分是RDB格式,阅读性较差 二进制方式存储 更小 什么时候下会自动重写 看 auto-aof-rewrite-percentage auto-aof-rewrite-min-size 小总结：1.redis提供了rdb持久化方案，为什么还要aof？ rdb 是跟据save触发持久化，所以会照成数据的丢失 aof持久化是1秒执行一次 在数据aof 在性能rdb高于aof 优化数据丢失问题，rdb会丢失最后一次快照后的数据，aof丢失不会超过2秒的数据 2.如果aof和rdb同时存在，听谁的？ aof数据准确率更高 3.rdb和aof优势劣势 rdb适合大规模的数据恢复,对数据完整性和一致性不高，在一定间隔时间做一次备份,如果redis意外宕机的话,就会丢失最后一次快照后的所有操作 aof根据配置项而定 1.官方建议两种持久化机制同时开启,如果两个同时开启优先使用aof久化机制 在生产环境中用集群，哨兵什么的 主机开aof 性能建议（这里只针对单机版redis持久化做性能建议）： 因为RDB文件只用作后备用途,只要15分钟备份一次就够了,只保留save 900 1这条规则. 因为开启aof持久化安全。 如果Enalbe AOF, 好处是在最恶劣情况下也只会丢失不超过两秒数据,启动脚本较简单只load自己的AOF文件就可以了. 代价一是带来了持续的IO,二是AOF rewrite的最后将rewrite过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。 只要硬盘许可,应该尽量减少AOF rewrite的频率, AOF重写的基础大小默认值64M太小了,可以设到5G以上.默认超过原大小100%大小时重写可以改到适当的数值。 看硬盘 1）AOF持久化开启且存在AOF文件时，优先加载AOF文件。 2）AOF关闭或者AOF文件不存在时，加载RDB文件。 3）加载AOF/RDB文件成功后，Redis启动成功。 4）AOF/RDB文件存在错误时，Redis启动失败并打印错误信息。 1.从主进程中fork出子进程，并拿到fork时的AOF文件数据写到一个临时AOF文件中 2.在重写过程中，redis收到的命令会同时写到AOF缓冲区和重写缓冲区中，这样保证重写不丢失，重写过程中的命令 3.重写完成后通知主进程，主进程会将AOF缓冲区中的数据追加到子进程生成的文件中 4.redis会原子的将旧文件替换为新文件，并开始将数据写入到新的aof文件上 执行bgrewriteaof命令的时候，如果当前有进程正在执行AOF重写，那么直接返回；如果有进程正在执行bgsave，那么等待bgsave执行完毕再执行AOF重 Redis主进程会fork一个子进程执行AOF重写。 AOF重写过程中，不影响Redis原有的AOF过程，包括写消息到AOF缓存以及同步AOF缓存中的数据到硬盘。 AOF重写过程中，主进程收到的写操作还会将命令写到AOF重写缓冲区，注意和AOF缓冲区分开。 由于AOF重写过程中原AOF文件还在陆续写入数据，所以AOF重写子进程只会拿到fork子进程时的AOF文件进行重写。 子进程拿到原AOF文件中的数据写道一个临时的AOF文件中。 子进程完成AOF重写后会发消息给主进程，主进程会把AOF重写缓冲区中的数据写道AOF缓冲区，并且用新的AOF文件替换旧的AOF文件。 总结 Redis 默认开启RDB持久化方式，在指定的时间间隔内，执行指定次数的写操作，则将内存中的数据写入到磁盘中。 RDB 持久化适合大规模的数据恢复但它的数据一致性和完整性较差。 Redis 需要手动开启AOF持久化方式，默认是每秒将写操作日志追加到AOF文件中。 AOF 的数据完整性比RDB高，但记录内容多了，会影响数据恢复的效率。 Redis 针对 AOF文件大的问题，提供重写的瘦身机制。 若只打算用Redis 做缓存，可以关闭持久化。 若打算使用Redis 的持久化。建议RDB和AOF都开启。其实RDB更适合做数据的备份，留一后手。AOF出问题了，还有RDB。 RDB和AOF的优缺点 RDB的优缺点： 一旦采用该方式，那么你的整个Redis数据库将只包含一个文件，这对于文件备份而言是非常完美的。比如，你可能打算每个小时归档一次最近24小时的数 据，同时还要每天归档一次最近30天的数据。通过这样的备份策略，一旦系统出现灾难性故障，我们可以非常容易的进行恢复。 相对于 AOF 持久化机制来说，直接基于 RDB 数据文件来重启和恢复 redis 进程，更加快速。 RDB 对 redis 对外提供的读写服务，影响非常小，可以让 redis 保持高性能，因为 redis 主进程只需要 fork 一个子进程，让子进程执行磁盘 IO 操作来进行 RDB 持久化即可。 对于灾难恢复而言，RDB是非常不错的选择。因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。 如果想要在 redis 故障时，尽可能少的丢失数据，那么 RDB 没有 AOF 好。一般来说，RDB 数据快照文件，都是每隔 5 分钟，或者更长时间生成一次，这个时候就得接受一旦 redis 进程宕机，那么会丢失最近 5 分钟的数据。 RDB 每次在 fork 子进程来执行 RDB 快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒。 AOF的优缺点： AOF 可以更好的保护数据不丢失，一般 AOF 会每隔 1 秒，通过一个后台线程执行一次fsync操作，最多丢失 1 秒钟的数据。 AOF 日志文件以append-only模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损。 如果我们本次操作只是写入了一半数据就出现了系统崩溃问题，不用担心，在Redis下一次启动之前，我们可以通过redis-check-aof工具来帮助我们解决数据 一致性的问题。 AOF 日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在rewrite log 的时候，会对其中的指令进行压缩，创建出一份需要恢复数据的最小日志出来。在创建新日志文件的时候，老的日志文件还是照常写入。当新的 merge 后的日志文件 ready 的时候，再交换新老日志文件即可。 因此在进行rewrite切换时可以更好的保证数据安全性。 AOF以一个格式清晰、易于理解的日志文件用于记录所有的修改操作， 非常适合做灾难性的误删除的紧急恢复。 比如有人不小心用flushall命令清空了所有数据，只要这个时候后台rewrite还没有发生，那么就可以立即拷贝 AOF 文件，将最后一条flushall命令给删了，然后再将该aof文件放回去，就可以通过恢复机制，自动恢复所有数据。 对于相同数量的数据集而言，AOF文件通常要大于RDB文件。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。 AOF 开启后，支持的写 QPS 会比 RDB 支持的写 QPS 低， 因为 AOF 一般会配置成每秒 fsync 一次日志文件。 类似 AOF 这种较为复杂的基于命令日志 / merge / 回放的方式，比基于 RDB 每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有 bug。 如何选择？ RDB和AOF如何选择？ 不要仅仅使用 RDB，因为那样会导致你丢失很多数据； 也不要仅仅使用 AOF，因为那样有两个问题：第一，你通过 AOF 做冷备，没有 RDB 做冷备来的恢复速度更快；第二，RDB 每次简单粗暴生成数据快照，更加健壮，可以避免 AOF 这种复杂的备份和恢复机制的 bug； redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择; 用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。 aof-load-truncated yes解决 aof文件同步过程 服务宕机 文件末尾出错 无法再次启动回复数据的问题这个配置可以绕过错误","categories":[],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://laxe.top/tags/Redis/"}]},{"title":"Docker 存储","slug":"docker存储","date":"2019-12-26T00:24:45.744Z","updated":"2019-12-26T00:30:32.722Z","comments":true,"path":"2019/12/26/docker存储/","link":"","permalink":"http://laxe.top/2019/12/26/docker存储/","excerpt":"Docek镜像层的镜像分层结构docker的镜像分层结构，如下所示： docker镜像中引入层layer概念，镜像的制作过程中的每一步都会生产一个新的镜像层 容器读写层的工作原理 我们刚刚在说镜像的分层特性的时候说到镜像是只读的。而事实上当我们使用镜像启动一个容器的时候，我们其实是可以在容器里随意读写的，从结果上看，似乎与镜像的只读特性相悖。 我们继续看上面的图，其实可以看到在镜像的最上层，还有一个读写层。而这个读写层，即在容器启动时为当前容器单独挂载。每一个容器在运行时，都会基于当前镜像在其最上层挂载一个读写层。而用户针对容器的所有操作都在读写层中完成。一旦容器销毁，这个读写层也随之销毁。 知识点： 容器=镜像+读写层 而我们针对这个读写层的操作，主要基于两种方式：写时复制和用时分配。","text":"Docek镜像层的镜像分层结构docker的镜像分层结构，如下所示： docker镜像中引入层layer概念，镜像的制作过程中的每一步都会生产一个新的镜像层 容器读写层的工作原理 我们刚刚在说镜像的分层特性的时候说到镜像是只读的。而事实上当我们使用镜像启动一个容器的时候，我们其实是可以在容器里随意读写的，从结果上看，似乎与镜像的只读特性相悖。 我们继续看上面的图，其实可以看到在镜像的最上层，还有一个读写层。而这个读写层，即在容器启动时为当前容器单独挂载。每一个容器在运行时，都会基于当前镜像在其最上层挂载一个读写层。而用户针对容器的所有操作都在读写层中完成。一旦容器销毁，这个读写层也随之销毁。 知识点： 容器=镜像+读写层 而我们针对这个读写层的操作，主要基于两种方式：写时复制和用时分配。 overlay2镜像存储结构容器 容器由最上面一个可写的容器层和若干个只读的镜像层组成，容器的数据就存在这些层中。这种分层结构最大的特点是Copy-on-Write。 新数据会直接存放在最上面的容器层 修改现有数据会从镜像层复制文件到容器中，再在容器层修改并保存，镜像层的数据不会发生改变 若多个层中有命名相同的文件，用户只能看到最上面一层的文件 分层结构使镜像和容器的创建、共享以及分发变得非常高效，而这些都要归功于 Docerk stoage driver。正是 storage driver 实现了多层数据的堆叠并为用户提供一个单一的合并之后的统一视图。 Docker 为容器提供了两种存放数据的资源： 由storage driver（存储驱动） 管理的镜像层和容器层 用来放一些无状态的数据 对于某些容器，直接将数据放在由 storage driver 维护的层中是很好的选择，比如那些无状态的应用。无状态意味着容器没有需要持久化的数据，随时可以从镜像直接创建。即存在与否依赖镜像的存在。 Data Volume。（数据卷） 用来放一些有状态的数据，例如数据库 本质上是 Docker Host （主机）文件系统中的目录或文件，能够直接被 ** mount （挂载）到容器的文件系统中**。 关于docker镜像的三问 基于镜像A创建镜像B时是否会拷贝A镜像中的所有文件：是不会的 基于镜像创建容器时是否会拷贝镜像中的所有文件至文件层：不会的 容器与镜像在结构上有什么区别：没有区别容器会比镜像多了一个 merged文件 在讲原理前，先讲下写时复制和写时分配 写时复制（CoW） 所有驱动都用到的技术——写时复制（CoW）。CoW就是copy-on-write，表示只在需要写时才去复制，这个是针对已有文件的修改场景比如基于一个image启动多个Container，如果为每个Container都去分配一个image一样的文件系统，那么将会占用大量的磁盘空间。而CoW技术可以让所有的容器共享image的文件系统，所有数据都从image中读取，只有当要对文件进行写操作时，才从image里把要写的文件复制到自己的文件系统进行修改。所以无论多少个容器共享同一个image，所作的写操作都是从image中复制到自己的文件系统中的复制本上进行，并不会修改image的源文件，且多个容器操作同一个文件，会在每个容器的文件系统里生成一个复本，每个容器修改的都是自己的复本，相互隔离的，相互不影响。使用CoW可以有效的提高磁盘的利用率。 用时分配（allocate-on-demand） 而用时分配是用在原本没有这个文件的场景，只有在要新写入一个文件时才分配空间，这样可以提高存储资源的利用率。比如启动一个容器，并不会为这个容器预分配一些磁盘空间，而是当有新文件写入时，才按需分配新空间。 Docker存储驱动的作用 将这些分层的镜像文件堆叠起来，并且提供统一的视图.使container的文件系统看上去和我们普通的文件系统没什么区别。当创建一个新的容器的时候,实际上是在镜像的分层上新添加了一层container layer（容器层）.之后所有对容器产生的修改,实际都只影响这一层。 注意 容器层：读写层(可写层)镜像层：只读层 Docker 支持多种 storage driver，有 AUFS 、Device Mapper 、Btrfs 、OverlayFS 、VFS 和ZFS。它们都能实现分层的架构，同时又有各自的特性。对于Docker 用户来说，具体选择使用哪个 storage driver 是一个难题，因为： ​ 没有哪个driver 能够适应所有的场景。 ​ driver 本身在快速发展和迭代。 优先使用 Linux 发行版默认的 storage driver。Docker 安装时会根据当前系统的配置选择默认的 driver。默认 driver 具有最好的稳定性，因为默认 driver 在发行版上经过了严格的测试。 运行docker info可以查看可查看当前系统使用的Storage driver。 Ubuntu 用的 AUFS，底层文件系统是 extfs，各层数据存放在 /var/lib/docker/aufs。centos默认的driver用的是overlay2，底层的文件系统是xfs,各层数据存放在/var/lib/docker 而写时分配是用在原本没有这个文件的场景，只有在要新写入一个文件时才分配空间，这样可以提高存储资源的利用率。 比如启动一个容器，并不是为这个容器预分配一些磁盘空间，而是当有新文件写入时，才按需分配新空间。 docker提供了多种的存储驱动来实现不同的方式存储镜像 Docker五种存储驱动原理及应用场景和性能测试对比 Docker 最开始采用AUFS作为文件系统，也得益于AUFS分层的概念，实现了多个Container可以共享同一个image。但由于AUFS 为并入 Linux内核，且只支持 Ubuntu，考虑到兼容的问题，在 Docker 0.7 版本中引入了存储驱动，就如Docker官网上说的，没有单一的驱动适应所有的应用场景，要根据不同的场景选择合适的存储驱动，才能有效的提高Docker 的性能。如何选择适合的存储驱动，要先了解存储驱动原理才能更好的判断。 接下来我们说说这些分层的镜像是如何在磁盘中存储的。 docker 提供了多种存储驱动来实现不同的方式存储镜像 下列出了 Docker 中支持的存储驱动程序： 技术 存储驱动成名称 OverlayFS overlay 或 overlay2 AUFS aufs Btrfs btrfs Device Mapper devicemapper VFS vfs ZFS zfs AUFS AUFS（AnotherUnionFS）是一种 Union FS ，是文件级的存储驱动。AUFS 是一个能透明覆盖一个或多个县有文件系统的层状文件系统，把多层合并成文件系统的单层表示。简单来说就是支持将不同目录挂载到同一个虚拟文件系统下的文件系统。这种文件可以一层一层地叠加修改文件。无论低下有多少层都是只读的，只有最上层的文件系统是可写的。当需要修改文件时，AUFS创建该文件的一个副本，使用CoW将文件从只读层复制到可写层进行修改，结果保存在可写层。在Docker中，低下的只读层就是image，可写层就是Container。结构如下图所示： 历史：aufs驱动老早就在Docker中存在了！其实，他在使用graphdriver这个名字之前久存在了。如果你查看项目在那（即首次使用graphdriver名称）提交之前的历史，之前项目中当时只有一个aufs的实现。下边devicemapper部分会讲到更多关于graphdriver这个名称诞生的历史。 实现：Aufs最初代表的意思“另一个联合文件系统（another union filesystem）”，试图对当时已经存在的UnionFS实现进行重写。正如你期望的那样，它是一个传统意义的上层覆盖，通过利用aufs称作为“分支（branch）”的特性，让堆叠的目录合并成一个堆叠内容单一挂载点视图。此驱动会将父级信息组合一个有序列表，并把它作为挂载参数，然后把重活移交给aufs来把这些分层组装成一个联合视图。更多的细节信息可以在aufs的帮助文档上看到。 优点：这可能是历史最久且测试最完善的graphdriver后端了。它拥有不错的性能，也比较稳定，适用于广泛的场景。尽管它只在Ubuntu或者Debian的内核上才可以启用（下边有说明），但是这两个发行版和Docker一起使用的场景已经非常多，这让它在广阔的环境中得到了验证。同时，通过让不同的容器从同一个分层里面加载相同的库（因为他们在磁盘上是相同的inode）达到了共享内存页的效果。 缺点：Aufs从来没有被上游Linux内核社区接受。多年来Ubuntu和Debian都需要往内核集成一个历史久远的补丁包，且原作者已经放弃了让它被内核采纳的努力。可能与IPV4和IPv6的辩论有些类似，人们担心某一天内核更新后会出现难以整合aufs的补丁的情况，从而导致aufs没得玩。但是就如IPv6，替换aufs势在必行的决心讲了一年又一年。除此之外，它面临着很多其他比较棘手的问题。其中一个最麻烦的、也是比较有历史的问题（尽管某种程度上这是一个安全的特性），是关于在高层更改向上拷贝的文件的权限的，这个问题困扰了不少用户。最终在2015年早期的时候通过编号为#11799的PR使用aufs的dirperm1特性修复了。自然，这需要内核中有具有dirperm1能力aufs，然而这在今天任何较新版本的Ubuntu或者Debian上都已经不成问题了。 总结：如果你在使用Ubtuntu或者Debian，那默认的graphdriver就是aufs，它能满足你绝大多数需求。有人期望有一天它能被overlay的实现取代，但是考虑到overlay文件系统的诸多问题，以及在上游内核中的成熟程度等挑战，这尚未实现。最后，aufs中没有配额的支持。 Overlay Overlay 是Linux内核3.18后支持的，也是一种Union FS，和AUFS的多层不同的是Overlay只有两层：一个upper文件系统和一个lower文件系统，分别代表Docekr的镜像层和容器层。当需要修改一个文件时，使用CoW将文件从只读的lower复制到可写的upper进行修改，结果也保存在upper层。在Docekr中，底下的只读层就是image，可写层就是Container。目前最新的OverlayFS为Overlay2。结构图如下所示： 历史：2014年8月，Red Hat的 Alex Larsson在编号为453552c8384929d8ae04dcf1c6954435c0111da0的代码提交中添加了针对OverlayFS（最初的上游内核的名称）的graphdriver。 实现：Overlay是一个联合文件系统，它的概念较之aufs的分支模型更为简单。Overlay通过三个概念来实现它的文件系统：一个“下层目录（lower-dir）”，一个“上层目录（upper-dir）”，和一个做为文件系统合并视图的“合并（merged）”目录。受限于只有一个“下层目录”，需要额外的工作来让“下层目录”递归嵌套（下层目录自己又是另外一个overlay的联合），或者按照Docker的实现，将所有位于下层的内容都硬链接到“下层目录”中。正是这种可能潜在的inode爆炸式增长（因为有大量的分层和硬连接）阻碍了很多人采用Overlay。Overlay2通过利用更高内核（4.0以及以上的版本）中提供了的更优雅处理多个位于下层分层的机制解决了这个问题。 优点：Overlay作为一个合并进主线Linux内核的一个有完整支持的联合文件系统有望成为人们的焦点。与aufs类似，通过使用磁盘上相同的共享库，它也能让分散的容器实现内存共享。Overlay同时有很多的上游Linux内核基于现代的应用场景，如Docker，被持续开发（参看overlay2）。 缺点：硬链接的实现方式已经引发了 inode耗尽的问题，这阻碍了它的大规模采用。inode耗尽并不是唯一的问题，还有其他一些与用户命名空间、SELinux支持有关的问题，且整体的成熟状况不足也阻碍着overlay直接取代aufs成为Docker默认的graphdriver。随着很多问题的解决，特别是在最新的内核发新版中，overlay的可用度越来越高了。如今出现的Overlay2修复了inode耗尽的问题，应该是从Docker 1.12版本之后的焦点，成为overlay驱动的后续开发对象。出于向后兼容的原因，overlay驱动将会继续留在Docker引擎中继续支持现有的用户。 总结：考虑到aufs没有足够多的发行版的支持，能有一个上游集成的联合文件系统且拥有Linux内核文件系统社区的支持，overlay驱动的加入是一个重大进步。Overlay在过去的18-24个月已经成熟了很多，并且随着overlay2的出现，它之前一些麻烦的问题已经解决了。希望overlay（或者更具可能性的overlay2）会成为未来默认的graphdriver。为了overlay最好的体验，上游内核社区在4.4.x的内核系列里面修复了很多overlay实现中存在的问题；选择该系列中更新的版本可以获得overlay更好的性能和稳定性。 Overlay2 历史：Derek McGowan在编号为#22126的PR中添加了overlay2的graphdriver，在2016年6月被合并进Docker 1.12版本，正如该PR的标题注明的，要取代之前overlay的主要原因是它能“支持多个下层目录”，能解决原先驱动中inode耗尽的问题。 实现：在上面的overlay部分已经讲述了Linux内核中的Overlay的框架。上面链接的PR中改进了原有的设计，基于Linux内核4.0和以后版本中overlay的特性，可以允许有多个下层的目录。 优点：overlay2解决了一些因为最初驱动的设计而引发的inode耗尽和一些其他问题。Overlay2继续保留overlay已有的优点，包括在同一个引擎的多个容器间从同一个分层中加载内库从而达到内存共享。 缺点：现在可能唯一能挑出overlay2的问题是代码库还比较年轻。很多早期的问题已经在早期测试过程中发现并被及时解决了。但是Docker 1.12是第一个提供overlay2的发行版本，随着使用量的增长，相信可能还会发现其他问题。 总结：将Linux内核中的一个现代的、广受支持的联合文件系统，和一个和Docker中一个性能优秀的graphdriver结合起来，这应该是Docker引擎未来打造默认的graphdriver最好的道路，只有这样才能获得各种Linux发行版广泛的支持。 Device mapper Device mapper 是Linux 内核 2.6.9 后支持的，提供的一种从逻辑设备到物理设备的映射框架机制，在该机制下，用户可以很方便的根据自己的需要制定实现存储资源的管理策略。前面讲的 AUFS 和 OverlayFS 都是文件级存储，而 Device mapper 是块级存储，所有的操作都是直接对块进行操作，而不是文件。Device mapper 驱动会先在块设备上创建一个资源池，然后在资源池上创建一个带有文件系统的基本设备，所有镜像都是这个基本设备的快照，而容器则是镜像的快照。所以在容器里看到文件系统是资源池上基本设备的文件系统的快照，并不有为容器分配空间。当要写入一个新文件时，在容器的镜像内为其分配新的块并写入数据，这个用时分配。当要修改已有文件时，再使用 CoW 为容器快照分配块空间，将要修改的数据复制在容器快照中新的块里在进行修改。Device mapper 驱动默认会创建一个 100 G 的文件包含镜像和容器。每个容器被限制在 10G 大小的卷内，可以自己设置调整。结构如下图所示： 历史：Devicemapper很早就以Ｃ代码的包装器面貌存在了，用来和libdevmapper进行交互； 是2013的９月Alex Larsson在编号为 739af0a17f6a5a9956bbc9fd1e81e4d40bff8167的代码提交中添加的。几个月后的重构了才诞生了我们现在所知道的“graphdriver”这个词；Solomon Hykes在2013年10月份早期代码合并的注释中说：将devmapper和aufs整合进通用的“graphdriver”框架。 实现：devicemapper这个graphdriver利用了Linux中devicemapper代码中众多特性之一，“轻配置（thin provisioning）”，或者简称为“thinp”。（译注：根据Wikipedia，“thin provisioning是利用虚拟化技术，让人觉得有比实际可用更多的物理资源。如果系统的资源足够，能同时满足所有的虚拟化的资源，那就不能叫做thin-provisioned。”） 这与之前提到的联合文件系统不同，因为devicemapper是基于块设备的。这些“轻配置（thin-provisioned）”的块设备带来的是如联合文件系统所提供的一样轻量的行为，但是最重要的一点是，他们不是基于文件的（而是基于块设备的）。正如你能推测的，这让计算分层之间的差别变得不再容易，也丧失了通过在容器间使用同样的库片段而共享内存的能力。 优点：Devicemapper在过去的年间也被一些人感到不屑，但是它提供的一个非常重要的能力让红帽系（Fedora,RHEL，Project Atomic）也有了一个graphdriver。因为它是基于块设备而不是基于文件的，它有一些内置的能力如配额支持，而这在其他的实现中是不容易达到的。 缺点：使用devicemapper没有办法达到开箱立即唾手可得很好的性能。你必须遵循安装和配置指示才能得到性能还可以的配置。并且最重要的是，在任何需要用Docke引擎来做点正事的地方，都不要使用“虚拟设备（loopback）”模式（对于运行有devicemapper且负载高的系统，如延迟删除（ deferred removal）这样的特性绝对有必要的，这能减少引擎看起来好似夯住了一样的悲剧。）。它的一些特性依赖libdevmaper特定的版本，并且需要比较高级的技能来验证系统上所有的设置。同时，如果Docker Engine的二进制是静态编译的话，devicemapper会完全无法工作，因为它需要udev sync的支持，而这不能被静态编译进引擎中。 总结：对于红帽类发行版本来说，devicemapper已经成为“可以直接用”的选择，并且在过去几年间里得到了红帽团队的大力支持和改进。它质量上有优点也有缺点，如果安装/配置过程中没有特别格外注意的话，可能导致和其他选项比较起来性能低下、质量不高。鉴于overlay和overlay2受到了Fedora和RHEL最新的内核的支持，并且拥有SELinux的支持，除非在Red Hat场景中有某种必须使用devicemapper的需求，我想随着用户的成熟他们会转向overlay的怀抱。 Btrfs Btrfs 被称为下一代写时复制文件系统，并入Linux内核，也是文件级存储，但可以向 Device mapper 一直操作底层设备。 Btrfs 把文件系统的一部分配置为一个完整的子文件系统，称为 subvolume。那么采用 subvolume ，一个大的文件系统可以被划分为很多个子文件系统，这些子文件系统共享底层的设备空间，在需要磁盘空间使用时便从底层设备中分配，类似应用程序调用 malloc（）分配内存一样。为了灵活利用设备空间， Btrfs 将磁盘空间划分为多个 chunk。每个 chunk 可以使用不同的磁盘空间分配策略。比如某些 chunk 只存放 metadata ，某些chunk 只存放数据。这种模型有很多优点，比如 Btrfs 支持动态添加设备。用户在系统中添加新的磁盘之后，可以使用 Btrfs 的命令将该设备添加到文件系统中。Btrfs 把一个大的文件系统当成一个资源池，配置成多个完整的子文件系统，还可以往资源池里加新的子文件系统，而基础镜像则是子文件系统的快照，每个子镜像和容器都有自己的快照，这些快照都是 subvolume 的快照。 当写入一个新文件时，为在容器的快照里为其分配一个新的数据块，文件写在这个空间里，这个叫做分配。而当要修改已有文件时，使用 CoW 复制分配一个新的原始数据和快照，在这个新分配的空间变更数据，变结束再跟新相关的数据结构指向新子文件系统和快照，原来的原始数据和快照没有指针指向，被覆盖。 历史：2013年12月较晚的时候，Red Hat公司的Alex Larsson在编号为e51af36a85126aca6bf6da5291eaf960fd82aa56的提交中，让使用btrfs作为管理/var/lib/docker的文件系统成为可能。 实现：Btrfs的原生特性中，有两个是“子卷（subvolumes）”和“快照（snapshots）”。（译注：根据Wikipedia，“子卷在btrfs中不是一个块设备，也不应该被当做是一个块设备。相反，子卷可以被想象成POSIX文件的命名空间。这个命名空间可以通过顶层的子卷来访问到，也可以独立地被挂载。快照在Btrfs中实际上是一个子卷，通过使用Btrfs的写时复制来和其他的子卷共享数据，对快照的更改不会影响原先的子卷。” ） graphdriver实现中主要结合了这两个能力，从而提供了堆叠和类似写时复制的特性。当然，graphdriver的根（默认情况下是：/var/lib/docker）需要是一个被btrfs文件系统格式化的磁盘。 优点：Btrfs几年前发布的时候（2007-2009时代），它被视作一个未来的Linux文件系统并受到了大量的关注。如今在上游Linux内核中，该文件系统已经比较健壮，并受到良好的支持，是众多可选的文件系统之一。 缺点：但是Btrfs并没有成为Linux发行版的主流选择，所以你不大可能已经有一个btrfs格式化的磁盘。因为这种在Linux发行版中采用不足的原因，它并没有受到类似其他graphdriver一样的关注和采用。 总结：如果你正在使用btrfs，那很显然的这个graphdriver应该迎合了你的需求。在过去几年有过很多Bug，并且有一段时间缺乏对SELinux的支持，但是这已经被修复了。同时，对btrfs配额的支持也直接加进了docker守护进程中，这是Zhu Guihua在编号为#19651的PR中添加的，这个特性包含在了Docker 1.12版本中。 ZFS ZFS 文件系统是一个革命性的全新的文件系统，它从根本上改变了文件系统的管理方式， ZFS 完全抛弃了 “ 卷管理 ” ，不再创建虚拟的卷，而是把所有设备集中到一个存储池中进行管理，用 “ 存储池 ” 的概念来管理物理存储空间。过去，文件系统都是构建在物理设备之上的，为了管理这些物理设备，并为数据提供冗余，“ 卷管理 ” 的概念提供了一个单设备的映射。而 ZFS 创建在虚拟的，被称为 “ zpools ” 的存储池之上。每个存储池由若干虚拟设备（ virtual devices ，vdevs ）组成。这些虚拟设备可以是原始磁盘，也节能是一个RAID1 镜像设备，或是非标准 RAID 等级的多磁盘组。 于是 zpool 上的文件系统可以使用这些虚拟设备的总存储容量。 下面看一下Docker 里ZFS的使用。首先从 zpool里分配一个ZFS 文件系统给镜像的基础层，而其他镜像层则是这个 ZFS 文件系统快照的克隆，快照是只读的，而克隆是可写的，当容器启动时则在镜像的顶层生成一个可写层。如下图所示： d当要写一个新文件时，使用按需分配，一个新的数据块从 zpool 里生成新的数据写入这个块，而这个新空间存于容器（ ZFS 的克隆 ）里。 当要修改一个已存在的文件时，使用写时复制，分配一个新空间并把原始数据复制到新空间完成修改。 历史：ZFS的graphdriver是由Arthur Gautier和Jörg Thalheim一起在#9411的PR中实现的，在2014年的5月被合并进了Docker引擎里面，并且从Docker 1.7版本开始用户可以使用。该实现依赖Go的一个三方包go-zfs进行相关zfs命令的交互。 实现：与btrfs和devicemapper类似，要使用zfs驱动必需要有一个ZFS格式化的块设备挂载到graphdriver路径（默认是/var/lib/docker）。同时也需要安装好zfs工具（在绝大多数的发行版上是一个名为zfs-utils的包）供zfs Go库调用来执行相关操作。ZFS有能力创建快照（与btrfs类似），然后以快照的克隆作为分享层的途径（在ZFS的实现中成了一个快照）。因为ZFS不是一个基于文件的实现，aufs和overlay中所拥有的内存共享能力在ZFS是没有的。 优点：ZFS正在受到越来越多的欢迎，在Ubuntu 16.04中，在Ubuntu的LXC/LXD中已经被使用。最初由Sun创建，ZFS已经存在很长的时间了，并且在Solaris和很多BSD的衍生版中使用，并且它的Linux移植版实现看起来也比较稳定，对于容器文件系统的场景也有足够合理性能。ZFSgraphdriver也很及时的在Dockr 1.12中通过PR #21946添加了配额的支持，这让它在配额支持方面和btrfs、devicemapper站在了同一起跑线上。 缺点：除了没有基于文件（inode）的共享达到内库共享之外，很难说ZFS和其它同样基于块设备的实现相比有什么缺点。通过比较，ZFS看起来欢迎程度越来越高。对于那些完全支持或者正在使用ZFS的Linux发行版或者UNIX衍生版而言，zfs graphdriver可以是一个非常好的选择。 总结：ZFS的支持为Docker引擎中稳定的graphdriver加了分。对于那些ZFS的使用者，或者那些ZFS扮演了更要角色的发行版来说，Docker能直接支持该文件系统，对这些社区来说是一个好消息。对于那些默认文件系统是ext4和xfs的发行版，默认采用overlay驱动的用户来说，时间会告诉我们他们是否会对zfs驱动产生更多的兴趣。 存储驱动的对比及适应场景 存储驱动 特点 优点 缺点 适用场景 AUFS 联合文件系统、未并入内核主线、文件级存储 作为docker的第一个存储驱动，已经有很长的历史，比较稳定，且在大量的生产中实践过，有较强的社区支持 有多层，在做写时复制操作时，如果文件比较大且存在比较低的层，可能会慢一些 大并发但少IO的场景 overlayFS 联合文件系统、并入内核主线、文件级存储 只有两层 不管修改的内容大小都会复制整个文件，对大文件进行修改显示要比小文件消耗更多的时间 大并发但少IO的场景 Devicemapper 并入内核主线、块级存储 块级无论是大文件还是小文件都只复制需要修改的块，并不是整个文件 不支持共享存储，当有多个容器读同一个文件时，需要生成多个复本，在很多容器启停的情况下可能会导致磁盘溢出 适合io密集的场景 Btrfs 并入linux内核、文件级存储 可以像devicemapper一样直接操作底层设备，支持动态添加设备 不支持共享存储，当有多个容器读同一个文件时，需要生成多个复本 不适合在高密度容器的paas平台上使用 ZFS 把所有设备集中到一个存储池中来进行管理 支持多个容器共享一个缓存块，适合内存大的环境 COW使用碎片化问题更加严重，文件在硬盘上的物理地址会变的不再连续，顺序读会变的性能比较差 适合paas和高密度的场景 AUFS VS Overlay AUFS和Overlay都是联合文件系统，但AUFS有多层，而Overlay只有两层，所以在做写时复制操作时，如果文件比较大且存在比较低的层，则AUSF可能会慢一些。而且Overlay并入了linux kernel mainline，AUFS没有，所以可能会比AUFS快。但Overlay还太年轻，要谨慎在生产使用。而AUFS做为docker的第一个存储驱动，已经有很长的历史，比较的稳定，且在大量的生产中实践过，有较强的社区支持。目前开源的DC/OS指定使用Overlay。 Overlay VS Device mapper Overlay是文件级存储，Device mapper是块级存储，当文件特别大而修改的内容很小，Overlay不管修改的内容大小都会复制整个文件，对大文件进行修改显示要比小文件要消耗更多的时间，而块级无论是大文件还是小文件都只复制需要修改的块，并不是整个文件，在这种场景下，显然device mapper要快一些。因为块级的是直接访问逻辑盘，适合IO密集的场景。而对于程序内部复杂，大并发但少IO的场景，Overlay的性能相对要强一些。 Device mapper VS Btrfs Driver VS ZFS Device mapper和Btrfs都是直接对块操作，都不支持共享存储，表示当有多个容器读同一个文件时，需要生活多个复本，所以这种存储驱动不适合在高密度容器的PaaS平台上使用。而且在很多容器启停的情况下可能会导致磁盘溢出，造成主机不能工作。Device mapper不建议在生产使用。Btrfs在docker build可以很高效。ZFS最初是为拥有大量内存的Salaris服务器设计的，所在在使用时对内存会有影响，适合内存大的环境。ZFS的COW使碎片化问题更加严重，对于顺序写生成的大文件，如果以后随机的对其中的一部分进行了更改，那么这个文件在硬盘上的物理地址就变得不再连续，未来的顺序读会变得性能比较差。ZFS支持多个容器共享一个缓存块，适合PaaS和高密度的用户场景。 IO性能对比 测试工具：IOzone（是一个文件系统的benchmark工具，可以测试不同的操作系统中文件系统的读写性能）测试场景：从4K到1G文件的顺序和随机IO性能测试方法：基于不同的存储驱动启动容器，在容器内安装IOzone，执行命令： 1./iozone -a -n 4k -g 1g -i 0 -i 1 -i 2 -f /root/test.rar -Rb ./iozone.xls 测试项的定义和解释 Write：测试向一个新文件写入的性能。Re-write：测试向一个已存在的文件写入的性能。Read：测试读一个已存在的文件的性能。Re-Read：测试读一个最近读过的文件的性能。Random Read：测试读一个文件中的随机偏移量的性能。Random Write：测试写一个文件中的随机偏移量的性能。 测试数据对比 Write： Re-write: Read： Re-Read： Random Read： Random Write： 通过以上的性能数据可以看到： AUFS在读的方面性能相比Overlay要差一些，但在写的方面性能比Overlay要好。 device mapper在512M以上文件的读写性能都非常的差，但在512M以下的文件读写性能都比较好。 btrfs在512M以上的文件读写性能都非常好，但在512M以下的文件读写性能相比其他的存储驱动都比较差。 ZFS整体的读写性能相比其他的存储驱动都要差一些。 简单的测试了一些数据，对测试出来的数据原理还需要进一步的解析。 Docker 提供了可插拔的存储驱动程序架构。它使我们能够灵活地 插入 Docker中的存储驱动程序。他完全基于Linux文件系统 。 要实现这一功能，我们必须 在docker 守护进程的开始时就设置驱动程序。 Docker 守护程序只能运行一个存储驱动程序，并且该守护程序实例创建的所有容器使用相同的存储驱动程序。 当前存储驱动 查看守护程序使用哪个存储驱动程序，可以使用一下命令。 1$ docker info 可以看到上面的命令显示了守护进程使用的存储驱动程序。备份文件系统 extfs 。 extfs 表示覆盖存储驱动程序在文件系统的顶部运行。 后备文件系统实质用于在 /var/lib/docker 录下创建 Docker 主机的本地存储区域的文件系统。 下表包含必须与主机备份文件系统相匹配的存储驱动程序。 存储驱动 常用 已禁用 overlay ext4xfs btrfs aufs overlayzfs eCryptfs overlay2 ext4xfs btrfs aufs overlayzfs eCryptfs aufs ext4xfs btrfs aufs eCryptfs aufs btrfsonly N/A devicemapper Direct-lvm N/A vfs debugging only N/A N/A 注意 ：- “已禁用/Disabled on” 表示某些存储驱动程序无法在某些后台文件系统上运行 设置存储驱动程序 可以通过 dockersd命令按指定名称来设置存储驱动程序。以下命令启动守护程序并设置新的驱动程序。 1$ dockerd --storage-driver=devicemapper 稍后，可以通过 docker info 命令检查 docker 服务驱动程序 对于某些容器，直接将数据放在由 storage driver 维护的层中是很好的选择，比如那些无状态的应用。无状态意味着容器没有需要持久化的数据，随时可以从镜像直接创建。即存在与否依赖镜像的存在。 1234# 如一些工具箱，启动是为了执行命令，不需要保存数据供以后使用，使用完直接退出，容器删除时存在容器层的工作数据也一起删除，这没问题，下次启动新容器即可。# 但对于另一类应用这种方式就不合适了，它们有持久化数据的需求，容器启动时需要加载已有的数据，容器销毁时希望保留产生的新数据，也就是说，这类容器是有状态的，例如数据库。这就要用到docker 的另一个存储机制：data volume Data Volume（数据卷） 对于有些容器，我们可能会持久化数据的需求，也就是容器启动时需要加载已有的数据，容器销毁时希望保留产生的数据，也就是说这类容器是有状态的。 这就需要用到 Docker 的 Data Volume 存储机制。Data Volume本质上是 Docker host文件系统中的目录或文件，能够直接被 mount 到容器的文件系统。 在具体的使用上，Docekr 提供了两种类型的Volume：bind mount 和docker managed volume。 附：bind mount 与 docker managed volume 的区别 这两种 data volume 实际上都是使用 host 文件系统的中的某个路径作为 mount 源。它们不同之处在于： 不同点 bind mount docker managed volume volume 位置 可任意指定 /var/lib/docker/volumes/… 对已有mount point 影响 隐藏并替换为 volume 原有数据复制到 volume 是否支持单个文件 支持 不支持，只能是目录 权限控制 可设置为只读，默认为读写权限 无控制，均为读写权限 移植性 移植性弱，与 host path 绑定 移植性强，无需指定 host 目录 什么是数据卷 Data Volume 数据卷 ：是可以存放在一个或多个容器内的 特定的目录，提供独立于容器之外的持久化存储；是经过特殊设计的目录，可以绕过联合文件系统（UFS），为一个或多个容器提供访问； 12345678910Docker Contrainer面向对象中的对象对象一旦被销毁，数据就不存在了容器一旦被销毁，则容器内的数据将一并被删除服务器中的图案也会一并销毁容器中的数据不是持久化状态的 不使用 volume的时候，对容器进行的改动是不会被保存的，使用 volume可以实现持久化存储；比如运行一个数据的操作，数据库的一个容器，数据库的数据应该被持久化存储的，volume就可以实现这个，并且 volume可以提供容器与容器之间的共享数据； Docker 的理念之一： 就是将其应用于其运行的环境打包，因此，通过Docker 容器的生存周期，都是与容器中运行的程序相一致的，而我们对数据的要求通常是持久化的；另一方面，docker容器之间也需要有一个 共享数据的渠道 ，而这些需求就催生出了docker数据卷的产生； 数据卷的设计的目的： 在于 数据的永久化 ，它完全独立于容器的生存周期，因此，Docekr不会在容器删除时删除其挂载的数据卷，也不会存在类似垃圾收集机制，对容器引用的数据卷进行处理了； 数据卷特点： Docker数据卷是独立于Docker的存在，它存在于Docker host（宿主机）中，因此，它与容器的生存周期是分离的； Docker数据卷本质上是存在于Docker宿主机的本地文件系统中； Docker 数据卷可以是目录也可以是文件；（不是块设备） Docker 容器可以利用数据卷的技术与容器宿主机进行数据共享； 同一个目录或者文件，可以支持多个容器进行访问，这样其实实现了容器的数据共享和交换； 数据卷是在容器启动是进行初始化的，那么如果容器使用的镜像包含了的数据也会在容器启动时拷贝到容器的数据卷中； 数据卷可以在容器之间共享和重用； 数据卷的修改会立马生效；容器可以对数据卷里的内容直接修改；容器对数据卷进行的修改是及时的，所有的修改都会直接体现在数据卷中； 数据卷的更新不会影响镜像；因为文件不会写到镜像中去，数据卷是独立于联合文件系统的，而镜像本身基于联合文件系统，so镜像与数据卷之间不会有相互影响的情况； 数据卷会一直存在，即使挂载数据卷的容器已经删除因为数据均本质上是宿主机上的一个目录，同时为了提供数据的永久化，它的生存周期与容器是完全隔离的； Docker 容器中的数据操作经过了UFS 的，UFS 会在宿主机中写一次文件，这个文件在宿主机上是临时的，这时候就出现了重复写的情况，会影响系统的性能；此外，删除容器的时候，就没有人能够通过UFS 在访问到宿主机中的文件了； 容器卷可以绕过 UFS 直接操作主机上的文件，当容器删除的时候，宿主机上的文件还在，就在指定的目录下，在重新创建容器的时候们可以指定容器继续读取宿主机上的文件； 创建一个数据卷 包含数据卷挂载的容器在容器关闭时，如果修改了宿主机下的数据卷会，容器里面会产生改变吗？ bind mount 数据卷 使用docker run –name nginx-test -p 8080:80 -d -v ~/myvolume:/usr/share/nginx/html nginx 创建一个bind mount 数据卷 是宿主机的存储位置必须是绝对路径。目录不存在则会生成 12345678# 以下两种情况创建的数据卷如果浏览器访问宿主机的ip:8080 会出现报错，因为这是创建的时候清空了容器数据卷下index.html# 创建的宿主机和容器的数据卷都有读写的权限$ docker run --name nginx-test -p 8080:80 -d -v ~/myvolume:/usr/share/nginx/html nginx# 这样执行后的文件宿主机的~/myvolume 文件如果不存在直接创建，容器的文件路径不存在也会直接创建，如果/usr/share/nginx/html文件存在里面内容会清空# 给容器里面的数据卷加权限$ docker run --name nginx-test -p 8080:80 -d -v ~/myvolume:/usr/share/nginx/html:ro nginx# 如果执行这个 :/usr/share/nginx/html:ro这个地方加的是 :ro 是设置的只有读取权限 123456789101112131415# 运行dockers inspect 容器名称或容器（ID） 是将容器的配置文件已json字符串的形式返回\"Binds\": [ \"/root/myvolume:/usr/share/nginx/html\" # 宿主机数据卷位置: 容器的目录位置 ],\"Mounts\": [ &#123; \"Type\": \"bind\", \"Source\": \"/root/myvolume\", # 是宿主机数据卷的存储位置 \"Destination\": \"/usr/share/nginx/html\", \"Mode\": \"\", \"RW\": true, # 权限 true是可以读写 fales 是只读 \"Propagation\": \"rprivate\" &#125; ], 123# 在宿主机的数据卷下执行:vim index.html # 在文件里写入hello ， 你在访问的时候就可以在页面上看到你写入得数据了 执行 docker exec -it 容器名称（容器ID） bahs进入到容器里面，每个容器都会包含一个迷你版的linux系统 执行 cd /usr/share/nginx/html 执行 ls 你会看到容器目录里会有我们刚才创建好的文件 index.html 执行 cat index.html 可以看到里面我们加入的数据 如果是挂载数据卷的时候加 :ro 容器内修改文件，发现会提示该文件是只读的 docker managed volume 数据卷 创建出来的两个都是有读写权限的 使用docker run –name nginx-test2 -p 8080:80 -d -v /usr/share/nginx/html nginx 创建一个docker managed volume 数据卷 这种命令创建是不用指定宿主机数据卷存储位置的默认在 /var/lib/docker/volumes/ 下的文件名是经过sha256 摘要过的 查看宿主机创建出来的数据卷 123456$ cd /var/lib/docker/volumes/$ ls 8d668720aaeccee44b5fb554571912a6a257eb3a28cecf334203805a0c9b6fd3 #这是自己创建出来的数据卷# 执行 cd _data 进入这这个文件夹里面$ ls50x.html index.html # 这两个文件是把容器里文件给拷贝了出来 可以在宿主机或者容器里面都可以对文件进行读写操作 挂载多个目录 就是执行多个 -v 就可以 容器间挂载 创建数据卷，只要在docker run命令后面跟上-v参数即可创建一个数据卷，当然也可以跟多个-v参数来创建多个数据卷，当创建好带有数据卷的容器后，就可以在其他容器中通过--volumes-from参数来挂载该数据卷了，而不管该容器是否运行。 1docker run -tid --rm --volumes-from nginx-test --name nginx-test3 nginx -i : 以交互模式运行容器，通常与 -t 同时使用； -t : 为容器重新分配一个伪输入终端，通常与 -i 同时使用； -d : 后台运行容器，并返回容器ID； 再创建一个nginx-test4，挂载nginx-test3中从nginx-test挂载的数据卷，当然也可以直接挂载初识的nginx-test容器的数据卷 12* 即使删除了初始的数据卷容器 nginx-test，或者是删除了其他容器，但只要是有容器在使用该数据卷，那么它里面的数据就不会丢失* 命令中的rm表示当容器退出即停止的时候，会自动删除该容器 备份数据卷 创建一个容器container1，包含两个数据卷/usr/share/nginx/html1和/usr/share/nginx/html2（这两个目录是在容器里的数据卷路径） 12345678910$ docker run -tid -v /usr/share/nginx/html1 -v /usr/share/nginx/html2 --name container1nginx # 创建容器container1$ docker exec -it container1 bash #进入创建好的容器里面$ cd html1/ # 进入到html1数据卷中$ echo html1 &gt;&gt; 1.text # 向 1.text 文件中追加数据，文件不存在则会创建文件$ cd html2/ # 进入到html2数据卷中$ echo html2 &gt;&gt; 2.text # 向 2.text 文件中追加数据，文件不存在则会创建文件 接下来进行数据卷的备份操作 使用 - -volumes-from 来创建一个加载 container1 容器卷的容器，并从宿主机挂载当前所在目录到容器的 /backup 目录，容器内会 tar 压缩 /var/colume1 目录下的文件到 /backup/backup1.tar，因为宿主机当前目录已经映射到 /backup 目录了，因此会在宿主机当前目录也存在该压缩包。备份完毕后 -rm 自动删除该创建的容器。 删除数据卷123docker volume ls 列出所有的数据卷docker volume ls --filter dangling=true 过滤不在使用的数据卷docker volume rm [volume name] 删除一个数据卷，容器正在使用的数据卷不能删除，绑定挂载的数据卷无法删除 1docker volume rm my-volio 删除数据卷 my-volio 数据卷 是被设计用来持久化数据的，它的生命周期独立于容器，Docker 不会在容器被删除后自动删除 数据卷，并且也不存在垃圾回收这样的机制来处理没有任何容器引用的 数据卷。如果需要在删除容器的同时移除数据卷。可以在删除容器的时候使用 docker rm -v 这个命令。 无主的数据卷可能会占据很多空间，要清理请使用以下命令 1$ docker volume prune","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://laxe.top/tags/Docker/"}]},{"title":"彻底卸载mysql","slug":"centos7彻底卸载mysql和通过yum安装mysql","date":"2019-12-26T00:24:21.232Z","updated":"2019-12-26T00:29:20.662Z","comments":true,"path":"2019/12/26/centos7彻底卸载mysql和通过yum安装mysql/","link":"","permalink":"http://laxe.top/2019/12/26/centos7彻底卸载mysql和通过yum安装mysql/","excerpt":"查看是否有安装的mysql 12rpm -qa | grep -i mysql // 查看命令1yum list install mysql* // 查看命令2 二选一查看 卸载mysql安装包 1234567yum remove mysql mysql-server mysql-libs compat-mysql51yum remove mysql-community-releaserpm -e --nodeps mysql-community-libs-5.7.22-1.el7.x86_64rpm -e –nodeps mysql57-community-release-el7-11.noarch总之删到通过上面两种命令查不出来任何有关mysql的东西。 删除残留的mysql目录或文件： 123456789101112查询mysql安装目录whereis mysql 或 find / -name mysql删除查询出的目录rm -rf /usr/lib64/mysqlrm -rf /usr/share/mysqlrm -rf /usr/bin/mysqlrm -rf /etc/logrotate.d/mysqlrm -rf /var/lib/mysqlrm -rf /var/lib/mysql/mysql总之删到通过上面两种命令查不出来任何有关mysql的东西。 继续删除 12345678删除mysql 配置文件rm –rf /usr/my.cnfrm -rf /root/.mysql_sercret删除mysql开机自启动服务chkconfig --list | grep -i mysqlchkconfig --del mysqld // 服务名为你设置时候自己设置的名字 至此就卸载干净了","text":"查看是否有安装的mysql 12rpm -qa | grep -i mysql // 查看命令1yum list install mysql* // 查看命令2 二选一查看 卸载mysql安装包 1234567yum remove mysql mysql-server mysql-libs compat-mysql51yum remove mysql-community-releaserpm -e --nodeps mysql-community-libs-5.7.22-1.el7.x86_64rpm -e –nodeps mysql57-community-release-el7-11.noarch总之删到通过上面两种命令查不出来任何有关mysql的东西。 删除残留的mysql目录或文件： 123456789101112查询mysql安装目录whereis mysql 或 find / -name mysql删除查询出的目录rm -rf /usr/lib64/mysqlrm -rf /usr/share/mysqlrm -rf /usr/bin/mysqlrm -rf /etc/logrotate.d/mysqlrm -rf /var/lib/mysqlrm -rf /var/lib/mysql/mysql总之删到通过上面两种命令查不出来任何有关mysql的东西。 继续删除 12345678删除mysql 配置文件rm –rf /usr/my.cnfrm -rf /root/.mysql_sercret删除mysql开机自启动服务chkconfig --list | grep -i mysqlchkconfig --del mysqld // 服务名为你设置时候自己设置的名字 至此就卸载干净了 安装mysql 下载并安装mysql的YUM源： 1234567选择一个目录下载并安装mkdir softcd softwget http://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm // 下载mysql yum源rpm -ivh mysql57-community-release-el7-11.noarch.rpm // 安装yum源 接下在就是正式安装mysql了 1yum install mysql-community-server 启动mysql 12345678910111213141516service mysqld start如果出现以下错误：ERROR 1045 (28000): Access denied for user ‘root’@’localhost’ (using password: NO)首先停止mysql服务service mysqld stop再以不检查权限的方式启动mysqld --skip-grant-tables &amp;又出现以下错误：[ERROR] Fatal error: Please read “Security” section of the manual to find out how to run mysqld as root!执行命令以root权限启动mysqld --user=root --skip-grant-tables &amp; 如果没有报错，登录 mysql ： 123mysql –uroot 如果报错试一下mysql –uroot -p直接回车 设置密码 1234567UPDATE mysql.user SET authentication_string=PASSWORD('密码') where USER='root';ALTER USER 'root'@'localhost' IDENTIFIED BY '密码';SET PASSWORD FOR root=PASSWORD('密码');flush privileges; // 刷新设置立即生效exit // 退出,或者使用 quit 命令 再次进入 12mysql -uroot –p // 会提示输入密码输入密码，成功则密码设置完成了 设置root权限的远程访问 1234567mysql -u root -pvmwaremysql&gt;use mysql;mysql&gt;update user set host = '%' where user = 'root';mysql&gt;flush privileges;mysql&gt;select host, user from user然后就可以通过navicat(或者其他工具)远程连接了","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://laxe.top/tags/MySQL/"}]},{"title":"Django 利用zipstream压缩下载多文件夹","slug":"Django 利用zipstream压缩下载多文件夹","date":"2019-12-26T00:24:12.102Z","updated":"2019-12-26T00:29:48.840Z","comments":true,"path":"2019/12/26/Django 利用zipstream压缩下载多文件夹/","link":"","permalink":"http://laxe.top/2019/12/26/Django 利用zipstream压缩下载多文件夹/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536import zipfileimport osimport zipstreamclass ZipUtilities: zip_file = None def __init__(self): self.zip_file = zipstream.ZipFile(mode='w', compression=zipstream.ZIP_DEFLATED) # 写模式打开二进制压缩文件对象，这个对象是在内存中的而不是在磁盘上的 # 第一个参数写模式 第二个参数写压缩格式 def toZip(self, file, name): if os.path.isfile(file): # 判断是否是文件 self.zip_file.write(file, arcname=os.path.basename(file)) # 将文件加入加入压缩文件对象里 else: # 此处判断到非文件对象 用添加目录方式添加到压缩文件 self.addFolderToZip(file, name) def addFolderToZip(self, folder, name): for file in os.listdir(folder): # 遍历目录下所有文件 full_path = os.path.join(folder, file) # 拼接绝对路径 if os.path.isfile(full_path): # 如果从目录下取出来的是文件 self.zip_file.write(full_path, arcname=os.path.join(name, os.path.basename(full_path))) # 将文件加入加入压缩文件对象里 elif os.path.isdir(full_path): # 如果从目录下取出来的是目录递归调用本函数 self.addFolderToZip(full_path, os.path.join(name, os.path.basename(full_path))) def close(self): if self.zip_file: self.zip_file.close()","categories":[],"tags":[{"name":"Django","slug":"Django","permalink":"http://laxe.top/tags/Django/"}]},{"title":"【压力测试】使用mysqlslap进行mysql基准测试","slug":"【压力测试】使用mysqlslap进行mysql基准测试","date":"2019-12-26T00:22:22.344Z","updated":"2019-12-26T00:28:54.723Z","comments":true,"path":"2019/12/26/【压力测试】使用mysqlslap进行mysql基准测试/","link":"","permalink":"http://laxe.top/2019/12/26/【压力测试】使用mysqlslap进行mysql基准测试/","excerpt":"为什么要进行压力测试？PS：在运维工作中，压力测试是一项很重要的工作。比如在一个网站上线之前，能承受多大访问量、在大访问量情况下性能怎样，这些数据指标好坏将会直接影响用户体验。但是，在压力测试中存在一个共性，那就是压力测试的结果与实际负载结果不会完全相同，就算压力测试工作做的再好，也不能保证100%和线上性能指标相同。面对这些问题，我们只能尽量去想方设法去模拟。所以，压力测试非常有必要，有了这些数据，我们就能对自己做维护的平台做到心中有数。","text":"为什么要进行压力测试？PS：在运维工作中，压力测试是一项很重要的工作。比如在一个网站上线之前，能承受多大访问量、在大访问量情况下性能怎样，这些数据指标好坏将会直接影响用户体验。但是，在压力测试中存在一个共性，那就是压力测试的结果与实际负载结果不会完全相同，就算压力测试工作做的再好，也不能保证100%和线上性能指标相同。面对这些问题，我们只能尽量去想方设法去模拟。所以，压力测试非常有必要，有了这些数据，我们就能对自己做维护的平台做到心中有数。 压力测试考察当前软硬件环境下系统所能承受的最大负荷并帮助找出系统瓶颈所在。压测都是为了系统在线上的处理能力和稳定性维持在一个标准范围内，做到心中有数。 一、应用场景1、对新的或调整后的数据库服务器进行测试，验证或比较配置结果；2、建立Mysql服务器的性能基准线，即得到健康环境下的指标，协助后续实际使用中的监控、优化；3、模拟多用户并发访问MySQL来进行压力测试，找出系统的扩张瓶颈，增加数据库的并发，观察QPS、TPS变化，确定并发量与性能最优的关系；4、对比多个存储引擎（MyISAM，InnoDB等）在相同环境下的相同并发压力下的性能差别。 二、测试计划1、确定测试工具，根据测试目标和业务制定测试计划、测试场景、测试命令；2、使用生产环境的数据库备份，根据测试用例进行测试；3、分析测试结果。 三、简介mysqlslapmysqlslap是版本高于5.1的mysql自带的工具。 【参数说明】-a//若命令中没通过语句或文件提供SQL表和数据，则将自动创建SQL表和数据 –auto-generate-sql-add-autoincrement//给自动创建的表添加一个auto_increment列 –auto-generate-sql-execute-number=N//对每个模拟用户的自动生成N次查询 –auto-generate-sql-guid-primary//给自动创建的表添加基于GUID的主键 –auto-generate-sql-load-type=name//指定测试语句类型：mixed（查询与插入对半）,update（更新主键）,write（插入）,key（读主键）或read（查询），默认为mixed –auto-generate-sql-secondary-indexes=N//给自动创建的表增加N个二级索引，默认为0 –auto-generate-sql-unique-query-number=N//指定自动创建的表中不同查询的数量 –auto-generate-sql-unique-write-number=N//指定自动创建的表中不同插入的数量 –auto-generate-sql-write-number=N//自动创建的表中，对每个线程插入N行数据（默认N为100） –commit=N//每N条DML提交一次（即一次事务） -C，–compress//若server和client的协议都支持压缩，则压缩信息后传送 -c N,–concurrency-name/模拟N个用户并发执行查询 –create=”字符串或.sql文件路径”//指定用来创建表的字符串或 .sql文件 –create-schema=”数据库名”指定测试用的数据库（mysql中的database就是schema） -#，–debug–debug-check-T,–debug-info //输出CPU以及内存的相关信息【遇到 [Error]mysqlslap：option ‘…’ used,but is disabled，暂时无法解决】 -F,–delimiter=name此参数指定的值作为sql语句中使用的分隔符 –detach=N每执行完N条请求，就断开重连一次 -e,–engine=name指定测试表使用的存储引擎 -h,–host=name连接指定host -i,–iterations=N指定测试迭代次数 -x,–number-char-cols=N指定自动创建的表中含N个char类型的字段，默认值为1 -y,–number-int-cols=N指定自动创建的表中含N个int类型的字段，默认值为1 –number-of-queries=N生成N次总查询（平均每个用户查询次数=总查询次数/并发数） –only-print不实际执行，打印模拟执行的过程 -u,–user=name连接server用的用户名 -p,–password[=name]连接server用的密码，参数与值之间没有空格，如-p123 -P，–port=端口号指定连接server的端口 –post（/pre）-query=name指定测试完成后（/前）执行的含sql语句的字符串或.sql文件 –post（/pre）-system=name指定测试完成后（/前）执行的系统语句 –protocol=name指定用来连接的协议：tcp,socket,pipe,memory -q “查询语句或包含查询语句的sql文件”,–query=”查询语句或包含查询语句的sql文件”自定义要运行的查询语句 –defaults-file=”配置文件路径”指定.cnf配置文件 【注意】不用-a自动生成数据表或自定义指定，就会报1049 error；命令行中，参数–number-of-queries=N（N为总查询次数）和–auto-generate-sql-execute-number=N（N为每个并发的查询次数）只能存在1个。 常用参数 -a 若命令中没通过语句或文件提供SQL表和数据，则将自动创建SQL表和数据 –concurrency：代表并发数量，多个用逗号隔开，concurrency=10,50,100, 并发连接线程数分别是10、50、100个并发–engines：代表要测试的引擎，可以有多个，用分隔符隔开–iterations：代表要运行这些测试多少次–commit=N：执行N条DML后提交一次–auto-generate-sql：代表用系统自己生成的SQL脚本来测试–auto-generate-sql-load-type：代表要测试的是读还是写还是两者混合的（read,write,update,mixed） –number-of-queries：代表总共要运行多少次查询。每个客户运行的查询数量可以用查询总数/并发数来计算–debug-info：代表要额外输出CPU以及内存的相关信息–number-int-cols ：创建测试表的 int 型字段数量–auto-generate-sql-add-autoincrement ：代表对生成的表自动添加auto_increment列，从5.1.18版本开始–number-char-cols：创建测试表的 char 型字段数量–create-schema：测试的schema，MySQL中schema也就是database–query：使用自定义脚本执行测试，例如可以调用自定义的一个存储过程或者sql语句来执行测试–only-print：如果只想打印看看SQL语句是什么，可以用这个选项 四、测试执行：一些栗子1）指定数据库‘test’，自定义sql语句，模拟50个并发用户进行测试： 1mysqlslap -uroot -p000000 -c 50 --create-schema=wzw -q \"select * from wzwapp_user;\" 2) 自动设置默认查询语句 mysqlslap -uroot -p -a --concurrency=200 --number-of-queries=10000 当我加大查询量的时候出现下面的错误 mysqlslap: Error when connecting to server: 1040 Too many connections 参考https://www.cnblogs.com/phpper/p/9570792.html 解决步骤： 可能是如下两种情况 一.查看系统最大限制# ulimit -n 系统的/etc/security/limits.conf 这里面的限制，把限制增大就可以了，前提不能超过系统的最大限制cat /proc/sys/fs/file-max 二。mysql&gt; show variables like ‘%connections%’; 临时修改变量（重启mysql后失效，永久的话请修改my.cnf增加max_connections = 100000） mysql&gt; set global max_connections=100000; 五，mysql优化技巧查看mysql存储引擎：show variables like ‘%storage_engine%’; ​ https://www.cnblogs.com/sharpest/p/10390035.html ​ https://blog.csdn.net/skiwnc/article/details/87351038","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://laxe.top/tags/MySQL/"}]},{"title":"Ansible-PlayBook","slug":"Ansible-PlayBook","date":"2019-12-10T08:28:11.421Z","updated":"2019-12-10T08:28:52.941Z","comments":true,"path":"2019/12/10/Ansible-PlayBook/","link":"","permalink":"http://laxe.top/2019/12/10/Ansible-PlayBook/","excerpt":"ansible-playbook 在之前的ansible使用中，我们都是通过命令行的形式实现对应远程主机的响应管理 但这样的工作方式功能上来说还是有一定的局限性，并且维护并不方便，引入playbook可以更加方便我们对于功能的编写维护，并且具有良好的灵活性 playbook也可以理解为命令行功能的一个合集脚本，用来编写更加复杂的业务","text":"ansible-playbook 在之前的ansible使用中，我们都是通过命令行的形式实现对应远程主机的响应管理 但这样的工作方式功能上来说还是有一定的局限性，并且维护并不方便，引入playbook可以更加方便我们对于功能的编写维护，并且具有良好的灵活性 playbook也可以理解为命令行功能的一个合集脚本，用来编写更加复杂的业务 yaml语法 Yaml为通用数据串行化格式语法，简洁而强大 ansible中的配置文件就采用了Yaml格式语法存在，以下就是对Yaml语法的介绍 1yaml 基本语法规则如下 大小写敏感 使用缩进表示层级关系 缩进的空格数目不唯一，只要相同层级元素左侧对齐即可 #号表示注释 1yaml 语法支持的数据结构有三种： 键值对：相当于hash表映射关系，字典 序列：相当于数组或列表 纯量（标量）：单独的值，无法继续拆分，比如字符串、整数、浮点数、Null、布尔值（true、false） 字符串 字符串定义时，默认可以不使用引号标注 12str_1: abc&#123;'str_1': 'abc',&#125; # 对应Python中数据类型 如字符串中出现特殊字符或包含空格，需要使用引号标注 12str_2: 'abc: bbb'&#123;'str_2': 'abc: bbb'&#125; # 对应Python中数据类型 双引号不会对字符串中特殊字符进行转义 123str_3: 'abc: \\n bbb'str_4: \"abc: \\n bbb\"&#123;'abc: \\\\n bbb', 'str_4': 'abc: \\n bbb'&#125; # 对应Python中数据类型 单引号字符串还有引号，需要使用两个单引号进行转义 12str_5: 'a''b'&#123;'str_5': \"a'b\"&#125; # 对应Python中数据类型 当字符串需要换行时，从第二行开始的下面几行，需要有对齐缩进，换行会被解释为空格，其余缩进前空格会忽略 12345str_6: 'abc aaa bbb ccc'&#123;'str_6': 'abc aaa bbb ccc'&#125; # 对应Python中数据类型 多行字符串可以使用 |保留换行符形成段落，或使用&gt;将换行符替换为空格 12345678str_7: &gt; bbb aaastr_8: | bbb aaa&#123;'str_7': 'bbb aaa\\n', 'str_8': 'bbb\\naaa\\n'&#125; # 对应Python中数据类型 +表示保留字符串末位的换行，-表示删除字符串末位的换行 123456str_9: |+ aaabbbstr_10: |- aaabbb'str_9': 'aaabbb\\n', 'str_10': 'aaabbb'&#125; # 对应Python中数据类型 键值对 Yaml中的键值对数据通过冒号定义，冒号后的数据与冒号之间存在一个空格 123456dict_1: adict_2: &#123; 1 : a &#125;dict_3: a: 1 b: 2&#123;'dict_1': 'a', 'dict_2': &#123;1: 'a'&#125;, 'dict_3': &#123;'a': 1, 'b': 2&#125;&#125; # 对应Python中数据类型 序列123456- list_1- list_2- - a_1 - a_2['list_1', 'list_2', ['a_1', 'a_2']] # 对应Python中数据类型 数据嵌套使用1234567- test_1: - a - b- test_2: var_1: true var_2: 0.2[&#123;'test_1': ['a', 'b']&#125;, &#123;'test_2': &#123;'var_1': True, 'var_2': 0.2&#125;&#125;] # 对应Python中数据类型 playbook playbook的编写使用yaml语法规则，先来看一下最简单的playbook 12345678---- hosts: all remote_user: root tasks: - name: Yum Install Apache yum: name=httpd state=installed - name: Start Apache Server service: name=httpd state=started 第一行：---指明Ymal将文件解释为正确的文档的要求，Yaml允许可以有多个文档同时出现在一个文件里，每个文档之间由---进行分割，目前我们的playbook中只需要有一个文档即可 第二行：hosts指明当前playbook将要操作的目标主机有哪些，这里我们选择全部 第三行：remote_user指明当前操作所使用的远程主机用户 第四行：tasks为任务列表，playbook将按照从上到下的定义顺序执行其中的模块对应的操作，name属性为一个字符串用以标示当前任务的介绍，第一个任务将使用yum模块安装apache服务，第二个任务使用ansible模块service，使httpd服务启动 执行playbook使用ansible-playbook 1ansible-playbook /etc/ansible/playbook.yml 包含 当遇到较为复杂的情况时，单独的playbook可能无法应对业务需求，那么可能需要编写多个playbook 这时，如果在playbook中的handlers或tasks可能在多个playbook中重复使用，就可以通过ansible所提供的include功能，将复用的部分单独写成一个文件，在需要的地方include包含进来即可 比如有这样的一个功能是需要多次复用的，这个文件叫做tasks.yaml 123--- - name: Yum Install Nginx yum: name=nginx state=installed 那么在一个主要playbook文件中可以这样引入 1234---- hosts: all tasks: - include: tasks.yml 执行该playbook 1ansible-playbook /etc/ansible/playbook.yml include包含的其他playbook支持模板变量，可以通过定义vars变量覆盖，或者像这样 123---- name: Yum Install Nginx yum: name=&#123;&#123; server_name &#125;&#125; state=installed playbook文件 123- hosts: all tasks: - include: tasks.yml server_name=nginx 此外在1.4及以上版本中，还支持字典、列表形式的参数传递 1234567---- name: Yum Install Nginx yum: name=&#123;&#123; server_name &#125;&#125; state=installed---- hosts: all tasks: - &#123; include: tasks.yml, server_name: nginx &#125; 角色 除去通过include功能将不同的任务分别写入不同的文件，然后按需include包含进来，在ansible中还有一种标准规范叫做role角色 通过不同级别的层级目录和文件来对变量、任务、配置模板等进行拆分管理，提高扩展性和可维护性 一般来说，一个role角色定义目录结构如下 1234567role_name/ # 角色名目录，playbook调用时需要 file/ # 存放copy或script等模块调用文件 tasks/ # 存放各种task任务，需要包含一个main.yml handlers/ # 存放各种handlers任务，需要包含一个main.yml vars/ # 存放定义好的变量，需要包含一个main.yml templates/ # 存放需要使用到的配置模板 meta/ # 当前角色的特殊设定及其依赖，需要包含一个main.yml 角色目录存放的路径可以在ansible的配置文件中定义 12# /etc/ansible/ansible.cfgroles_path = /etc/ansible/roles 示例目录结构 任务tasks目录下main文件内容 123456# tasks/main.yml- name: Install Apache Server yum: name=httpd state=installed- name: Write Apache Config template: src=httpd.j2 dest=/etc/httpd/conf/httpd.conf notify: Restart Apache Server handlers目录下main文件内容 123# handlers/main.yml- name: Restart Apache Server service: name=httpd state=restarted templates下配置模板 123# templates/httpd.j2#上面内容太多省略，只保留模板变量部分Listen &#123;&#123; listen_port &#125;&#125; 变量vars目录下main文件 12# vars/main.ymllisten_port: 8000 调用role的playbook文件内容 1234- hosts: all remote_user: root roles: - apache 在执行角色role此处为apache任务时，会将文件夹下的main.yml文件自动导入合并，执行结果如下","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://laxe.top/tags/Linux/"}]},{"title":"Ansible","slug":"Ansible","date":"2019-11-28T07:37:10.939Z","updated":"2019-11-28T07:38:11.648Z","comments":true,"path":"2019/11/28/Ansible/","link":"","permalink":"http://laxe.top/2019/11/28/Ansible/","excerpt":"Ansible ansible基于Python开发，集合了众多运维工具（puppet、cfengine、chef、func、fabric）的优点，实现了批量系统配置、批量程序部署、批量运行命令等功能 在使用时，ansible不需要在被控端安装客户端，ansible工作基于ssh，只要被控端服务器有ssh服务，加上一个Python环境，就可以使用ansible 另外，ansible在15年的时候，以1.5亿美元被RedHat公司收购，新版的RedHat操作系统内置ansible软件，很厉害的","text":"Ansible ansible基于Python开发，集合了众多运维工具（puppet、cfengine、chef、func、fabric）的优点，实现了批量系统配置、批量程序部署、批量运行命令等功能 在使用时，ansible不需要在被控端安装客户端，ansible工作基于ssh，只要被控端服务器有ssh服务，加上一个Python环境，就可以使用ansible 另外，ansible在15年的时候，以1.5亿美元被RedHat公司收购，新版的RedHat操作系统内置ansible软件，很厉害的 Ansible部署 ansible安装可以通过源码，yum源以及python所提供的pip管理工具进行安装 使用pip管理工具进行安装 1pip3 install ansible 使用yum进行安装 12yum install epel-release # 安装扩展源yum install ansible Ansible配置 安装之后，默认ansible工具的配置文件在/etc/ansible下 如果通过pip命令安装，是没有这个目录的，需要我们手动创建，其中所需主要配置文件如下 ansible.cfg：ansible主配置文件 hosts：被管理主机IP或者主机名列表文件，也是比较重要的一个文件 roles：角色或插件目录（默认为空） 此外除了默认的ansible的配置文件路径，关于ansible的配置文件路径选择还有如下几种，按照顺序表示优先级 export ANSIBLE_CONFI：指定的全局变量 ./ansible.cfg：当前目录下的配置文件 ~/.ansible.cfg：当前用户目录下的配置文件 /etc/ansible/ansible.cfg：etc目录下的配置文件 如果以上四个路径下均没有cfg配置文件，则使用默认配置 如果通过源进行安装，那么在/etc/ansible/目录下会自动包含ansible.cfg文件 也可以通过访问在线的配置文件地址进行获取 https://raw.githubusercontent.com/ansible/ansible/devel/examples/ansible.cfg ansible配置文件中可以进行ansible的各项参数的设置，包括并发线程数量、用户、模块路径、调优等等 defaluts：默认的配置项，一般不需要修改 privilege_escalation：执行命令的用户权限设置 paramiko_connection：paramiko插件设置 ssh_connection：ssh连接设置 默认ansible使用hosts文件列举监控主机，格式为ini，可以进行IP的分组以及IP规则设置，比如如下的例子 12[webserver]192.168.1.101:22 ansible支持很多模块来进行对被控主机的管理，包括：command、shell、script、yum、copy、File、async、docker、cron、mysql_user、ping、sysctl、user、acl、add_host、easy_install、haproxy等。默认在执行命令时，使用模块为command，接下里会进行介绍 Ansible使用参数 ansible在工作时，需要使用我们安装好的ansible来执行命令 经常在使用ansible模块进行工作时，可能还需要额外提供一些参数来辅助工作，下面是常用参数 命令参数 解释 -v 打印详细信息 -m 指定使用的模块，默认为command模块 -k 要求输入远程主机密码 -a 将参数或命令传入模块 -C 测试执行过程，但不真正执行 -sudo 基于sudo用户执行 --list-hosts 列举命令生效的主机 -l 限制匹配规则的主机数 -i 指定hosts文件路径 -u SSH连接所使用用户 现在看到这些命令参数你可能有一些蒙蔽，不过不要着急，结合模块使用，你将很快了解这些参数的实际意义 配置免密登陆 由于ansible是通过ssh服务进行命令下达执行，那避免不了用户认证 但是在批量执行时，多次的重复认证会导致我们的效率及其低下，这里可以通过配置主控端与被控端主机之间SSH免密登陆来实现用户认证的跳过，可谓是一次配置，轻松很久呐 在主控服务器192.168.1.104下生成秘钥 12ssh-keygen -t rsa #-t指定加密的方式，默认为rsa 进行秘钥的分发 1ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.1.101 输入对应远程主机的ssh账号密码之后，接下来在主控服务器就可以不进行SSH的用户认证也可以访问到被控端，这里测试主机为192.168.1.104（主控），192.168.1.101（被控） 定义主机及组规则 ansible通过定义好的主机与组规则(Inventory)在执行命令时通过匹配进行远程操作 这个文件默认就是我们上面所说的/etc/ansible/hosts文件，其中定义的几种方式如下 直接将IP写入 1192.168.1.101 规则分组 123[webserver]192.168.1.101:2333www.example.com 可以在规则的IP后指定端口 规则命名 123myhost ansible_ssh_host=192.168.1.101[webservers]myhost 在使用时，直接利用myhost即可 除去示例中的指定方式，还有如下一些参数可以利用 ansible_ssh_host：目标主机地址 ansible_ssh_port：目标主机ssh服务端口 ansible_ssh_user：目标主机ssh登录用户 ansible_ssh_pass：目标主机ssh登录密码 ansible_connection：连接类型：local、ssh、paramiko ansible_ssh_priveate_key_file：连接所需ssh私钥文件； ansible_shell_type：目标主机的shell类型：ash、bash（默认使用的shell，可以结合help查看帮助文档）、ksh（支持42个内部命令）、csh、zsh（最庞大的shell，支持84个内部命令） 正则规则 123[webservers][a:z]bc.example.com192.168.1.10[1:5] 在主机处填写对应的正则规则，可以更加方便的映射某个网段下的ip地址 Ping模块 ping模块可以判断被控主机是否在线， 返回值为changed和ping 首先在/etc/ansible/hosts文件下添加被控主机，并建立分组为webservers 12[webservers]192.168.1.101:22 ping命令的用法，要进入到python安装目录下，找到对应的ansible可执行文件 1./ansible all -m ping 返回值ping如果为pong则代表可以ping通 ansible命令行第二个参数可以是一个主机的正则规则，all代表所有hosts文件下IP，也可以指定使用某个分组 1./ansible webservers -m ping Command模块 通过ansible执行命令时，默认使用command模块，该模块主要用于执行linux基础命令 注意：对比之后的Shell及Script功能模块，Command模块不支持管道 command支持的额外参数 12./ansible-doc -s command# 文档 参数 解释 chdir 执行命令时，先进入到该目录下 creates 给定文件存在时，不执行该命令 free_form 需要执行的脚本 removes 给定文件存在，则执行该命令 对远程主机执行命令 1./ansible webservers -m command -a \"ifconfig\" 执行命令时更改工作目录 1./ansible webservers -m command -a \"ls chdir=/home/\" Shell模块 shell使用远程主机下的/bin/sh进行命令执行，支持比command模块更多的命令，常用参数如下 12./ansible-doc -s shell# 文档 额外参数 参数 解释 chdir 执行命令时，先进入到该目录下 creates 给定文件存在时，不执行该命令 free_form 需要执行的脚本 removes 给定文件存在，则执行该命令 executable 更换执行命令所使用的shell环境 远程主机编写sh脚本，向屏幕输出hello 1echo \"hello\" 执行远程主机的shell脚本 1./ansible webservers -m shell -a \"sh ~/test.sh\" Script模块 该模块可以方便运行当前管理机上的脚本直接到远程被控端，而不需要先将脚本拷贝到远程主机后在执行 在主控制home目录下创建sh脚本 1echo \"this is Control\" 将这个sh脚本通过script模块执行到远程被控端 1./ansible webservers -m script -a \"/root/test.sh\" Copy模块 copy模块可以方便的将当前主机下文件拷贝到远程主机，类似scp命令等 12./ansible-doc -s copy# 文档地址 支持的参数 参数 解释 src 将本地路径复制到远程服务器; 可以是绝对路径或相对的。如果是一个目录，它将被递归地复制。如果路径以/结尾，则只有该目录下内容被复制到目的地，如果没有使用/来结尾，则包含目录在内的整个内容全部复制 content 当用content代替src参数的时候，可以把文档的内容设置到特定的值 dest 目标绝对路径。如果src是一个目录，dest也必须是一个目录。如果dest是不存在的路径，并且如果dest以/结尾或者src是目录，则dest被创建。如果src和dest是文件，如果dest的父目录不存在，任务将失败 backup 如果文件修改，则在覆盖之前将原文件备份，备份文件包含时间信息 directory_mode 设定目录的权限，在新建时使用，不会影响已存在的目录 force 当目标内容不同于源时，将替换远程文件。设置为no时，只有在目标文件不存在的情况下才会传输文件 group 设置文件/目录的所属组 mode 设置文件权限 owner 设置文件/目录的所属用户 Copy前备份1./ansible all -m copy -a \"src=/root/ansible_copy_file backup=yes dest=/home/\" 在第一次拷贝时，由于目标主机还并没有这个文件， 备份动作不生效 在对文件内容进行修改后重新执行该命令拷贝文件 此时目标主机下，不光会有我们上传的拷贝文件，还有之前文件的一个备份 覆盖内容 直接通过content参数指定内容，并对目标主机上已存在的test_copy文件进行覆盖 1./ansible all -m copy -a \"content='这是命令修改\\n' dest=/home/test_copy\" 这条命令将会把远程主机home目录下的test_copy文件覆盖为我们的content内容 Stat模块 该模块可以获取远程主机下的文件信息，需要使用path参数指明文件路径 1./ansible all -m stat -a \"path=/home/test_copy\" Yum模块 该模块可以对远程主机上的软件安装、卸载进行管理 12./ansible-doc -s copy# 文档 支持参数 参数 解释 name 必须参数，用于指定需要管理的软件包，比如nginx state 用于指定软件包的状态，默认值为present，表示确保软件包已经安装 除了present，其他可用值有installed、latest、absent、removed 其中installed与present等效，latest表示安装yum中最新的版本，absent和removed等效，表示删除对应的软件包 在远程主机下安装nginx 1./ansible all -m yum -a \"name=nginx state=installed\" 查看nginx服务状态 1systemctl status nginx Service模块 该模块主要用于远程服务器上对应的服务管理，比如开启或关闭apache服务等 12./ansible-doc -s yum# 文档 支持参数 参数 解释 name 需要管理的服务名称，如nginx state 此参数用于指定服务的状态 比如，我们想要启动远程主机中的nginx，则可以将state的值设置为started 如果想要停止远程主机中的服务，则可以将state的值设置为stopped 此参数的可用值有started、stopped、restarted、reloaded enabled 此参数用于指定是否将服务设置为开机启动项，设置为yes表示将对应服务设置为开机启动，设置为no表示不会开机启动 将远程主机下的httpd服务开启 1./ansible all -m service -a \"name=httpd state=started\" File模块 file模块可以帮助我们完成一些对文件的基本操作 比如，创建文件或目录、删除文件或目录、修改文件权限等 12./ansible-doc -s yum# 文档 支持参数 参数 解释 path 指明需要操作的文件或目录路径 state 此参数非常灵活，其对应的值需要根据情况设定。比如，我们想要在远程主机上创建/testdir/a/b目录，那么则需要设置path=/testdir/a/b，但是，我们无法从/testdir/a/b这个路径看出b是一个文件还是一个目录，ansible也同样无法单单从一个字符串就知道你要创建文件还是目录，所以，我们需要通过state参数进行说明 当我们想要创建的/testdir/a/b是一个目录时，需要将state的值设置为directory，directory为目录之意，当它与path结合，ansible就能知道我们要操作的目标是一个目录 当我们想要操作的/testdir/a/b是一个文件时，则需要将state的值设置为touch 当我们想要创建软链接文件时，需将state设置为link；想要创建硬链接文件时，需要将state设置为hard 当我们想要删除一个文件时（删除时不用区分目标是文件、目录、还是链接），则需要将state的值设置为absent，absent为缺席之意，当我们想让操作的目标”缺席”时，就表示我们想要删除目标 src src参数：当state设置为link或者hard时，表示我们想要创建一个软链或者硬链 所以，我们必须指明软链或硬链链接的哪个文件，通过src参数即可指定链接源 force 当state=link的时候，可配合此参数强制创建链接文件，当force=yes时，表示强制创建链接文件。不过强制创建链接文件分为三种情况 情况一：当要创建的链接文件指向的源文件并不存在时，使用此参数，可以先强制创建出链接文件 情况二：当要创建链接文件的目录中已经存在与链接文件同名的文件时，将force设置为yes，会将同名文件覆盖为链接文件，相当于删除同名文件，创建链接文件 情况三：当要创建链接文件的目录中已经存在与链接文件同名的文件，并且链接文件指向的源文件也不存在，这时会强制替换同名文件为链接文件 owner 指定文件所属用户 group 指定文件所属组 mode 指定文件权限 将远程主机下的Python3创建软连接到home目录 1./ansible all -m file -a \"path=/home/python3 state=link src=/usr/local/python3/bin/python3\"","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://laxe.top/tags/Linux/"}]},{"title":"Redis常见数据类型及其操作指令","slug":"Redis常见数据类型及其操作指令","date":"2019-10-21T03:37:03.489Z","updated":"2019-12-26T00:33:34.500Z","comments":true,"path":"2019/10/21/Redis常见数据类型及其操作指令/","link":"","permalink":"http://laxe.top/2019/10/21/Redis常见数据类型及其操作指令/","excerpt":"Redis Redis可以存储键体与五种不同数据结构类型类型之间的映射 分别为STRING字符串、LIST列表、SET集合、HASH散列和ZSET有序集合 Redis客户端 1redis-cli 如需支持中文展示，可以使用参数","text":"Redis Redis可以存储键体与五种不同数据结构类型类型之间的映射 分别为STRING字符串、LIST列表、SET集合、HASH散列和ZSET有序集合 Redis客户端 1redis-cli 如需支持中文展示，可以使用参数 1redis-cli --raw 字符串（STRING） redis中的字符串与很多语言中的字符串非常相似 字符串可以存储：字节串byte string、整数、浮点数 常见指令 指令 解释 GET 获取存储在给定键中的值 SET 设置存储在给定键中的值 DEL 删除存储在给定键中的值 123456127.0.0.1:6379&gt; set name 张三OK127.0.0.1:6379&gt; get name张三127.0.0.1:6379&gt; del name1 列表（LIST） 一个列表结构可以有序的存储多个字符串 常见指令、 指令 解释 LPUSH/RPUSH 将给定的值推入列表的左/右端 LPOP/RPOP 从列表的左/右端弹出一个值并返回 LRANGE 获取列表在给定范围内的值 LINDEX 获取列表在某个给定位置上的值 12345678910127.0.0.1:6379&gt; rpush l a1127.0.0.1:6379&gt; rpush l b2127.0.0.1:6379&gt; rpush l c3127.0.0.1:6379&gt; lrange l 0 -1abc rpush，是从列表的右侧推入数据，类似栈，后进入的数据在列表的头部 12345678910127.0.0.1:6379&gt; lpush l1 a1127.0.0.1:6379&gt; lpush l1 b2127.0.0.1:6379&gt; lpush l1 c3127.0.0.1:6379&gt; lrange l1 0 -1cba lpush，是从列表的左侧推入数据，类似队列，先进的在头部 123456789101112127.0.0.1:6379&gt; lpush l1 a1127.0.0.1:6379&gt; lpush l1 b2127.0.0.1:6379&gt; lpush l1 c3127.0.0.1:6379&gt; lrange l1 0 -1cba127.0.0.1:6379&gt; lindex l1 2a 集合（SET） Redis的集合和列表都可以存储多个字符串，但是不同在于列表可以存储多个相同的值，而集合中的数据元素是唯一的，这是由于集合通过散列表来进行维护（这些散列表只有键Key，没有与之相关的值Value） 此外，redis中的结合是无序的，所以不能像列表一样的数据可以在某一端推入数据 指令 解释 SADD 将给定的元素添加到集合 SMEMBERS 返回集合中包含的所有元素 SISMEMBER 检查某元素是否包含在集合中 SREM 如果元素存在与集合，那么移出该元素 注意：如果集合中包含的元素太多，那么SMEMBERS指令的处理可能会非常慢，慎用 123456789101112131415161718192021127.0.0.1:6379&gt; sadd s 11127.0.0.1:6379&gt; sadd s 21127.0.0.1:6379&gt; sadd s 31127.0.0.1:6379&gt; smembers s123127.0.0.1:6379&gt; sismember s 21127.0.0.1:6379&gt; sismember s a0127.0.0.1:6379&gt; srem s a0127.0.0.1:6379&gt; srem s 11127.0.0.1:6379&gt; smembers s23 一般情况下，命令的执行如果成功，那么将会返回对应操作生效的个数，比如：1，反之则返回0 散列（HASH） 散列可以存储多个键值对映射；散列存储的值可以是字符串、也可以是数字值 美妙的是，散列可以支持用户对其中存储的数字值进行自增或自减的操作 人们经常这样形容散列：这就像一个微缩版的Key-Value数据库，一个微缩版的Redis 指令 解释 HSET 在散列里面添加给定的键值对 HGET 获取指定兼职对的值 HGETALL 获取散列包含的所有键值对 HDEL 如果给定的键存在与散列中，那么将其删除 1234567891011127.0.0.1:6379&gt; hset h k1 v11127.0.0.1:6379&gt; hset h k2 v21127.0.0.1:6379&gt; hget h k1v1127.0.0.1:6379&gt; hdel h k11127.0.0.1:6379&gt; hgetall hk2v2 hgetall获取到的结果是竖着排列，两个为一组键值对 有序集合（ZSET） 有序集合和散列一样，都用于存储键值对 有序集合的键key是成员，在一个有序集合中，只能有一个不同的成员 有序集合的值是value被称为分值score，分值为一个浮点数类型， 有序集合通过分值对键值对进行排序 基于时间衰减的商品热度值计算 指令 解释 ZADD 将一个带有分值的成员添加到有序集合中 ZRANGE 根据元素在有序排列中所处的位置，从有序集合中获取多个元素，类似lrange ZRANGEBYSCORE 获取有序集合中在给定分值范围内的成员 ZREM 如果给定成员存在与有序集合中，那么移出这个成员 1234567891011121314151617181920212223242526127.0.0.1:6379&gt; ZADD z 5 first(integer) 1127.0.0.1:6379&gt; ZADD z 3 second(integer) 1127.0.0.1:6379&gt; ZRANGE z 0 -11) \"second\"2) \"first\"127.0.0.1:6379&gt; ZRANGE z 0 -1 withscores1) \"second\"2) \"3\"3) \"first\"4) \"5\"127.0.0.1:6379&gt; ZADD z 4.5 third(integer) 1127.0.0.1:6379&gt; ZRANGE z 0 -1 withscores1) \"second\"2) \"3\"3) \"third\"4) \"4.5\"5) \"first\"6) \"5\"127.0.0.1:6379&gt; zrem z third(integer) 1127.0.0.1:6379&gt; ZRANGE z 0 -1 1) \"second\"2) \"first\" 字符串其他操作自增、自减 当一个值被存入Redis时，如果这个值可以被解释成十进制或者浮点数，那么Redis会检测到这一属性 并允许用户可以对这样的值进行自增和自减操作 指令 解释 INCR 将键存储的值增长1 DECR 将键存储的值减去1 INCRBY 将键存储的值加上整数 DECRBY 将键存储的值减去整数 INCRBYFLOAT 将键存储的值加上浮点数（传递负值即为减去）、在redis2.6及以上版本可用 12345678910127.0.0.1:6379&gt; set age 1OK127.0.0.1:6379&gt; incr age(integer) 2127.0.0.1:6379&gt; get age\"2\"127.0.0.1:6379&gt; decr age (integer) 1127.0.0.1:6379&gt; get age \"1\" 在Python的代码中，只需要使用incr即可包含incrby的功能 12345678910127.0.0.1:6379&gt; incrby age 10(integer) 11127.0.0.1:6379&gt; get age \"11\"127.0.0.1:6379&gt; decrby age 5(integer) 6127.0.0.1:6379&gt; get age \"6\"127.0.0.1:6379&gt; incrbyfloat age -2.5\"3.5\" 子串 像python的切片操作一样，Redis中的字符串也支持对某个范围进行操作 指令 解释 APPEND 将一个值追加到给定字符串的末尾 GETRANGE 给定起点、终点，获取该范围内所有的字符组成的子串，包括起点重点，左闭右闭 SETRANGE 将字符串从某个偏移量开始设置成给定的值 123456127.0.0.1:6379&gt; set name abcOK127.0.0.1:6379&gt; append name aaa(integer) 6127.0.0.1:6379&gt; get name \"abcaaa\" 现在版本的getrange是由老版本的substr函数改名而来，如果使用2.6版本以上的redis，建议使用getrange 1234567891011127.0.0.1:6379&gt; getrange name 2 4\"caa\"127.0.0.1:6379&gt; substr name 2 4\"caa\"# 左闭右闭127.0.0.1:6379&gt; getrange name 0 -1\"abcaaa\"127.0.0.1:6379&gt; setrange name 2 ***(integer) 6127.0.0.1:6379&gt; get name\"ab***a\" 列表其他操作范围裁剪 除了以上对于列表某个位置或范围的访问，以及对列表左或右侧推入、弹出数据的命令 还可以通过LTRIM对列表进行裁剪 指令 解释 LTRIM 给定起点和终点，对列表进行裁剪，只保留该范围内的数据 123456# l: 4, 3, 2, 1127.0.0.1:6379&gt; ltrim l 1 3OK127.0.0.1:6379&gt; lrange l 0 -11) \"2\"2) \"1\" 元素移动 redis还支持在两个列表之间进行数据移动，从某个列表中pop数据，然后push到另外一个列表中 指令 解释 RPOPLPUSH source dest 从source列表中弹出最右端的数据，并从最左端推入dest列表中 BRPOPLPUSH source dest timeout timeout参数代表当source列表为空时，该命令阻塞等待可弹出数据，超过时间则返回None 1234567# l1: 2,1 # l2: a,127.0.0.1:6379&gt; lrange l1 0 -11) \"2\"127.0.0.1:6379&gt; lrange l2 0 -11) \"1\"2) \"a\" 阻塞弹出 指令 解释 BLPOP 阻塞等待timeout时间，从一个非空列表中弹出最左侧的元素，超时返回None BRPOP 与上同，只是从列表的最右侧弹出元素 这俩命令本质上与普通的LPOP和RPOP差不多，只是多了阻塞行为 集合其他操作计数、随机 唯一、无序 指令 解释 SCARD 返回集合中包含元素的数量 SRANDMEMBER KEY COUNT 从key的集合中随机返回COUNT个数量的元素 SPOP KEY COUNT 随机移除COUNT个元素，并返回被移除的元素 1234567891011121314151617127.0.0.1:6379&gt; smembers s11) \"1\"2) \"2\"3) \"3\"127.0.0.1:6379&gt; scard s1(integer) 3127.0.0.1:6379&gt; srandmember s1 21) \"2\"2) \"1\"127.0.0.1:6379&gt; srandmember s1 21) \"2\"2) \"3\"127.0.0.1:6379&gt; spop s1 21) \"2\"2) \"3\"127.0.0.1:6379&gt; smembers s11) \"1\" 组合 指令 解释 SMOVE SOURCE DEST ITEM 如果ITEM存在与SOURCE中，那么将其移除并添加到DEST集合中，成功返回1，反之返回0 12345678910111213127.0.0.1:6379&gt; sadd s1 a(integer) 1127.0.0.1:6379&gt; sadd s2 * (integer) 1127.0.0.1:6379&gt; smove s1 s2 a(integer) 1127.0.0.1:6379&gt; smove s1 s2 a(integer) 0127.0.0.1:6379&gt; smembers s21) \"*\"2) \"a\"127.0.0.1:6379&gt; smembers s1(empty list or set) 差集、交集、并集 与数学中的语义一致 指令 解释 SDIFF KEY1 KEY2… 返回存在与KEY1而不存在于其他集合中的元素（差集） SDIFFSTORE DEST KEY1 KEY2… 返回存在与KEY1而不存在于其他集合中的元素（差集），并存储到DEST中 SINTER KEY1 KEY2… 返回同时存在于所有集合中的元素（交集） SINTERSTORE DEST KEY1 KEY2… 返回同时存在于所有集合中的元素（交集），并存储到DEST中 SUNION KEY1 KEY2… 返回那些至少存在于一个集合中的元素（并集） SUNIONSTORE DEST KEY1 KEY2 返回那些至少存在于一个集合中的元素（并集），并存储到DEST中 123456789101112131415127.0.0.1:6379&gt; sdiffstore dest s2 s1(integer) 2127.0.0.1:6379&gt; smembers dest1) \"*\"2) \"a\"# dest: *, a# s2: *, a# s3: ~127.0.0.1:6379&gt; sunion dest s21) \"*\"2) \"a\"127.0.0.1:6379&gt; sunion dest s2 s31) \"*\"2) \"~\"3) \"a\" 散列其他操作批量存储 之前的是单独的key、value存储 来看看更高级的批量键值获取存储，这样的操作可以减少命令的调用次数，以及客户端与Redis之间的通信往返次数来提升Redis的性能 指令 解释 HMGET 从一个散列获取一个或多个值 HMSET 为散列设置一个或多个值 HLEN 返回散列包含的键值对数量 12345678127.0.0.1:6379&gt; hmset hm a 1 b 2 c 3OK127.0.0.1:6379&gt; hmget hm a b c1) \"1\"2) \"2\"3) \"3\"127.0.0.1:6379&gt; hlen hm(integer) 3 获取、检查 Redis的散列还可以像Python中的字典一样，支持集成了很多功能 指令 解释 HEXISTS 检查给定的键是否在散列中 HKEYS 获取散列包含的所有键 HVALS 获取散列包含的所有值 HINCRYBY 将键存储的值加上一个整数 HINCRYBYFLOAT 将键存储的值加上一个浮点数 123456789101112131415127.0.0.1:6379&gt; hset h a 1(integer) 1127.0.0.1:6379&gt; hexists h a (integer) 1127.0.0.1:6379&gt; hexists h b(integer) 0# h: &#123; 1:a, 2:b &#125;127.0.0.1:6379&gt; hvals h1) \"v2\"2) \"1\"3) \"2\"127.0.0.1:6379&gt; hkeys h1) \"k2\"2) \"a\"3) \"b\" 使用getall在大量数据的情况下，可以先使用hkeys，然后再使用hget一个个的取出键的值 有序集合其他操作计数、区间 有序集合主要是通过分值大小有序的进行获取和扫描成员 指令 解释 ZCARD 返回有序集合的数据成员数量 ZINCRBY 将有序集合某个成员的分值加上某个值 ZCOUNT KEY MIN MAX 返回分值介于min和max之间的成员数量 ZRANK KEY MEMBER 返回成员在有序集合中的排名 ZSCORE 返回成员的分值 1234567891011121314151617181920212223127.0.0.1:6379&gt; zcard z(integer) 2# a2:5 a3:7 a1:10127.0.0.1:6379&gt; zadd z 10 a1(integer) 1127.0.0.1:6379&gt; zadd z 5 a2(integer) 1127.0.0.1:6379&gt; zadd z 7 a3(integer) 1127.0.0.1:6379&gt; zrange z 0 -11) \"a2\"2) \"a3\"3) \"a1\"127.0.0.1:6379&gt; zcount z 7 10(integer) 2127.0.0.1:6379&gt; zrank z a2(integer) 0127.0.0.1:6379&gt; zrank z a3(integer) 1127.0.0.1:6379&gt; zrank z a1(integer) 2127.0.0.1:6379&gt; zscore z a1\"10\" 范围删除、获取 除了正向的排序，还可以通过分值逆向排序提取结果 还可以对有序集合进行范围移除 指令 解释 ZREVRANK 返回从大到小的单个元素的排名 ZREVRANGE 返回有序集合给定排名范围内的成员，成员按照分值从大到校排列 ZRANGEBYSCORE KEY MIN MAX 返回介于某个分值之间的所有元素 ZREVRANGEBYSCORE 返回介于某个分值之间的所有元素并逆序 ZREMRANGEBYRANK KEY START STOP 移除介于某个排名区间之间的所有元素 ZREMRANGEBYSCORE KEY MIN MAX 移除介于某个分值之间的所有元素 ZINTERSTORE 执行交集运算 ZUNIONSTORE 执行并集运算 12345678910111213141516171819202122232425127.0.0.1:6379&gt; zrange z 0 -11) \"a2\"2) \"a3\"3) \"a1\"127.0.0.1:6379&gt; zrevrank z a3(integer) 1127.0.0.1:6379&gt; zrevrank z a2 (integer) 2127.0.0.1:6379&gt; zrevrank z a1(integer) 0127.0.0.1:6379&gt; zrevrange z1 0 -11) \"zhangsan\"2) \"wangwu\"3) \"lisi\"127.0.0.1:6379&gt; zrange z1 0 -11) \"lisi\"2) \"wangwu\"3) \"zhangsan\"127.0.0.1:6379&gt; zrangebyscore z1 99.5 1001) \"wangwu\"2) \"zhangsan\"127.0.0.1:6379&gt; zremrangebyrank z1 0 1(integer) 2127.0.0.1:6379&gt; zrange z1 0 11) \"zhangsan\"","categories":[],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://laxe.top/tags/Redis/"}]},{"title":"Redis的数据淘汰策略","slug":"Redis的数据淘汰策略","date":"2019-10-21T03:36:00.091Z","updated":"2019-10-21T03:36:35.471Z","comments":true,"path":"2019/10/21/Redis的数据淘汰策略/","link":"","permalink":"http://laxe.top/2019/10/21/Redis的数据淘汰策略/","excerpt":"Redis数据过期策略 当redis内存不足时，此时就要有响应的策略来保证将一些无用或冷数据从内存中剔除出去； 定时删除 策略 : 在设置键的过期时间的同时，创建一个定时器，让定时器在键的过期时间来临时，立即执行对键的删除操作 优点 : 对内存友好，保证过期键会尽可能快地被删除，并释放过期键所占用的内存 缺点 : 对CPU时间不友好，占用太多CPU时间，影响服务器的响应时间和吞吐量","text":"Redis数据过期策略 当redis内存不足时，此时就要有响应的策略来保证将一些无用或冷数据从内存中剔除出去； 定时删除 策略 : 在设置键的过期时间的同时，创建一个定时器，让定时器在键的过期时间来临时，立即执行对键的删除操作 优点 : 对内存友好，保证过期键会尽可能快地被删除，并释放过期键所占用的内存 缺点 : 对CPU时间不友好，占用太多CPU时间，影响服务器的响应时间和吞吐量 惰性删除 策略 : 放任过期键不管，每次从键空间读写操作时，都检查键是否过期，如果过期，删除该键，如果没有过期，返回该键 优点 : 对CPU时间友好，读写操作键时才对键进行过期检查，删除过期键的操作只会在非做不可的情况下进行 缺点 : 对内存不友好，只要键不删除，就不会释放内存，浪费太多内存，有内存泄漏风险 定期删除 策略 :对定时删除策略和惰性删除策略的一种整合和折中。每隔一段时间执行一次定时删除，并通过限制删除操作执行的总时长和总频率来限制删除操作对CPU占用时间的影响。通过定期删除过期键，有效减少了因为过期键而带来的内存浪费 难点：确定删除操作执行的总时长和总频率。执行太频繁，执行时间过长，就会退化成定时删除策略，影响客户端请求效率；执行得太少，执行时间太短，会演变为惰性删除，存在内存浪费的情况 Redis服务器使用惰性删除和定期删除两种策略，通过配合使用，很好地在合理使用CPU时间和避免浪费内存之间取得平衡 驱逐策略 maxmemory maxmemory 用于指定Redis能使用的最大内存。既可以在 redis.conf 文件中设置, 也可以在运行过程中通过CONFIG SET命令动态修改 1maxmemory 100mb 达到最大内存限制时maxmemory ，Redis根据 maxmemory-policy 配置的策略, 来决定具体的行为 Redis 3.0支持的策略包括 noeviction：不删除策略，达到最大内存限制时，如果需要更多内存，直接返回错误信息 大多数写命令都会导致占用更多的内存(有极少数会例外, 如 DEL )。 allkeys-lru：所有key通用；优先删除最近最少使用key volatile-lru：只限于设置了expire的部分; 优先删除最近最少使用(less recently used、LRU)的 key allkeys-random：所有key通用；随机删除一部分key volatile-random：只限于设置了expire的部分；随机删除一部分key volatile-ttl：只限于设置了expire的部分；优先删除剩余时间短的key 如果没有设置 expire 的key，不满足先决条件(prerequisites) 那么 volatile-lru, volatile-random 和 volatile-ttl 策略的行为，和 noeviction(不删除) 基本上一致 配置驱逐策略，可以通过maxmemory-policy属性设置 1maxmemory-policy noeviction maxmemory-policy同样可以在运行时设置，用户可以根据内存的使用情况动态的修改淘汰策略。 当redis中的数据有一部分访问频率比较高，另外一部分访问频率较低时，设置allkeys-lru比较合适。或者无法预测数据的使用频率时，allkeys-lru也是不错的选择。 如果你需要循环或者扫描连续数据时，换种说法就是数据的访问概率大致相等时，allkeys-random是不错的选择 当你想通过设置不同的ttl来控制数据过期的先后顺序时，你可以设置为volatile-ttl 当你希望一些数据常驻内存，另外一些数据可以被替换掉时，就请用volatile-lru或volatile-random吧 另外，数据的过期时间是存储在另外一个哈希表中的，因此要耗费更多的内存空间，而allkeys-lru并不需要数据设置过期时间，因此对内存的利用率更高 volatile-lru，volatile-random和volatile-ttl在没有数据满足被淘汰的条件时，会和noeviction一样返回错误 触发淘汰动作 客户端执行一个命令, 导致Redis中的数据增加,占用更多内存 Redis检查内存使用量, 如果超出 maxmemory 限制, 根据策略清除部分key 继续执行下一条命令, 以此类推 策略执行方式 Redis为了避免反复触发淘汰策略，每次会淘汰掉一批数据；当Redis指令产生数据比较大时，淘汰掉的数据量也相应也比较大。 为了节省内存，LRU的策略并不是严格执行的，Redis是在整体中随机抽样取出一小部分数据，在这部分数据中严格执行LRU策略 在Redis3.0以后的版本对此算法做了改进，但仍然也是近似的LRU的策略，只是离真正的LRU更近了。 另外用户可以动态的设定随机抽取的样本数，例如 1maxmemory-samples 5","categories":[],"tags":[{"name":"Django","slug":"Django","permalink":"http://laxe.top/tags/Django/"}]},{"title":"Redis的键空间、键事件通知系统","slug":"Redis的键空间、键事件通知系统","date":"2019-10-21T03:34:37.619Z","updated":"2019-10-21T03:35:27.512Z","comments":true,"path":"2019/10/21/Redis的键空间、键事件通知系统/","link":"","permalink":"http://laxe.top/2019/10/21/Redis的键空间、键事件通知系统/","excerpt":"键空间事件通知 在Redis里面有一些事件，比如键到期、键被删除等。可以通过打开redis键空间事件通知来让 Redis 一旦触发这些事件的时候就往特定的Channel推一条消息 键事件通知配置 默认在redis中，键事件通知是不打开的，需要我们手动配置，具体的选项如下，默认他是个空字符串，代表关闭状态","text":"键空间事件通知 在Redis里面有一些事件，比如键到期、键被删除等。可以通过打开redis键空间事件通知来让 Redis 一旦触发这些事件的时候就往特定的Channel推一条消息 键事件通知配置 默认在redis中，键事件通知是不打开的，需要我们手动配置，具体的选项如下，默认他是个空字符串，代表关闭状态 1notify-keyspace-events \"\" 关于这条属性的选项，在配置文件也有了详细的介绍，如下 选项字符 解释 K 键空间通知，所有通知以__keyspace@&lt;db&gt;__ 为前缀 E 键事件通知，所有通知以__keyevent@&lt;db&gt;__ 为前缀 g DEL、EXPIRE、RENAME等类型无关的通用命令的通知 $ 字符串命令的通知 l 列表命令的通知 s 集合命令的通知 h 哈希命令的通知 z 有序集合命令的通知 x 过期事件：每当有过期键被删除时发送 e 驱逐(evict)事件：每当有键因为maxmemory政策而被删除时发送 A 参数g$lshzxe的别名 键空间和键事件 对于每个修改数据库的操作，键空间通知都会发送两种不同类型的事件 比如说，对0号数据库的键mykey执行DEL命令时， 系统将分发两条消息， 相当于执行以下两个PUBLISH命令 12PUBLISH __keyspace@0__:mykey delPUBLISH __keyevent@0__:del mykey __keyspace@0__:mykey：接收0号数据库中所有修改键mykey的事件 __keyevent@0__:del：接收0号数据库中所有执行del命令的键 12&gt; keyspace`为前缀的频道被称为键空间通知`key-space notification&gt; 12&gt; keyevent`为前缀的频道则被称为键事件通知`key-event notification&gt; 订阅键空间频道，监控被执行事件的键，如监控mykey；那么此时将接收到该键所对应的事件：del 订阅键事件频道，监控某个事件，如del；那么del事件触发时，订阅者收到：mykey 过期的键事件通知 过期的键事件通知常用在订单过期通知等场景下，此时只需要订阅对应过期事件的频道，当某键触发过期事件时，即可接受到对应过期键的消息 redis配置如下： 1notify-keyspace-events \"Ex\" Python代码的简单示范，订阅过期频道 12345678910111213141516import redisimport timeredis = redis.Redis(host='123.57.61.168', port=6379)pubsub = redis.pubsub()pubsub.psubscribe('__keyevent@0__:expired') # 订阅过期事件频道print('Starting message loop')while True: try: message = pubsub.get_message() if message: print(message) else: time.sleep(0.01) except KeyboardInterrupt: # CTRL + C break 那么当此时执行此段代码，另起redis客户端，设置一个可以过期的key值，来看一下效果","categories":[],"tags":[{"name":"Django","slug":"Django","permalink":"http://laxe.top/tags/Django/"}]},{"title":"Redis进行持久化的两种办法","slug":"Redis进行持久化的两种办法","date":"2019-10-21T03:33:08.935Z","updated":"2019-10-21T03:38:47.961Z","comments":true,"path":"2019/10/21/Redis进行持久化的两种办法/","link":"","permalink":"http://laxe.top/2019/10/21/Redis进行持久化的两种办法/","excerpt":"redis提供了两种办法，进行数据持久化，保证数据安全可靠，也就是人们众所周知的RDB和AOF机制 快照（snapshotting） 客户端发送BGSAVE命令来创建一个快照，当调用BGSAVE命令之后，Redis会调用fork来创建一个子进程，该子进程负责将快照写入硬盘，而父进程则继续处理命令请求 客户端发送SAVE来创建一个快照，接到SAVE命令的redis服务器会在快照创建完毕之前不响应任何其他命令，save命令并不常用，我们通常只会在没有足够内存去执行BGSAVE的情况下，或者无视等待持久化操作所造成的时间浪费问题，也可以使用该命令 当redis配置了save选项，比如save 60 10000，那么redis最近一次创建快照开始算起，当60秒内有10000次写入这个条件被满足时，redis就会自动触发BGSAVE命令，当用户配置了多个save选项，当任意一个save条件被满足时，redis就会触发一次bgsave 命令 当redis接收到了shutdown命令以及标准的term信号时，会自动执行save命令，阻塞所有的客户端，不再执行客户端发送的任何命令，并在save命令执行完毕之后关闭服务器 当redis实现主从同步时，从服务器向主服务器发送sync命令时，此时，如果主服务器目前没有在执行bgsave命令，或并非刚刚执行完bgsave命令，那么此时主服务器就会执行bgsave进行数据持久化备份，","text":"redis提供了两种办法，进行数据持久化，保证数据安全可靠，也就是人们众所周知的RDB和AOF机制 快照（snapshotting） 客户端发送BGSAVE命令来创建一个快照，当调用BGSAVE命令之后，Redis会调用fork来创建一个子进程，该子进程负责将快照写入硬盘，而父进程则继续处理命令请求 客户端发送SAVE来创建一个快照，接到SAVE命令的redis服务器会在快照创建完毕之前不响应任何其他命令，save命令并不常用，我们通常只会在没有足够内存去执行BGSAVE的情况下，或者无视等待持久化操作所造成的时间浪费问题，也可以使用该命令 当redis配置了save选项，比如save 60 10000，那么redis最近一次创建快照开始算起，当60秒内有10000次写入这个条件被满足时，redis就会自动触发BGSAVE命令，当用户配置了多个save选项，当任意一个save条件被满足时，redis就会触发一次bgsave 命令 当redis接收到了shutdown命令以及标准的term信号时，会自动执行save命令，阻塞所有的客户端，不再执行客户端发送的任何命令，并在save命令执行完毕之后关闭服务器 当redis实现主从同步时，从服务器向主服务器发送sync命令时，此时，如果主服务器目前没有在执行bgsave命令，或并非刚刚执行完bgsave命令，那么此时主服务器就会执行bgsave进行数据持久化备份， 12345671.主服务器会在命令执行完毕之后，向所有从服务器发送快照文件2.并在发送期间继续记录被执行的写命令3.从服务器会在接收到新的快照文件之后丢弃所有的旧数据4.载入新收到的快照文件5.主服务器发完新的快照文件继续将缓冲区中的写命令同步到从服务器上6.从服务器完成对快照的载入之后，开始接收命令，并执行新的主服务器发来的缓冲区里的写命令7.从服务器回归原来的工作模式，继续接收读指令 save选项1save 900 1 如上的redis配置选项告知redis，它应该根据这个选项提供的两个值来进行bgsave操作 如果服务器距离上次成功生成快照已超过了900秒，或者在这期间执行了至少一次写操作，那么redis 就会自动开始一次新的BGSAVE操作 快照规则的选定是一个技术活，需要在开发环境即模拟生产环境，避免备份操作频繁，或是过于稀少而导致的资源浪费或含有丢失大量数据的隐患 数据较大 对于真实的物理机，vmware或者kvm虚拟机来说，redis进程每占用多一个G的内存，创建bgsave进程所需要的时间就要多增加10~20毫秒 对于xen虚拟机来说，同样一个GB的redis内存增加，会导致bgsave子进程的时间多200~300毫秒 虽然bgsave不需要阻塞服务，但是由于开启了子进程，会造成资源抢占而导致redis服务停顿，在一个50GB内存的redis服务上执行bgsave命令，创建子进程需要花费15秒，生成快照需要15~20分钟；而使用save命令只需要3~5分钟即可完成快照生成 AOF持久化 aof机制将被执行的写命令写到AOF文件的末尾，以此来记录数据的变化， redis只需要从头到尾的执行一次AOF文件包含的所有写命令，就可以回复AOF文件所记录的数据集， AOF配置选项，在centos7操作系统下位于redis配置文件的第594行附近，把no改成yes 12appendonly no# appendonly yes AOF频率的设置 123appendfsync everysec # 每秒进行一次同步，显示的将多个写命令同步到硬盘appendfsync always # 每个redis写命令都同步的写入磁盘，这样做会严重降低redis的速度appendfsync no # 由操作系统决定应该何时进行同步 注意，appendfsync always选项会让Redis每次只写入一个命令，而不是像其他的appendfsync选项那样一次写入多个命令，这种不断写入的少量数据的做法会在固态硬盘的情况下，引发严重的写入放大，甚至会将固态硬盘的寿命从原来的几年降低为几个月 为了兼顾安全和写入性能，用户可以考虑使用appendfsync everysec选项，让redis以每秒一次的频率对AOF文件进行同步；redis每秒同步一次AOF文件时的性能和不使用任何持久化特性时的性能相差无几，这样的持久化策略，即使出现系统崩溃，也只会损失一秒的数据 当硬盘忙于执行写入操作时，Redis还会优雅的放慢自己的速度以便适应硬盘的最大写入速度 数据较大 虽然AOF可以最低使时间丢失的时间窗口降低至1秒，但是不断增长的命令记录会写到AOF文件里面，导致AOF的体积越来越大，极端情况下，不断增长的AOF文件甚至会用完所有的磁盘空间，另外，重启的Redis需要重新执行AOF文件所记录的所有命令来还原数据集，如果AOF文件非常大，那么还原操作的时间也会非常漫长 解决这个AOF文件过大的问题，可以向redis发送bgrewriteaof，这个命令会移除在文件中的冗余命令来重写rewriteAOF文件，使AOF文件的体积变得尽可能的小 BGREWRITEAOF指令和BGSAVE工作的原理相似，都需要在后台开辟子进程，由子进程负责对AOF文件进行重写；因为AOF文件重写需要子进程，那么同样会造成开辟子进程造成的性能问题和内存占用问题； 还需要注意的是，当AOF文件过大，在重写过程以及重写完成之后删除旧有AOF文件，删除一个较大的AOF文件还可能会导致操作系统挂起数秒 设置AOF 12auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb 当AOF文件此时大于64M，并且AOF文件的体积比上一次重写之后的体积大于了至少一倍100%，那么redis就会执行BGREWRITEAOF命令 如果AOF重写频繁，可以适当调整auto-aof-rewrite-percentage选项，可以使redis在AOF体积变得更大的情况下才进行重写","categories":[],"tags":[{"name":"Django","slug":"Django","permalink":"http://laxe.top/tags/Django/"}]},{"title":"Redis中的发布者与订阅者","slug":"Redis中的发布者与订阅者","date":"2019-10-21T03:30:56.022Z","updated":"2019-12-26T00:32:54.585Z","comments":true,"path":"2019/10/21/Redis中的发布者与订阅者/","link":"","permalink":"http://laxe.top/2019/10/21/Redis中的发布者与订阅者/","excerpt":"发布与订阅 发布和订阅pub/sub，订阅者负责订阅频道，发送者负责像频道发送二进制字符串消息，每当有消息发布到订阅的这个频道，那么所有的订阅者都可以收到这个消息， 发布订阅也是像是我们生活中的电台，订阅者可以订阅收听多个电台，而发送者可以再任何电台发送消息","text":"发布与订阅 发布和订阅pub/sub，订阅者负责订阅频道，发送者负责像频道发送二进制字符串消息，每当有消息发布到订阅的这个频道，那么所有的订阅者都可以收到这个消息， 发布订阅也是像是我们生活中的电台，订阅者可以订阅收听多个电台，而发送者可以再任何电台发送消息 发布、订阅命令 指令 解释 SUBSCRIBE CHANNLE 订阅给定的一个或多个频道 UNSUBSCRIBE CHANNLE 退订一个或多个频道，如果没有指定具体退订的频道，那么是全部退订 PSUBSCRIBE PATTERN 订阅与给定模式相匹配的所有频道 PUNSUBSCRIBE PATTERN 退订给定的模式相匹配的频道，未指定，则退订所有 PUBLISH CHANNLE MESSAGE 向给定频道发送消息 以下是一个Python的小DEMO，实现发布者订阅者 发布者，注意当订阅者迟于发布者时，可能会由于某些消息已经被发布而无法被新参与的订阅者拿到 123456789def publish(conn): ''' 发布者频道 conn: 连接对象 ''' time.sleep(1) # 让订阅者有充足的时间先订阅频道 for var in range(10): conn.publish('channle',var) time.sleep(1) # 消息发送间隔一秒 订阅者，这里注释部分提供了一个迟于发布者的订阅逻辑 1234567891011121314151617def subscribe(conn): ''' 订阅者频道 ''' pubsub = conn.pubsub() # time.sleep(3) 当订阅迟于发布时，会丢失时间间隔内所发布的消息 pubsub.subscribe(['channle']) i = 0 for item in pubsub.listen(): if i == 10: pubsub.unsubscribe() # 退订！但是还不能跳出循环，要把这次取出来的打印了 下次跳出循环 if i == 11: break print('[SUB] : %s' % item) sys.stdout.flush() i += 1 入口函数 1234567def main(): conn = redis.Redis(host='44.33.22.11',port=6379) Thread(target=publish, args=(conn,)).start() # 开启发布者频道 subscribe(conn)if __name__ == \"__main__\": main() 当发布者的消息等待一秒，而订阅者无等待时间差时，此时订阅者可以拿到所有的数据 但是当注释掉的三秒延迟打开，此时订阅者将会晚于发布者三秒进行 很明显，丢掉了两秒间隔的数据0和1，这和生活中很贴近，已经出版的期刊，不会再订阅之后重新不给你 而且由于代码此时在订阅者部分必须循环到10次才会取消订阅，结合listen的阻塞模式，当前程序进入到了阻塞状态，无法继续，但是发布者也已经不在工作了。 发布、订阅模式的缺陷 对于旧版的Redis来说，如果某个订阅者的消息提取速度不够快的话，会导致消息积压而造成Redis输出缓冲区的体积变得越来越大，这可能会导致Redis的速度越来越慢，或者直接崩溃，也可能会导致Redis会被操作系统强制杀死，甚至导致操作系统不可用，毕竟这是在内存里的数据库 新版的Redis不会出现这样的问题 此外，如果客户端在订阅消息操作过程中出现了断线，那么客户端将丢失在断线过程中发布者发送的所有消息","categories":[],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://laxe.top/tags/Redis/"}]},{"title":"Redis实现分布式锁以及利用乐观锁保证数据安全","slug":"Redis实现分布式锁以及利用乐观锁保证数据安全","date":"2019-10-21T03:25:16.370Z","updated":"2019-12-26T00:33:31.403Z","comments":true,"path":"2019/10/21/Redis实现分布式锁以及利用乐观锁保证数据安全/","link":"","permalink":"http://laxe.top/2019/10/21/Redis实现分布式锁以及利用乐观锁保证数据安全/","excerpt":"分布式锁 一般来说，对数据进行加锁时，程序首先需要通过获取acquire锁来得到对数据操作、排他的权力 在操作完毕之后，还需要通过release进行锁的释放，以供其他程序使用 Redis使用WATCH命令用以代替对数据进行加锁，WATCH只会在数据被其他客户端抢先修改了的情况下通知执行命令的这个客户端（通过WatchError异常），但不会阻止其他客户端对数据的修改，这样的加锁的行为也常称为乐观锁","text":"分布式锁 一般来说，对数据进行加锁时，程序首先需要通过获取acquire锁来得到对数据操作、排他的权力 在操作完毕之后，还需要通过release进行锁的释放，以供其他程序使用 Redis使用WATCH命令用以代替对数据进行加锁，WATCH只会在数据被其他客户端抢先修改了的情况下通知执行命令的这个客户端（通过WatchError异常），但不会阻止其他客户端对数据的修改，这样的加锁的行为也常称为乐观锁 锁和范围score有关，为了让Redis存储的数据进行排他性访问，客户端需要一个锁，而这样的锁，是可以让所有的客户端都在看得见的范围，这个范围就是Redis本身，因此我们需要把锁构建在Redis里面。另一个方面，虽然有类似的SETNX命令可以实现Redis中的锁的功能，但他锁提供的机制并不完整，也不具备分布式锁的一些高级特性，还是得通过我们手动构建 Watch 回顾一下Multi命令 Multi命令用于标记一个事务块的开始 事务块内的多条命令会按照先后顺序被放进一个队列当中，最后由EXEC命令原子性(atomic)地执行 回顾一下WATCH命令（redis在2.2之后加入了watch的功能） 12&gt; WATCH`命令可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，在`Python`中将会抛出`WatchError&gt; 监控一直持续到EXEC命令（事务中的命令是在EXEC之后才执行的，所以在MULTI命令后可以修改WATCH监控的键值） 当用户购买时，首先开启事务，通过WATCH监听用户库存，判断是否含有库存，如果含有，则库存数量减一，并执行任务 1234567891011121314151617181920212223# 首先在redis中设置某商品apple 对应数量value值为1000import redisdef sale(): rs = redis.Redis(host=host,port=6379) while 1: with rs.pipeline() as p: ''' 通过管道方式进行连接 多条命令执行结束，一次性获取结果 ''' try: p.watch('apple') # 监听key值为apple的数据数量改变 count = int(rs.get('apple')) print('拿取到了苹果的数量: %d' % count) p.multi() # 事务开始 if count&gt; 0 : # 如果此时还有库存 p.set('apple', count - 1) p.execute() # 执行事务 p.unwatch() break # 当库存成功减一或没有库存时跳出执行循环 except Exception as e: # 当出现watch监听值出现修改时，WatchError异常抛出 print('[Error]: %s' % e) continue # 继续尝试执行 到目前，通过Watch监听，结合事务的MULTI以及EXEC可以实现这样一个版本的锁，随着负载的不断增加，系统完成一次交易的重试次数也将会越来越大，完成一次交易需要等待的时间也将不断增加 可以看到，Redis在尝试完成一个事务的时候，可能会因为事务的失败而重复尝试重新执行，保证商品的库存量正确是一件很重要的事情，但是单纯的使用WATCH这样的机制在压力较大的情况下并不完美，那么接下来，就可以通过上锁来进行库存数量改变 SimpleLock 通过加锁的形式，可以解决以上Watch监控所导致的问题 uuid uuid是什么 它是通过MAC地址、 时间戳、 命名空间、 随机数、 伪随机数来保证生成ID的唯一性 uuid有着固定的大小128bit位，通常由32字节的字符串（十六进制）表示 uuid的作用 很多应用场景需要一个id，但是又不要求这个id有具体的意义，仅仅用来标识一个对象 常见的用处有数据库表的id字段 另一个例子是前端的各种UI库，因为它们通常需要动态创建各种UI元素，这些元素需要唯一的id， 这时候就需要使用UUID了 例如：一个网站在存储视频、图片等格式的文件时，这些文件的命名方式就可以采用UUID生成的随机标识符，避免重名的出现 python生成uuid数值可以通过以下方式 uuid.uuid1([node[, clock_seq]]) ：基于时间戳 使用主机ID，序列号，和当前时间来生成UUID，可保证全球范围的唯一性 但由于使用该方法生成的UUID中包含有主机的网络地址，因此可能危及隐私，该函数有两个参数, 如果node参数未指定, 系统将会自动调用getnode()函数来获取主机的硬件地址，如果clock_seq参数未指定系统会使用一个随机产生的14位序列号来代替 uuid.uuid3(namespace, name)：基于名字的MD5散列值 通过计算命名空间和名字的MD5散列值来生成UUID；可以保证同一命名空间中不同名字的唯一性和不同命名空间的唯一性，但同一命名空间的同一名字生成的UUID相同 uuid.uuid4()：基于随机数 通过随机数来生成UUID，使用的是伪随机数有一定的重复概率 uuid.uuid5(namespace, name)：基于名字的SHA-1散列值 通过计算命名空间和名字的SHA-散列值来生成UUID，算法与uuid.uuid3()相同. RedisLock 使用Redis构建锁非常简单，在Redis中，可以通过使用SETNX命令来实现，这个命令会在键不存在的情况下为吉键设置值，而锁要做的事情就是将一个随机生成的128位UUID设置位键的值，防止该锁被其他进程获取 如果程序在尝试获取锁的过程中失败，那么他将不断的进行重试，直到成功的取得锁或超过锁的持有超时时间 初始化连接函数 123def get_conn(host,port=6379): rs = redis.Redis(host=host, port=port) return rs 加锁函数 123456789101112131415161718def acquire_lock(rs, lock_name, expire_time=10): ''' rs: 连接对象 lock_name: 锁标识 acquire_time: 过期超时时间 return -&gt; False 获锁失败 or True 获锁成功 ''' # print('获取锁...') identifier = str(uuid.uuid4()) end = time.time() + expire_time while time.time() &lt; end: # 当获取锁的行为超过有效时间，则退出循环，本次取锁失败，返回False if rs.setnx(lock_name, identifier): # 尝试取得锁 # print('锁已设置: %s' % identifier) return identifier time.sleep(.001) return False 加锁函数通过SETNX命令，尝试在锁不存在的i情况下，为键设置一个值，以此来获取锁 在获取锁失败的时候，会尝试在给定的时间内进行重试，一直到重新成功获取到或超过给定的实现 释放锁函数 123456789101112131415161718192021def release_lock(rs, lockname, identifier): ''' rs: 连接对象 lockname: 锁标识 identifier: 锁的value值，用来校验 ''' pipe = rs.pipeline(True) try: pipe.watch(lockname) # print('当前获取到的锁:', rs.get(lockname).decode()) # print('redis中实际锁的值:',identifier) # print(rs.get(lockname).decode() == identifier) if rs.get(lockname).decode() == identifier: pipe.multi() # 开启事务 pipe.delete(lockname) pipe.execute() # print('锁已释放') return True # 删除锁 pipe.unwatch() # 取消事务 except Exception as e: pass return False # 删除失败 锁的删除操作很简单，只需要将对应锁的key值获取到的uuid结果进行判断验证，符合条件通过delete在redis中删除即可，此外当其他用户持有同名锁时，由于uuid的不同，经过验证后不会错误释放掉别人的锁 1234567891011121314151617def sale(): rs = get_conn(host=host) start = time.time() # 程序启动时间 with rs.pipeline() as p: while 1: lock = acquire_lock(rs, 'lock') if not lock: # 持锁失败 continue try: count = int(rs.get('apple')) # 取量 p.set('apple', count-1) # 减量 p.execute() print('当前库存量: %s' % count) break finally: release_lock(rs, 'lock', lock) print('[time]: %.2f' % (time.time() - start)) ExpireLock 在之前的锁中，还出现这样的问题，比如某个进程持有锁之后突然程序崩溃，那么会导致锁无法释放而其他进程无法持有锁继续工作，为了解决这样的问题，可以在获取锁的时候加上锁的超时功能 Redis中，可以通过EXPIRE命令为锁设置过期时间，Redis会自动释放超时的锁，以下是超时锁的定义模型 1234567891011121314151617181920def acquire_expire_lock(rs, lock_name, expire_time=10, locked_time=10): ''' rs: 连接对象 lock_name: 锁标识 acquire_time: 过期超时时间 locked_time: 锁的有效时间 return -&gt; False 获锁失败 or True 获锁成功 ''' # print('获取锁...') identifier = str(uuid.uuid4()) end = time.time() + expire_time while time.time() &lt; end: # 当获取锁的行为超过有效时间，则退出循环，本次取锁失败，返回False if rs.setnx(lock_name, identifier): # 尝试取得锁 # print('锁已设置: %s' % identifier) rs.expire(lock_name, locked_time) return identifier time.sleep(.001) return False 在其他数据库里面，加锁通常是一个自动执行的基本操作，而Redis的WATCH、MULTI和EXEC操作只是一个乐观锁；这种锁只会在数据被其他客户端抢先修改的情况下，通知加锁的客户端，让他撤销对于被监控数据的修改，而不会把数据真正的锁住 通过在客户端上面实现一个真正的锁，程序可以位用户带来更好的性能，更熟悉的编程概念、更简单易用的API 于此同时，也要注意，Redis并不会自动使用我们自制的锁，我们必须自己使用这个锁来代替WATCH，从而保证数据的正确与一致性","categories":[],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://laxe.top/tags/Redis/"}]},{"title":"Vue","slug":"Vue","date":"2019-10-21T02:57:05.032Z","updated":"2019-10-21T02:58:19.343Z","comments":true,"path":"2019/10/21/Vue/","link":"","permalink":"http://laxe.top/2019/10/21/Vue/","excerpt":"VUE Vue.js是前端三大新框架：Angular.js、React.js、Vue.js之一，Vue.js目前的使用和关注程度在三大框架中稍微胜出，并且它的热度还在递增 Vue的核心库只关注视图层，Vue的目标是通过尽可能简单的API实现响应的数据绑定，在这一点上Vue.js类似于后台的模板语言 Vue也可以将界面拆分成一个个的组件，通过组件来构建界面，然后用自动化工具来生成单页面(SPA - single page application)系统","text":"VUE Vue.js是前端三大新框架：Angular.js、React.js、Vue.js之一，Vue.js目前的使用和关注程度在三大框架中稍微胜出，并且它的热度还在递增 Vue的核心库只关注视图层，Vue的目标是通过尽可能简单的API实现响应的数据绑定，在这一点上Vue.js类似于后台的模板语言 Vue也可以将界面拆分成一个个的组件，通过组件来构建界面，然后用自动化工具来生成单页面(SPA - single page application)系统 Vue.js官方文档： https://cn.vuejs.org/v2/guide/ vue.js下载地址： https://cn.vuejs.org/v2/guide/installation.html npm配置cnpm windows下配置cnmp环境： 默认的使用NPM可能会因为网络问题而导致无法使用或延迟居高，可以使npm升级为cnpm，从国内淘宝镜像中加载所需的npm软件源 1npm install -g cnpm --registry=https://registry.npm.taobao.org 设置安装包缓存路径 1cnpm config set cache \"C:\\nodejs\\node_cache\" 设置安装包位置 1cnpm config set prefix \"C:\\nodejs\\node_global\" 之后使用命令安装的模块存储在C:\\nodejs\\node_global\\node_modules里 请按照个人需求设置你的文件位置 1npm config set cache \"C:\\nodejs\\node_cache\" Vue部署 安装Vue 1cnpm install vue -g 安装vue脚手架 1cnpm install vue-cli -g -g参数代表全局位置安装，这样可以在环境变量生效的情况下直接在命令行等工具下使用vue命令行进行项目的开启 vue-devtools调试工具 vue-devtools可以方便开发者进行Vue中变量等信息的调试跟踪 下载vue-devtools 1git clone https://github.com/vuejs/vue-devtools 进入到vue-devtools目录下安装依赖包 123cd vue-devtools-devcnpm install cnpm run build 注意：在进行调试工具安装时，首先需要修改shells&gt;chrome文件夹下的mainifest.json中的persistent为true 将插件目录下的chrome文件夹拖入到chrome浏览器的扩展程序下，记得打开调试模式 扩展程序可以通过浏览器访问 1chrome://extensions/ Vue-CDN 除去通过npm安装的方式来使用vue，还可以直接使用cdn中的vue.js文件 vue.js：开发版本，包含了有帮助的命令行警告 1&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt; vue.min.js：生产环境版本，优化了尺寸和速度 1&lt;script src=\"https://cdn.jsdelivr.net/npm/vue\"&gt;&lt;/script&gt; Vue语法 每个vue应用都是通过实例化一个新的vue对象开始的 创建第一个模板语法： 1234567891011&lt;div id=\"content\"&gt; &#123;&#123; message &#125;&#125; &lt;!-- 这个也叫做插值表达式 --&gt;&lt;/div&gt;var vm = new Vue(&#123; // vm这个变量不允许使用连字符，可以使用下划线，比如vm-data是不允许的 el: \"#content\", // 对应document中的一个标签，当vue对象创建后，这个标签内的区域就被接管 data: &#123; message: \"这是vue里的变量\" &#125;&#125;) 当一个vue实例被创建时，vue的响应式系统中加入了对其data对象中能找到的所有属性 当这些属性值被改变时，视图也会发生相应，并将对应属性更新为新的值 也可以通过定义函数来改变实例中data对象中的数据，数据改变，视图中的数据也将改变 12345678910111213141516171819&lt;div id=\"app\"&gt; &lt;p&gt;&#123;&#123; message &#125;&#125;&lt;/p&gt; &lt;button @click=\"ChangeMsg\"&gt;改变&lt;/button&gt; &lt;!-- 绑定点击事件为定义好的vue函数 --&gt;&lt;/div&gt;window.onload = function()&#123; var vm = new Vue(&#123; el: \"#app\", data: &#123; message: \"我对应的是message的变量\" &#125;, methods:&#123; // 定义一个函数 并绑定在按钮的点击事件上 ChangeMsg:function()&#123; this.message = \"我被改变了\"; // 修改当前实例中的message变量 &#125; &#125; &#125;)&#125; 这里的代码，将在点击按钮时，使当前的message变量发生变化 ``这样的语法有点类似一些Web框架，比如django的模板语言中的模板变量 返回值 除了直接定义某个变量的固定值进行页面渲染，模板变量还支持通过函数的返回值进行赋值 12345678910111213141516171819&lt;div id=\"app\"&gt; &lt;h1&gt;&#123;&#123; classType &#125;&#125;学习&lt;/h1&gt; &lt;p&gt;&#123;&#123; content &#125;&#125;&lt;/p&gt; &lt;span&gt;&#123;&#123; describe() &#125;&#125;&lt;/span&gt;&lt;/div&gt;window.onload = function()&#123; var vm = new Vue(&#123; el: \"#app\", // getElementById('app') data: &#123; classType: \"vue\", content: \"这是vue的一个测试\", &#125;, methods:&#123; describe:function()&#123; return \"这是一个函数的返回值\" &#125;, &#125; &#125;)&#125; Vue模板指令 模板语法指的是如何将数据放入html中 Vue.js使用了基于HTML的模板语法，允许开发者声明式地将DOM绑定至底层 Vue 实例的数据 所有 Vue.js的模板都是合法的 HTML ，所以能被遵循规范的浏览器和HTML 解析器解析 插入值，模板变量 数据绑定最常见的形式就是使用Mustache语法(双大括号) 的文本插值，也就是上面示例中的`` 内容绑定v-html 将内容按照html格式进行插入 123456789&lt;div id=\"app\"&gt; &lt;p v-html=\"contetn\"&gt;&lt;/p&gt;&lt;/div&gt;var vm = new Vue(&#123; el: \"#app\", data: &#123; content: \"&lt;b&gt;段落标签&lt;/b&gt;文本内容\" &#125;,&#125;) 在网站上动态渲染任意HTML是非常危险的，因为容易导致XSS攻击 v-html一般只用在可信内容中，永不用在用户提交的内容上 v-text 将内容按照文本格式进行插入，但会覆盖原有标签内的内容，不会有加载的闪烁问题 123456789101112131415&lt;div id=\"app\"&gt; &lt;p v-text=\"contetn\"&gt;&lt;/p&gt; &lt;p&gt; &#123;&#123; gender ? '男' : '女' &#125;&#125; &lt;!-- ok? true:false --&gt; &lt;/p&gt; &lt;/div&gt;var vm = new Vue(&#123; el: \"#app\", data: &#123; gender: true, // 变量值为true时，显示模板变量中左边的值 content: \"&lt;b&gt;段落标签&lt;/b&gt;文本内容\" &#125;,&#125;) v-cloak 解决使用差值表达式时页面渲染过程，由于变量没有初始化而导致的闪烁问题 通俗的来说，比如变量的实际内容没有被创建，那么此时页面只会展示出这样的效果，之后当变量初始化之后，``将变化为实际的值，此时变化的过程我们称作闪烁 这个指令可以隐藏未编译的标签直到实例准备完毕 123456789101112&lt;div id=\"app\"&gt; &#123;&#123; message &#125;&#125;&lt;/div&gt;&lt;script type=\"text/javascript\" src=\"js/vue.js\"&gt;&lt;/script&gt;&lt;script type=\"text/javascript\"&gt; new Vue(&#123; el: \"#app\", data:&#123; message: \"测试\", &#125; &#125;)&lt;/script&gt; 在上面的代码中，如果网速够慢的清空下，页面首先加载显示出的内容是`` 解决办法：通过v-clock指令，在使用到模板变量的标签上写入，并设置一个v-clock的类样式 12345678&lt;style type=\"text/css\"&gt; [v-cloak]&#123; display: none; &#125;&lt;/style&gt;&lt;div v-cloak id=\"app\"&gt; &lt;p v-cloak&gt;&#123;&#123; message &#125;&#125;&lt;/p&gt;&lt;/div&gt; 属性绑定v-bind 如果我们需要设置的模板变量是一个属性，比如a标签的href属性 1234567891011&lt;div id=\"app\"&gt; &lt;a v-bind:href=\"message\"&gt;连接&lt;/a&gt; &lt;a :href=\"message +'abc'\"&gt;连接&lt;/a&gt; &lt;!-- 属性内的模板变量写法已被移除，使用v-bind:attr 或 :attr --&gt;&lt;/div&gt;var vm = new Vue(&#123; el: \"#app\", data: &#123; message: \"https://www.baidu.com\" &#125;&#125;) 可以通过v-bind指令或者:的简写对某个dom元素的属性进行绑定 在下面还有更加详细的属性绑定示例 事件绑定v-on 给元素绑定对应事件，以下是对于点击事件的绑定 123456789101112&lt;div id=\"app\"&gt; &lt;button v-on:click=\"show\"&gt;按钮&lt;/button&gt; &lt;button @click=\"show\"&gt;按钮&lt;/button&gt;&lt;/div&gt;new Vue(&#123; el: \"#app\", method: &#123; show: function()&#123; alert(\"弹一下\") &#125; &#125;&#125;) 跑马灯效果 这里有一个跑马灯效果可以玩耍 12345678910111213141516171819202122232425262728293031&lt;div id=\"app\"&gt; &lt;h3 v-html=\"message\"&gt;&lt;/h3&gt; &lt;button @click=\"start\"&gt;开始&lt;/button&gt; &lt;button @click=\"stop\"&gt;停止&lt;/button&gt;&lt;/div&gt;new Vue(&#123; el: \"#app\", data: &#123; message: \"这是一个跑马灯\", sT: null, // 定时器实例 &#125;, methods:&#123; work()&#123; this.message = this.message.substring(1) + this.message[0] // 循环定时器所作的事情 &#125;, start()&#123; if (this.sT==null) &#123; // 判断此时是否已有定时器开启 console.log(\"开启定时器\") this.sT = setInterval(this.work,400) &#125; else &#123; console.log(\"已经开启 不在开启\") &#125; &#125;, stop()&#123; // 关闭定时器 设置定时器变量为null console.log(\"关闭定时器\") clearInterval(this.sT) this.sT = null &#125; &#125; 绑定事件修饰符阻止冒泡 比如一个按钮在一个div中，并且按钮和div均有自己的事件，那么此时点击按钮，事件会像冒泡一样从按钮开始一直到div进行触发，.stop修饰符用来阻止默认的事件触发行为 12345678910111213141516171819&lt;div id=\"fDiv\" @click=\"divClick\"&gt; &lt;button id=\"fBtn\" @click=\"btnClick\"&gt;按钮&lt;/button&gt;&lt;/div&gt;&lt;script type=\"text/javascript\"&gt; window.onload = function()&#123; var vm = new Vue(&#123; el: \"#fDiv\", // 控制区域 data: &#123;&#125;, methods: &#123; divClick()&#123; console.log(\"div被点击了\") &#125;, btnClick()&#123; console.log(\"按钮被点击了\") &#125; &#125;, &#125;) &#125;&lt;/script&gt; 通过.stop修饰阻止冒泡 123&lt;div id=\"fDiv\" @click=\"divClick\"&gt; &lt;button id=\"fBtn\" @click.stop=\"btnClick\"&gt;按钮&lt;/button&gt;&lt;/div&gt; 阻止默认行为 比如像a标签这样的，在点击时他有默认的跳转动作，可以通过.prevent阻止该默认行为 1234567891011&lt;div id=\"fDiv\"&gt; &lt;a href=\"https://www.baidu.com\" @click.prevent=\"aLink\"&gt;去百度&lt;/a&gt;&lt;/div&gt;var vm = new Vue()&#123; el: \"#fDiv\", methods:&#123; aLink()&#123; console.log(\"连接被点击\") &#125; &#125; &#125; 捕获事件 默认的事件触发处理机制是冒泡机制，capture代表具有该修饰的事件，会优先触发，脱离冒泡顺序； 也可理解为谁有该修饰符，先触发谁的事件 12345678910111213141516171819&lt;div id=\"fDiv\" @click.capture=\"divClick\"&gt; &lt;button id=\"fBtn\" @click=\"btnClick\"&gt;按钮&lt;/button&gt;&lt;/div&gt;&lt;script type=\"text/javascript\"&gt; window.onload = function()&#123; var vm = new Vue(&#123; el: \"#fDiv\", // 控制区域 data: &#123;&#125;, methods: &#123; divClick()&#123; console.log(\"div被点击了\") &#125;, btnClick()&#123; console.log(\"按钮被点击了\") &#125; &#125;, &#125;) &#125;&lt;/script&gt; 自身事件 与capture和冒泡不同，.self只有是自身触发的当前的事件才真正执行处理的回调函数 并且.self只会阻止当前元素的事件触发行为 1234&lt;div id=\"fDiv\" @click.self=\"divClick\"&gt; &lt;button id=\"fBtn\" @click.self=\"btnClick\"&gt;按钮&lt;/button&gt;&lt;/div&gt;// 与上同 单次事件 使用.once只触发一次事件函数 123456789101112&lt;div id=\"fDiv\"&gt; &lt;a href=\"https://www.baidu.com\" @click.prevent.once=\"aLink\"&gt;去百度&lt;/a&gt; &lt;!-- 连接无法跳转的阻止事件 只会出现一次 --&gt;&lt;/div&gt;var vm = new Vue()&#123; el: \"#fDiv\", methods:&#123; aLink()&#123; console.log(\"连接被点击\") &#125; &#125; &#125; 表单双向绑定v-model 使用v-model指令可以在表单input、textarea以及select元素上创建双向数据绑定 根据表单上的值，自动更新模板变量中的值 v-model会忽略表单的初始值，比如：checked、value、selected，如果需要的话，应该在javascript中首先声明初始值 text1234567891011121314&lt;div id=\"container\"&gt; &lt;h3 v-html=\"message\"&gt;&lt;/h3&gt; &lt;input type=\"text\" v-model=\"message\"&gt;&lt;/div&gt;&lt;script&gt; window.onload = function()&#123; var vm = new Vue(&#123; el: \"#container\", data: &#123; message: \"这是个表单内容\", &#125;, &#125;) &#125;&lt;/script&gt; textarea12345&lt;div id=\"container\"&gt; &lt;h3 v-html=\"message\"&gt;&lt;/h3&gt; &lt;textarea v-model=\"message\"&gt;&lt;/textarea&gt;&lt;/div&gt;// 同上 checkbox 单个复选框：数据为绑定为true和false的布尔值 1234567891011121314&lt;div id=\"container\"&gt; &lt;h3 v-html=\"checked\"&gt;&lt;/h3&gt; &lt;input type=\"checkbox\" v-model=\"checked\"&gt;&lt;/div&gt;&lt;script&gt; window.onload = function()&#123; var vm = new Vue(&#123; el: \"#container\", data: &#123; checked: true, &#125;, &#125;) &#125;&lt;/script&gt; 多个复选框：选中的结果会绑定到同一个数组，将保存的v-model变量创建为数组 12345678910111213141516&lt;div id=\"container\"&gt; &lt;h3 v-html=\"checked\"&gt;&lt;/h3&gt; &lt;input name=\"fruit\" type=\"checkbox\" value=\"apple\" v-model=\"checked\"&gt;苹果 &lt;input name=\"fruit\" type=\"checkbox\" value=\"banana\" v-model=\"checked\"&gt;香蕉 &lt;input name=\"fruit\" type=\"checkbox\" value=\"orange\" v-model=\"checked\"&gt;橘子&lt;/div&gt;&lt;script&gt; window.onload = function()&#123; var vm = new Vue(&#123; el: \"#container\", data: &#123; checked: new Array, &#125;, &#125;) &#125;&lt;/script&gt; radio123456789101112131415&lt;div id=\"container\"&gt; &lt;h3 v-html=\"picked\"&gt;&lt;/h3&gt; &lt;input type=\"radio\" name=\"gender\" value=\"junior\" v-model=\"picked\"&gt;男 &lt;input type=\"radio\" name=\"gender\" value=\"girl\" v-model=\"picked\"&gt;女&lt;/div&gt;&lt;script&gt; window.onload = function()&#123; var vm = new Vue(&#123; el: \"#container\", data: &#123; picked: \"哈哈哈哈\", &#125;, &#125;) &#125;&lt;/script&gt; select12345678910111213141516171819&lt;div id=\"container\"&gt; &lt;h3 v-html=\"selected\"&gt;&lt;/h3&gt; &lt;select v-model=\"selected\"&gt; &lt;option disabled value=\"\"&gt;你想去哪&lt;/option&gt; &lt;option value=\"山西\"&gt;山西&lt;/option&gt; &lt;option value=\"北京\"&gt;北京&lt;/option&gt; &lt;option value=\"上海\"&gt;上海&lt;/option&gt; &lt;/select&gt;&lt;/div&gt;&lt;script&gt; window.onload = function()&#123; var vm = new Vue(&#123; el: \"#container\", data: &#123; selected: \"\", &#125;, &#125;) &#125;&lt;/script&gt; selects 设置select标签的multiple属性即可设置为多选下拉菜单，按着ctrl键可以多选 123456789101112131415161718&lt;div id=\"container\"&gt; &lt;h3 v-html=\"selecteds\"&gt;&lt;/h3&gt; &lt;select multiple v-model=\"selecteds\"&gt; &lt;option value=\"上衣\"&gt;上衣&lt;/option&gt; &lt;option value=\"裤子\"&gt;裤子&lt;/option&gt; &lt;option value=\"鞋\"&gt;鞋&lt;/option&gt; &lt;/select&gt;&lt;/div&gt;&lt;script&gt; window.onload = function()&#123; var vm = new Vue(&#123; el: \"#container\", data: &#123; selecteds: new Array, // 多重数据一般都要保存成数组 &#125;, &#125;) &#125;&lt;/script&gt; 修饰符.lazy 默认情况下，v-model在input和textarea表单中进行同步输入框的改动 添加了.lazy修饰符之后，对应的v-model绑定事件触发机制将变为change事件，只有在光标失去焦点时会触发 1234567891011121314&lt;div id=\"container\"&gt; &lt;h3 v-html=\"message\"&gt;&lt;/h3&gt; &lt;input type=\"text\" v-model.lazy=\"message\"&gt;&lt;/div&gt;&lt;script&gt; window.onload = function()&#123; var vm = new Vue(&#123; el: \"#container\", data: &#123; message: \"这是个表单内容\", &#125;, &#125;) &#125;&lt;/script&gt; .number 如果用户希望将输入表单的内容处理为Number类型，可以使用.number给v-model进行修饰；如果表单字符串无法被处理为数字，则返回原始的值 1234&lt;div id=\"container\"&gt; &lt;h3 v-html=\"typeof message\"&gt;&lt;/h3&gt; &lt;input type=\"text\" v-model.number=\"message\"&gt;&lt;/div&gt; .trim 使用.trim可以自动过滤输入框的首尾空格 123456&lt;div id=\"container\"&gt; &lt;input type=\"text\" v-model.trim=\"message\"&gt; &lt;br&gt; &lt;input type=\"text\" v-model=\"message\"&gt; &lt;!-- 通过查看另一个表单中同步的缩进 --&gt;&lt;/div&gt; 动态绑定 当某些情况下，无法确定表单中所代表的属性值，可以使用v-bind进行动态绑定，v-model获取到的表单输入此时则是我们定义的v-bind属性值 123456789101112131415161718&lt;div id=\"container\"&gt; &lt;h3 v-html=\"message\"&gt;&lt;/h3&gt; &lt;input type=\"radio\" v-model=\"message\" :value=\"choiceA\"&gt; A &lt;input type=\"radio\" v-model=\"message\" :value=\"choiceB\"&gt; B&lt;/div&gt;&lt;script&gt; window.onload = function () &#123; var vm = new Vue(&#123; el: \"#container\", data: &#123; message: \"\", // 表单绑定变量 choiceA: \"Yes!\", // 属性绑定变量，未来不需要修改标签中的value值即可动态修改 choiceB: \"No!\", &#125;, &#125;) &#125;&lt;/script&gt; 计算属性 关键词：computed 模板内的表达式非常便利，但是设计它们的初衷是用于简单运算的 在模板中放入太多的逻辑会让模板过重且难以维护 也就是说，某些时候页面中的模板变量如果需要复杂的运算处理，应该使用计算属性，而不是直接在模板位置进行计算。 12345678910111213141516171819202122232425262728&lt;script type=\"text/javascript\"&gt; window.onload = function () &#123; var vm = new Vue(&#123; el: \"#container\", data: &#123; String1:\"这是一个字符串\", &#125;, methods: &#123; MreverseString()&#123; return this.String1.split(\"\").reverse().join(\"\") &#125; // 定义一个函数进行字符串逆置 &#125;, computed: &#123; CreverseString()&#123; return this.String1.split(\"\").reverse().join(\"\") &#125; // 定义一个计算属性进行字符串逆置 &#125; &#125;) &#125;&lt;/script&gt;&lt;div v-cloak id=\"container\"&gt; &lt;p&gt;这是一个字符串:&#123;&#123; String1 &#125;&#125; &lt;/p&gt; &lt;p&gt;他的逆置:&#123;&#123; String1.split(\"\").reverse().join(\"\") &#125;&#125; &lt;/p&gt; &lt;p&gt;他的逆置:&#123;&#123; CreverseString &#125;&#125; &lt;/p&gt; &lt;!-- 计算属性直接写入函数名 --&gt; &lt;p&gt;他的逆置:&#123;&#123; MreverseString() &#125;&#125; &lt;/p&gt; &lt;!-- 普通methods函数调用需加括号 --&gt;&lt;/div&gt; 注意：虽然计算属性和函数都可以达成同样的目的，但是computed会缓存结果，计算属性如果发现依赖的属性message未发生改变，再次访问计算属性不会重复运算函数，而是直接利用已有结果；如果依赖数据发生改动，计算属性函数才会重新运算。 在函数及计算属性中添加日志输出即可看到这个效果： 123456789101112methods: &#123; MreverseString() &#123; console.log(\"MreverseString被运算了\") return this.String1.split(\"\").reverse().join(\"\") &#125;&#125;,computed: &#123; CreverseString() &#123; console.log(\"CreverseString被运算了\") return this.String1.split(\"\").reverse().join(\"\") &#125;&#125; 在终端下进行计算属性以及函数的访问即可看到效果。 计算属性SetAttr 默认的计算属性只有获取getattr的方式，我们可以手动为他添加一个setter 1234567891011computed:&#123; CreverseString: &#123; get: function()&#123; return this.String1.split(\"\").reverse().join(\"\") &#125; set: function(val)&#123; this.String1 = val.split(\"\").reverse().join(\"\") // 如果当前的逆置之后字符串为val，那么原本的字符串需要再颠倒一次 &#125; &#125;&#125; 侦听属性 侦听属性的作用是侦听某些属性的变化，从而做相应的操作，进行对数据变化的相应， 侦听属性是一个对象（字典），key值是要监听的元素，值是当监听的元素发生改变时要执行的函数； 监听函数有两个参数，一个是当前值，另一个是变化后的值 比如监听一个变量的变化 123456789101112131415161718192021&lt;script type=\"text/javascript\"&gt; window.onload = function()&#123; var vm = new Vue(&#123; el: \"#container\", data:&#123; content: \"\", // 表单内容 count: 0, // 记录表单内用户敲了多少次 &#125;, watch:&#123; content:function (oldVal,newVal)&#123; // 只要在文本框输入内容影响到了age数据发生改变，就会触发 this.count += 1 &#125;， &#125;， &#125;) &#125;&lt;/script&gt;&lt;div id=\"container\"&gt; &lt;p&gt;&lt;label&gt;你敲了:&#123;&#123; count &#125;&#125;次&lt;/label&gt;&lt;/p&gt; &lt;input type=\"text\" placeholder=\"请输入你的年纪\" v-model=\"content\"&gt;&lt;/div&gt; 属性绑定 使用v-bind:class指令来设置元素的class属性； 属性表达式的类型可以是字符串、对象或数组 数组属性 可以通过为元素绑定一个数组，用来为元素设置单个或多个样式，类名在数组中用单引号 1234567891011&lt;style type=\"text/css\"&gt; .fontBold &#123; font-weight: bold; &#125; .fontRed &#123; color: red; &#125;&lt;/style&gt;&lt;div id=\"container\"&gt; &lt;p :class=\"['fontBold','fontRed']\"&gt;这是一个段落&lt;/p&gt;&lt;/div&gt; 动态属性 可以通过为元素绑定一个对象，对象的key是样式类，对象的value是true或false来动态切换class 12345678910111213141516171819202122232425&lt;script type=\"text/javascript\"&gt; window.onload = function () &#123; var vm = new Vue(&#123; el: \"#container\", data: &#123; flag: true, &#125;, methods: &#123; toggle() &#123; if (this.flag)&#123; // 判断当前toggle变量的属性，对称变换 this.flag = false &#125;else&#123; this.flag = true &#125; &#125; &#125; &#125;) &#125;&lt;/script&gt;&lt;div id=\"container\"&gt; &lt;p :class=\"&#123;fontBold: flag&#125;\" @click=\"toggle\"&gt;这是一个段落&lt;/p&gt; &lt;p :class=\"&#123;flag? fontBold:''&#125;\" @click=\"toggle\"&gt;这是一个段落&lt;/p&gt; &lt;!-- 三元表达式 --&gt;&lt;/div&gt; 样式绑定 使用v-bind:style语法，为元素绑定样式 123&lt;p :style=\"&#123;color:'red','font-weight':'bold'&#125;\"&gt; 一段文字&lt;/p&gt; 也可以在vue的data中定义一个对象，用来描述样式，其中带有连字符的样式属性要加引号 123456789&lt;div id=\"container\"&gt; &lt;p :style=\"styleObj\"&gt;一段文字&lt;/p&gt;&lt;/div&gt;data: &#123; styleObj: &#123; color:'red', 'font-weight':'bold', &#125;&#125;, data中的对象也可以通过数组类型绑定到元素上 123456789101112&lt;div id=\"container\"&gt; &lt;p :style=\"[styleObj1,styleObj2]\"&gt;一段文字&lt;/p&gt; &lt;!-- 对于js的样式绑定不需要加引号，因为就是一个变量 --&gt;&lt;/div&gt;styleObj1: &#123; border: '1px solid gray', width: '100px',&#125;,styleObj2:&#123; background: 'black', color: 'blue',&#125; 条件渲染 通过条件指令可以控制元素的显示及隐藏，或者说叫做创建和销毁 v-if v-if指令用于条件性的渲染一块内容。这块内容只会在指令的表达式返回truthy值的时候渲染 12345678910111213141516171819&lt;div v-cloak id=\"container\"&gt; &lt;h3 v-if=\"oh3\"&gt;h3标题&lt;/h3&gt; &lt;p v-if=\"gender === 'girl'\"&gt;你是女的&lt;/p&gt; &lt;p v-else-if=\"gender === 'boy'\"&gt;你是男的&lt;/p&gt; &lt;p v-else&gt;不男不女&lt;/p&gt;&lt;/div&gt;&lt;script type=\"text/javascript\"&gt; window.onload = function()&#123; var vm = new Vue(&#123; el: \"#container\", data:&#123; oh3:\"a\", gender: 'other' &#125;, &#125;) &#125;&lt;/script&gt; truthy和ture的区别： 隐含有true属性的变量不可以认为它是true，它不是boolean类型 v-show 与v-if不同的是，v-show 的元素始终会被渲染并保留在DOM中 12&gt; v-show` 只是简单地切换元素的`CSS`属性 `display&gt; 12345678910111213141516&lt;div v-cloak id=\"container\"&gt; &lt;h3 v-if=\"oh3\"&gt;h3标题&lt;/h3&gt; &lt;h4 v-show=\"oh4\"&gt;h4标题&lt;/h4&gt;&lt;/div&gt;&lt;script type=\"text/javascript\"&gt; window.onload = function()&#123; var vm = new Vue(&#123; el: \"#container\", data:&#123; oh3:\"1\", // v-if 在该变量不为真时直接消失在document中 oh4:\"1\", // v-show 处理不为真的变量条件 绑定元素不会消失 &#125;, &#125;) &#125;&lt;/script&gt; 列表渲染v-for 把一个数组对应为一组元素 用 v-for 指令根据一组数组的选项列表进行渲染 v-for 指令需要使用 item in items 形式的特殊语法，items 是源数据数组并且 item 是数组元素迭代的别名 1234567891011121314151617181920&lt;ol id=\"container\"&gt; &lt;li v-for=\"user in users\"&gt; &lt;span&gt;&#123;&#123; user.name &#125;&#125;&lt;/span&gt; &lt;/li&gt;&lt;/ol&gt;&lt;script type=\"text/javascript\"&gt; window.onload = function()&#123; var vm = new Vue(&#123; el: \"#container\", data:&#123; users: [ &#123;name:\"张三\",age:18&#125;, &#123;name:\"李四\",age:20&#125;, &#123;name:\"王五\",age:19&#125;, ] &#125;, &#125;) &#125;&lt;/script&gt; v-for还可以支持将当前循环索引作为渲染时的第二个参数，第二个参数为访问索引位置 12345678910&lt;p v-for=\"(user,index) in users\"&gt; &#123;&#123; index &#125;&#125;:&#123;&#123; user.age &#125;&#125;&lt;/p&gt;data:&#123; users: [ &#123;name:\"张三\",age:18&#125;, &#123;name:\"李四\",age:20&#125;, &#123;name:\"王五\",age:19&#125;, ]&#125;, 使用v-for迭代访问一个对象 12345678&lt;p v-for=\"key in myself\"&gt; &#123;&#123; key &#125;&#125; &lt;!-- 当v-for渲染时只有一个参数，此时参数为value值 --&gt;&lt;/p&gt;myself : &#123; name:\"赵六\", age:\"17\",&#125; v-for支持最多三个参数，同时获取遍历对象的key和value值，以及index索引位置 要注意的是，此时的key和value和python中的顺序是颠倒的，key在后，value在前 1234567&lt;p v-for=\"(value,key,index) in myself\"&gt; &#123;&#123; index &#125;&#125;: &#123;&#123; key &#125;&#125; - &#123;&#123; value &#125;&#125;&lt;/p&gt;myself : &#123; name:\"孙七\", age:\"17\",&#125; v-for进行一段取值 123456&lt;div&gt; &lt;p v-for=\"n in 8\"&gt; &#123;&#123; n &#125;&#125; &lt;/p&gt; &lt;!-- 1 2 3 4 5 6 7 8 --&gt;&lt;/div&gt; 选项卡练习1234567891011121314151617181920212223242526272829303132333435363738&lt;script type=\"text/javascript\"&gt; window.onload = function()&#123; var vm = new Vue(&#123; el: \"#container\", data: &#123; choicId: null, &#125; &#125;) &#125;&lt;/script&gt;&lt;style&gt; li&#123; list-style-type: none; border: 3px outset lightgreen; width: 100px; background:lightblue; margin:5px; &#125; li:hover&#123; border: 3px inset gray; cursor: pointer; &#125; [v-cloak]&#123; display: none; &#125;&lt;/style&gt;&lt;div v-cloak id=\"container\"&gt; &lt;ol list&gt; &lt;li @click=\"choicId = 1\"&gt;A&lt;/li&gt; &lt;li @click=\"choicId = 2\"&gt;B&lt;/li&gt; &lt;li @click=\"choicId = 3\"&gt;C&lt;/li&gt; &lt;li @click=\"choicId = 4\"&gt;D&lt;/li&gt; &lt;/ol&gt; &lt;p v-show=\"choicId == 1\"&gt;aaaaaaaaaa&lt;/p&gt; &lt;p v-show=\"choicId == 2\"&gt;bbbbbbbbbb&lt;/p&gt; &lt;p v-show=\"choicId == 3\"&gt;cccccccccc&lt;/p&gt; &lt;p v-show=\"choicId == 4\"&gt;dddddddddd&lt;/p&gt;&lt;/div&gt; js中两个等号和三个等号的区别： ==表示： 如果两边值的类型不同的时候，是要先先进行类型转换后，才能做比较；equality等同 ===表示：不需要做类型转换，如果两边值的类型不同，就表示一定是不等的identity恒等 注意 Vue无法检测到对于数组的索引设置及长度修改以及对于对象属性的删除或添加 但是可以通过以下方式进行属性添加触发状态更新 123Vue.set($vm.Object,\"key\",\"val\") // 对于对象 这样的添加方式可以触发状态更新Vue.set($vm.Array, index, newVal) // 对于数组 添加元素 触发状态更新// vm.items.splice(newLength) // 设置数组长度 javascript.splice(where, num, [additem1,additem2...] )：删除或添加元素 此外，当v-for与v-if同时使用时，v-for有更高的优先级，这会造成重复遍历得到的元素都要在做一次v-if的判断，如果我们是为了有目的判断当前是否需要渲染这个元素，或是跳过这个循环，可以将v-if放在外层元素，比如template标签中，(template标签无实际意义，默认不展示，但是可以起到包裹作用) 过滤器 Vue.js允许你自定义过滤器，可被用于一些常见的文本，对它们进行格式化 过滤器可以用在两个地方：双花括号插值和 v-bind 表达式 (后者从 2.1.0+ 开始支持) 过滤器应该被添加在JavaScript表达式的尾部，由管道符号指示 语法 12345&lt;p&gt; &#123;&#123; message | filter &#125;&#125;&lt;/p&gt;&lt;p v-bind:type=\"message | filter\"&gt; &lt;/p&gt; 过滤器本质上是一个函数，比如我们定义一个将表单输入的内容中所有的字母变大写的过滤器 1234567891011121314151617181920212223&lt;body&gt; &lt;div v-cloak id=\"container\"&gt; &lt;input type=\"text\" v-model=\"message\"&gt; &lt;p&gt;展示: &#123;&#123; message | toUpper &#125;&#125;&lt;/p&gt; &lt;/div&gt;&lt;/body&gt;&lt;script type=\"text/javascript\"&gt; window.onload = function () &#123; var vm = new Vue(&#123; el: \"#container\", data: &#123; message: \"\", &#125;, filters: &#123; toUpper: function (value) &#123; if (!value) return '' // 字符串内容为空 直接返回 console.log(\"正在变大小\") return String(value).toUpperCase() &#125; &#125; &#125;) &#125;&lt;/script&gt; 过滤器函数也可以有多个参数 1234567891011121314&#123;&#123; message | filter(arg1, arg2) &#125;&#125;// message 第一个参数// arg1 第二个参数// arg2 第三个参数&lt;div v-cloak id=\"container\"&gt; &lt;input type=\"text\" v-model=\"message\"&gt; &lt;p&gt;展示: &#123;&#123; message | toLong(\"| \",\" |\") &#125;&#125;&lt;/p&gt;&lt;/div&gt;filters: &#123; toLong(value,arg1,arg2)&#123; if (!value) return '' return arg1 + value + arg2 &#125;&#125; Vue实例生命周期 每个Vue实例在被创建时都要经过一系列的初始化过程 例如：需要设置数据监听、编译模板、将实例挂载到DOM并在数据变化时更新DOM等 同时在这个过程中会自动运行一些叫做生命周期钩子的函数，我们可以使用这些函数，在实例的不同阶段加上我们需要的代码，实现特定的功能 beforeCreate：数据还没有监听，没有绑定到vue对象实例，同时也没有挂载对象 created：数据已经绑定到了对象实例，但是还没有挂载对象 beforeMount：模板已经编译好了，根据数据和模板已经生成了对应的元素对象，将数据对象关联到了对象的$el属性 $el属性是一个HTMLElement对象，也就是这个阶段，vue实例通过原生的createElement等方法来创建这个html片段，准备注入到我们vue实例指明的el属性所对应的挂载点 mounted： 将$el的内容挂载到了el，相当于我们在jQuery执行了$(el).html($el)，生成页面上真正的dom 上面我们就会发现页面的元素和我们$el的元素是一致的；在此之后，我们能够用方法来获取到el元素下的dom对象，并进行各种操作 beforeUpdate：数据发生变化时调用 updated：由于数据更改导致的虚拟DOM重新渲染和打补丁，在这之后会调用该钩子 beforeDestroy：Vue实例销毁前 destroyed：Vue实例销毁后 12&gt; window.$vm.$destroy()&gt; 一大段代码进行钩子函数的调用过程监控 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;script type=\"text/javascript\"&gt; window.onload = function () &#123; function showData(process, vm) &#123; console.log(process) console.log(\"vue数据:\", vm.message) // 当前Vue中的数据 console.log(\"Vue挂载el:\") // Vue接管的元素 console.log(vm.$el) console.log(\"真实Dom:\") console.log(document.getElementById(\"container\").innerHTML) console.log('-----------------') &#125; // 这个函数用来输出相关信息的 new Vue(&#123; el: \"#container\", data: &#123; message: \"aaaaa\", &#125;, beforeCreate: function () &#123; showData(\"创建Vue实例前\", this) &#125;, created: function () &#123; showData(\"创建Vue实例后\", this) &#125;, beforeMount: function () &#123; showData(\"挂载到Dom前\", this) &#125;, mounted: function () &#123; showData(\"挂载到Dom后\", this) &#125;, beforeUpdate: function () &#123; showData(\"数据发生变化时\", this) &#125;, updated: function () &#123; showData(\"数据发生变化后\", this) &#125;, beforeDestroy: function () &#123; showData(\"Vue实例销毁前\", this) &#125;, destroyed: function () &#123; showData(\"Vue实例销毁后\", this) &#125; &#125;)&#125;&lt;/script&gt;&lt;div id=\"container\"&gt; &lt;p v-html=\"message\"&gt;&lt;/p&gt;&lt;/div&gt; 组件ES6语法 ES6是JavaScript语言的新版本，它也可以叫做ES2015，之前学习的JavaScript属于ES5，ES6在它的基础上增加了一些语法 ES6是未来JavaScript的趋势，而且vue组件开发中会使用很多的ES6的语法，所以掌握这些常用的ES6语法是必须的 变量声明 let：定义封闭作用域的变量，并且变量只能声明一次 const：定义封闭作用域的常量，并且变量只能声明一次 let和const是新增的声明变量的开头的关键字，在这之前，变量声明是用var关键字 这两个关键字和var的区别是，它们声明的变量没有预解析，无法脱离定义空间使用 let和const的区别是，let声明的是一般变量，const申明的常量，不可修改 12345678910console.log(a) // undefinedconsole.log(b) // b is not definedconsole.log(c) // c is not definedvar a = 1var a = 2let b = 2// let b = 3 // Identifier 'b' has already been declaredconst c = 3// const c = 4 // Identifier 'c' has already been declaredc = 4 // Assignment to constant variable 箭头函数 可以把箭头函数理解成匿名函数的第二种写法，箭头函数的作用是可以在对象中绑定this 解决了JavaScript中this指定混乱的问题 定义函数的一般方式 123function func()&#123; ...&#125; 匿名赋值创建函数 123var func = function()&#123; ...&#125; 箭头函数的写法 123456789101112131415161718192021222324var func = (a, b) =&gt; &#123; // 这样的函数在嵌套时，会自动绑定外部作用域下的this&#125;var func = a =&gt; &#123; // 一个参数时，可以省略参数&#125;window.onload = function () &#123; var vm = new Vue(&#123; el: \"#container\", data: &#123; message: \"abcdef\", &#125;, methods: &#123; show() &#123; console.log(\"这是show函数:\", this.message), func = () =&gt; &#123; console.log(\"我是内部函数:\", this.message) &#125;, func(), // 调用一下这个内部函数 &#125; &#125; &#125;)&#125;&lt;div id=\"container\"&gt; &lt;button @click=\"show\"&gt;按钮&lt;/button&gt;&lt;/div&gt; Vue组件 组件Component是Vue.js最强大的功能之一 组件可以扩展HTML元素，封装可重用的代码 所有的Vue组件同时也都是Vue的实例，所以可接受相同的选项对象（除了一些根级特有的选项）并提供相同的生命周期钩子 注册全局组件 注册一个全局组件语法格式如下 123Vue.component(tagName, options)// tagName：组件名// options：配置选项 比如这样一个全局组件 123456789Vue.component('button_show', &#123; data: function () &#123; return &#123; count: 0 &#125; &#125;, // 当前组件会需要的数据，定义为函数的返回值 template: '&lt;button @click=\"count++\"&gt;按钮:&#123;&#123; count &#125;&#125;&lt;/button&gt;' // 组件的标签模板&#125;) 接下来可以在任何Vue接管的元素中使用该组件， 12345678&lt;div id=\"container\"&gt; &lt;button_show&gt;&lt;/button_show&gt;&lt;/div&gt;window.onload = function () &#123; var vm = new Vue(&#123; el: \"#container\", &#125;)&#125; data必须是函数 组件就是vue的实例，所有vue实例中属性和方法，组件中也可以用 其中data属性必须是一个函数，因为组件会重复使用在多个地方，为了使用在多个地方的组件数据相对独立，data属性需要用一个函数的返回值来将数据处理为不同的每个个体 Prop传递数据 Prop是你可以在组件上注册的一些自定义特性 当一个值传递给一个prop特性的时候，它就变成了那个组件实例的一个属性 为了给组件传递数据，我们可以用一个 props 选项将一些特性值列举在其中 12345678910111213141516171819202122232425&lt;script type=\"text/javascript\"&gt; Vue.component(\"myp\",&#123; props: [\"content\",\"like\"], // 需要两个外界传入的值 template: \"&lt;p :class='like'&gt;&#123;&#123; content &#125;&#125;&lt;/p&gt;\" // 组件绑定未来要接受的变量，要用到v:bind &#125;) window.onload = function()&#123; var vm = new Vue(&#123; el: \"#container\", data: &#123; content: '这是p段落的文本', like: 'beauty', // 要传递的变量 &#125; &#125;) &#125;&lt;/script&gt;.beauty&#123; width: 100px; color: red; background: green;&#125;&lt;div id=\"container\"&gt; &lt;myp :like=\"like\" :content=\"content\"&gt;&lt;/myp&gt; &lt;!-- 传递到组件中 --&gt;&lt;/div&gt;","categories":[],"tags":[{"name":"Django","slug":"Django","permalink":"http://laxe.top/tags/Django/"}]},{"title":"JavaScript","slug":"JavaScript","date":"2019-10-21T02:51:45.043Z","updated":"2019-10-21T02:52:45.093Z","comments":true,"path":"2019/10/21/JavaScript/","link":"","permalink":"http://laxe.top/2019/10/21/JavaScript/","excerpt":"JavaScript JavaScript是运行在浏览器端的脚本语言，JavaScript主要解决的是前端与用户交互的问题 是一种动态性、弱类型的语言； 他的解释器就在我们的浏览器中，是浏览器的一部分 这门语言对大小写敏感，并会忽略多余的空格，可以使用\\进行代码换行，注释使用//或/**/","text":"JavaScript JavaScript是运行在浏览器端的脚本语言，JavaScript主要解决的是前端与用户交互的问题 是一种动态性、弱类型的语言； 他的解释器就在我们的浏览器中，是浏览器的一部分 这门语言对大小写敏感，并会忽略多余的空格，可以使用\\进行代码换行，注释使用//或/**/ 主要由三部分组成 ECMAScript：语言的语法和基本对象 文档对象模型Dom(Document Object Model)：处理网页内容的方法和接口 浏览器对象模型Bom(BrowserObjectModel)：与浏览器进行交互的方法和接口 前端三大部 HTML：页面的内容、结构 CSS：页面的表现形式、部分动画 JavaScript：页面的行为、交互、功能 JavaScript引入 行间事件：为某一个具体的元素标签赋予js内容 1&lt;input type=\"button\" value=\"按钮\" onclick=\"alert('点我');\"&gt; 嵌入引入：在文档页面通过Script标签嵌入 123456&lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;script type=\"text/javascript\"&gt; alert(\"ok!\"); &lt;/script&gt;&lt;/head&gt; 外部引入：定义单独js文件，通过script标签进行引入 1&lt;script type=\"text/javascript\" src=\"js/main.js\"&gt;&lt;/script&gt; alert函数用来展示一个提示框 变量定义 123var x = 1var y = \"2\"var z = 2 定义变量需要使用关键字：var 同时定义多个变量可以使用 ， 隔开 注意：javascript变量均为对象，每当声明一个变量，就相当于创建了一个对象 命名规则： 区分大小写 首字符为字母、数字、下划线_、或美元符号$ 其他字符可以为字母、数字、下划线、美元符号 调试程序的方法： alert：弹框 console.log()：浏览器控制台 document.title()：页面标题 基本数据类型 Number：数字类型，可以带小数点，也可以不带 12var a = 1;var b = 1.5; String：字符串类型，可以使用单引号或双引号 12var a = \"abc\";var b = \"aaaa\" + 1 Boolean：布尔类型，只能是true|false 1var a = true; undefined：未定义类型 1var a; null：空对象类型 1var a = null; 查看变量数据类型 12var x = \"abc\";alert(typeof x) 匈牙利命名规则： 对象 o (Object)：oPerson 数组 a (Array)：aUsers 字符串 s (String)：sAccount 整数 i (Integer)：iScore 布尔值 b (Boolean)：bIsLogin 浮点数 f (Float)：fPrice 函数 f (Function)：fEats 正则 re (RegExp)：reIDCard 类型转换 转换为字符串：toString，支持Boolean、Number、String三种主要类型 123456var x = 1;var y = \"abc\";var z = true;alert(x.toString()) // \"1\"alert(y.toString()) // \"abc\"alert(z.toString()) // \"true\" 转换为数字：parseInt、parseFloat，将只含有数字的字符串变为整形或浮点型，其他类型返回NaN() 123456789var x = \"123\"var y = \"123.01\"var z = \"123aa\"alert(parseInt(x)) // 123alert(parseFloat(x)) // 123alert(parseInt(y)) // 123alert(parseFloat(y)) // 123.01alert(parseInt(z)) // 123alert(parseFloat(z)) // 123 注意：parseFloat转换的包含浮点数的字符串应该是十进制 八进制或十六进制，该方法会忽略前导0 八进制数字020会被解析为20 十六进制数字0xFF，会返回Nan，因为x符号不是有效字符 强制类型转换 Boolean()：当要转换的值是至少有一个字符的字符串 非0数字或对象时，Boolean()函数将返回true 如果该值是空字符串、数字0、undefined或null，它将返回false。 1234alert(Boolean(0)) // falsealert(Boolean(1)) // truealert(Boolean(\"1\")) // truealert(Boolean(\"1a\")) // true Number()：换与parseInt()和parseFloat()方法的处理方式相似，只是它转换的是整个值，而不是部分值 123456789alert(Number(false)) // 0alert(Number(true)) // 1alert(Number(undefined)) // NaNalert(Number(null)) // 0alert(Number(\"1.2\")) // 1.2alert(Number(\"12\")) // 12alert(Number(\"1.2.3\")) // NaNalert(Number(new object())) // NaNalert(Number(50)) // 50 String()：可把任何值转换成字符串 注意：强制转换成字符串和调用toString()方法的唯一不同之处在于，对null和undefined值强制类型转换可以生成字符串而不引发错误 复合类型 Array：数组，索引从0开始 123456var people = ['张三','李四','王五'];var people = new Array('张三','李四','王五');var people = new Array();people[0] = \"张三\"people[1] = \"李四\"people[2] = \"王五\" Object：对象，就像是字典，定义时key值不需要设置类型 1234567891011var person = &#123; name: \"张三\", age: 18, sex: \"male\",&#125;;/*对象有两种访问方式：*/person[\"name\"]person.namevar person = new Object();person.name = \"张三\";person.age = 17; 函数 函数语法：包裹在花括号中的代码块，前面使用了关键词function 12345678910&lt;button onclick=\"func()\"&gt;点击这里&lt;/button&gt;function func(arg1,arg2,...) &#123; alert(\"函数被执行\") // 执行代码 return 1; // return是可选的，并且可以不写返回值，单纯只做函数终止&#125;// 函数名 func// 参数 arg1,arg2,...// 返回值 return 1func() // 函数执行 变量作用域 局部变量 在JavaScript函数内部声明的变量（使用var）是局部变量， 只能在函数内部访问它 该变量的作用域是局部的 生命周期：局部变量会在函数运行以后被删除 (生命期从它们被声明的时间开始) 全局变量 在函数外声明的变量是全局变量 网页上的所有脚本和函数都能访问它 生命周期：全局变量会在页面关闭后被删除 (生命期从它们被声明的时间开始) 局部变量如果希望变为全局变量、可以使用windows.var =的形式赋予给当前窗口 12var x = 1;window.x = x; 12345function func(x,y)&#123; return x + y&#125;var res = func(1,2)alert(res) 1JavaScript 函数解析过程： 预编译：function函数提前，并将var定义的变量声明提前，先暂时赋值为undefined 执行 1234567func() // 弹出提示alert(iNum) // undefinedalert(abc) // 出错function func() &#123; alert(\"这个是函数\")&#125;var iNum = 1 匿名函数 函数可以没有名字，比如直接为某些事件赋值 1234window.onload = function()&#123; var sDate = new Date() console.log(sDate)&#125; 封闭函数 封闭函数常用来创建一个开始就执行而不用命名的函数 123(function()&#123; alert(\"你好\");&#125;)(); 也可以在函数定义前加上”~“和”!“等符号来定义匿名函数 123!function()&#123; alert(\"你好\");&#125;(); 封闭函数可以创建一个独立的空间，在封闭函数内定义的变量不会影响外部同名的函数和变量，可以避免命名冲突 123456var x = 1;!function()&#123; var x = \"这是同名变量\"; alert(x);&#125;alert(x); 当页面上引入多个js文件时，用这种办法比较安全 运算算术运算符 运算符 描述 示例 结果 + 加 x=y+2 x=7 - 减 x=y-2 x=3 * 乘 x=y*2 x=10 / 除 x=y/2 x=2.5 % 取余 x=y%2 x=1 ++ 累加 x=++y x=6 -- 递减 x=--y x=4 赋值运算符 运算符 例子 等价于 结果 = x=y x=5 += x+=y x=x+y x=15 -= x-=y x=x-y x=5 *= x*=y x=x*y x=50 /= x/=y x=x/y x=2 %= x%=y x=x%y x=0 注意：数字与字符串相加，结果将成为字符串 比较运算符 运算符 描述 示例 == 等于 x==8为false === 全等（值和类型） x===5为true；x===&quot;5&quot;为false != 不等于 x!=8为true &gt; 大于 x&gt;8为false &lt; 小于 x&lt;8为true &gt;= 大于或等于 x&gt;=8为false &lt;= 小于或等于 x&lt;=8为true 比较运算符常在条件语句中进行使用 1234var name = \"张三\"; if (name==\"张三\") &#123; document.write(\"这个人是张三\") &#125; 逻辑运算符 运算符 描述 示例 &amp;&amp; and (x &lt; 10 &amp;&amp; y &gt; 1) 为 true ` ` ! not !(x==y) 为 true 条件运算符12var NumCheck = 0; var Dis = (NumCheck==0) ? \"是数字0\":\"不是数字0\"; 如果变量NumCheck是0，则Dis的值为：”是数字0“；反之为：”不是数字0“ 条件语句 条件语句 12345678var iNum = 0;if (iNum==0)&#123; ...;&#125;else if (iNum==1) &#123; 条件细分...;&#125;else&#123; 不满足以上条件均到这里; &#125; switch语句 1234567891011var day = new Date().getDay();// 星期日:0 范围:0~6switch(day)&#123; case 0: alert(\"今天是星期二\"); break; case 1: ... break; ...&#125; 工作原理：首先设置表达式n（通常是一个变量）；随后表达式的值会与结构中的每个case的值做比较。如果存在匹配，则与该case关联的代码块会被执行。请使用break来阻止代码自动地向下一个case运行 for循环语句 语法 12345678910111213141516171819202122for(var i = 0; i &lt; len; i++)&#123; ...&#125;// for(起点数据; 判断条件; 数据递增或递减)&#123;&#125;var i = 0;for( ;i &lt; 10; i++)&#123; ...&#125;// 如果循环起始值已经被设置，可以在开头省略for(var i = 0; ; i++)&#123; ... if (i==5)&#123; ... break; //终止循环 &#125;&#125;// 当没有第二个语句时，必须在循环内提供break，否则循环则无法停下来，可能令浏览器崩溃for(var i = 0; i &lt; 10; )&#123; console.log(i); i += 2;&#125;// 如果没有提供第三个语句，可以在for循环中进行编写数值的变化 for/in语句循环遍历对象的属性 12345678910111213141516for (x in object)&#123; console.log(x);&#125;// 字符串：x 取下标// 数组：x 取下标// 对象：x 取keyvar x = \"abcdef\" // 0,1,2,3,4,5var y = [1,2,3,4,\"5\"] // 0,1,2,3,4var z = &#123; // name,age,gender name:\"张三\", age:16, gender:\"male\",&#125;for (obj in z)&#123; console.log(obj);&#125; while循环语句 语法 12345678910while (条件)&#123; 执行代码;&#125;var x = \"abcdef\";var i = 0;while (x[i])&#123; console.log(x[i]); i++;&#125;// 下表超出范围时不会报错，返回undefined do/while循环：do/while循环是while循环的变体 该循环首先会执行一次循环代码块，然后检查循环条件是否为真 如果条件为真，就会重复这个循环 123456789do&#123; 循环执行代码&#125;while (条件);var i = 3;do&#123; console.log(i) i--;&#125;while (i &gt; 5);// do/while循环至少会执行一次 获取页面元素 通过页面元素ID值进行获取：document.getElementById(&#39;&#39;) 获取到的是一个HTML对象，可以赋值给一个变量 注意：获取对应元素时，首先要确定页面已经生成所需元素 通常我们将javascript代码写到页面最下面 或通过使用windows.onload()事件判断是否已经生成页面 123456789101112131415161718192021&lt;body&gt; &lt;p id=\"p\"&gt;这是一段待获取的文字&lt;/p&gt; &lt;script&gt; function func()&#123; var sP = document.getElementById('p'); console.log(sP); &#125; func() &lt;/script&gt;&lt;/body&gt;&lt;!-- 获取到的内容: &lt;p id=\"p\"&gt;这是一段待获取的文字&lt;/p&gt; --&gt;&lt;body&gt; &lt;p id=\"p\"&gt;这是一段待获取的文字&lt;/p&gt; &lt;script&gt; window.onload = function()&#123; var sP = document.getElementById('p'); console.log(sP); &#125; &lt;/script&gt;&lt;/body&gt;&lt;!-- 获取到的内容: &lt;p id=\"p\"&gt;这是一段待获取的文字&lt;/p&gt; --&gt; 操作页面元素 可以通过id方式获取到对应页面内的元素，就可以对元素的属性进行操作，包括对属性的读和写 读取元素属性：元素.属性 12345678&lt;p id=\"aaa\" style=\"color: red;\"&gt;这是一段待获取的文字&lt;/p&gt;&lt;script&gt; var oP = document.getElementById('aaa'); console.log(oP) console.log(oP.id); console.log(oP.style); console.log(oP.style.color);&lt;/script&gt; 修改元素属性：元素.属性 =xxx 1234567891011121314151617181920&lt;p id=\"aaa\" style=\"color: red;\"&gt;这是一段待获取的文字&lt;/p&gt;&lt;button onclick=\"blue_font()\"&gt;按钮&lt;/button&gt;&lt;script&gt; function blue_font()&#123; var oP = document.getElementById('aaa'); oP.style.color = \"blue\"; // 修改字体样式属性中的字体颜色为蓝色 &#125;&lt;/script&gt;&lt;p id=\"aaa\" style=\"color: red;\"&gt;这是一段待获取的文字&lt;/p&gt;&lt;button id=\"color_button\"&gt;按钮&lt;/button&gt;&lt;script&gt; color_button.onclick = function()&#123; var oP = document.getElementById('aaa'); oP.style.color = \"blue\"; // 修改字体样式属性中的字体颜色为蓝色 &#125;&lt;/script&gt; 也可以获取到对应按钮元素后在绑定函数到它 12345678910&lt;p id=\"aaa\" style=\"color: red;\"&gt;这是一段待获取的文字&lt;/p&gt;&lt;button id=\"Button\"&gt;按钮&lt;/button&gt;&lt;script&gt; var oButton = document.getElementById('Button'); oButton.onclick = function()&#123; var oP = document.getElementById('aaa'); oP.style.color = \"blue\"; // 修改字体样式属性中的字体颜色为蓝色 &#125;&lt;/script&gt; 读取或写入标签包裹的内容（读取或修改标签文本内容）：innerHTML 12345678910&lt;a id=\"a\" href=\"https://www.baidu.com\"&gt;百度&lt;/a&gt;&lt;button onclick=\"urlChange()\"&gt;变搜狗&lt;/button&gt;&lt;script&gt; function urlChange()&#123; var oA = document.getElementById('a'); oA.href = \"https://www.sougou.com\"; console.log(oA.innerHTML); // 获取标签文本内容 oA.innerHTML = \"搜狗\"; //修改标签文本内容 &#125;&lt;/script&gt; JS事件及属性 常见事件 1234567- 用户点击鼠标- 网页已加载- 图像已加载- 鼠标移动某个元素上- 输入字段被改变时- 提交表单时- 用户触发某些按键时 onclick事件：用户点击鼠标 12345678910111213141516&lt;p onclick=\"TextChange(this)\"&gt;这是文本&lt;/p&gt;&lt;!-- this 代表当前所处的元素 --&gt;&lt;script&gt; function TextChange(id)&#123; id.innerHTML = \"文本修改\"//可以直接通过传来的参数进行页面元素的读取及修改 &#125;&lt;/script&gt;&lt;p id=\"p\"&gt;这是文本&lt;/p&gt;&lt;script&gt; var oP = document.getElementById(\"p\"); oP.onclick = function()&#123; oP.innerHTML = \"文本修改\"//可以直接通过传来的参数进行页面元素的读取及修改 &#125;&lt;/script&gt; onmouseover事件：鼠标移入 onmouseout事件：鼠标移出 12345678910&lt;p id=\"aaa\"&gt;请把鼠标移动过来&lt;/p&gt;&lt;script&gt; var oP = document.getElementById(\"aaa\"); oP.onmouseover = function()&#123; oP.style.color = \"green\";//可以直接通过传来的参数进行页面元素的读取及修改 &#125; oP.onmouseout = function()&#123; oP.style.color = \"red\"; &#125;&lt;/script&gt; JS高级字符串及操作方法 字符串合并：+ 数字字符串变整数：parseInt() 数字字符串变浮点数：parseFloat() 字符串按分隔符切分：split(&quot;*&quot;) 123var x = \"a*b*c*d\"alert(x.split(\"*\")) // a,b,c,dconsole.log(x.split(\"*\")) // [\"a\", \"b\", \"c\", \"d\"] 查找字符串是否含有某字符，找到返回索引，找不到返回-1：String.indexOf() 123var x = \"abcdefag\"var res = x.indexOf(\"z\")alert(res) 截取字符串：String.substring(start, end)，不包含end索引位置数据 1234var x = \"abcdefag\"alert(x.substring(2)) // cdefagalert(x.substring(2,4)) // cdalert(x.substring()) // abcdefag 字符串反转：通过结合数组的reverse()函数 12var x = \"abcd\";console.log(x.split(\"\").reverse().join(\"\")) //dcba 数组及操作方法 定义数组的方法 12345var aList = new Array(1,2,3);var aList = new Array();aList[0] = \"a\";aList[1] = \"b\";var aList = [1,2,3,4,\"a\"]; 获取数组的长度：Array.length() 12var aList = new Array(1,2,3);console.log(aList.length) // 3 将数组成员通过指定拼接符合并成一个字符串：Array.join(&quot;*&quot;) 12var aList = [1,2,3,4,5]console.log(aList.join(\"*\")) // 1*2*3*4*5 向数组的最后增加或删除成员：Array.pop()、Array.push() 123456var aList = [1,2,3,4,5]var opa = aList.pop() // opa: 5console.log(opa) // 5console.log(aList) // [1, 2, 3, 4]aList.push(\"a\")console.log(aList) // [1, 2, 3, 4, \"a\"] 将数组反转：Array.reverse() 123var aList = [1,2,3,4,5];aList.reverse();console.log(aList); //[5, 4, 3, 2, 1] 返回数组中元素第一次出现的索引值：Array.indexOf(chr) 12var aList = [1,2,3,4,5];console.log(aList.indexOf(3)) // 2 在数组中增加或删除成员，并返回被删除的：Array.splice(index, howmany, items...) 从index位置开始，给定的hwomany个数的值，并用后面的items替换这些被删除的值 123var aList = [1,2,\"a\",4,5]aList.splice(2,1,\"b\",\"c\")console.log(aList) // [1, 2, \"b\", \"c\", 4, 5] 多维数组 数组的成员包含数组 123var aList = [1,2,3,[\"a\",\"b\"]]console.log(aList[-1][0]) // 出错 undefinedconsole.log(aList[3][0]) // a 定时器 作用：定时调用函数、制作动画 反复执行定时器 setInterval(code, millisec)：反复执行的定时器 code: 必须参数，要调用的函数或要执行的代码串 millisec: 必须参数，执行code任务所需要的事件间隔，以毫秒计 clearInterval(setInterval_obj)：关闭反复执行的定时器 12345678910111213141516171819&lt;!--跑马灯效果--&gt;&lt;h3 id=\"h3\"&gt;abcdefg&lt;/h3&gt;&lt;button id=\"start_button\"&gt;开始&lt;/button&gt;&lt;button id=\"stop_button\"&gt;停止&lt;/button&gt;&lt;script&gt; start_button.onclick = function()&#123; // 开启定时事件 var sT = setInterval(loop,1000); window.sT = sT; // 声明此sT定时事件为全局变量 &#125; stop_button.onclick = function()&#123; // 关闭定时事件 clearInterval(sT) &#125; function loop()&#123; var Opstr = document.getElementById('h3'); Opstr.innerHTML = Opstr.innerHTML.substring(1) + Opstr.innerHTML[0] console.log(Opstr.innerHTML) &#125;&lt;/script&gt; 等待执行定时器 setTimeout(code, millisec)：定义只执行一次的等待定时器 1code : 必须参数，要调用的函数或要执行的代码串 millisec: 必须参数，执行code任务所需要的事件间隔，以毫秒计 clearTimeout(setTimeout_obj)：关闭只执行一次的等待计时器 123456789101112&lt;h3 id=\"h3\"&gt;我是一个内容&lt;/h3&gt;&lt;button id=\"start_button\"&gt;让上面的内容消失&lt;/button&gt;&lt;script type=\"text/javascript\"&gt; start_button.onclick = function()&#123; var st = setTimeout(clear,1000) window.st = st; &#125; function clear()&#123; var oH3 = document.getElementById('h3'); oH3.innerHTML = \"\"; &#125;&lt;/script&gt;","categories":[],"tags":[{"name":"Django","slug":"Django","permalink":"http://laxe.top/tags/Django/"}]},{"title":"Css","slug":"Css","date":"2019-10-21T02:49:45.661Z","updated":"2019-10-21T02:51:18.064Z","comments":true,"path":"2019/10/21/Css/","link":"","permalink":"http://laxe.top/2019/10/21/Css/","excerpt":"CSS CSS值层叠样式表（Cascading Style Sheets），主要为了让我们的HTML页面具有花里胡哨的样式效果 样式定义如何显示HTML元素 样式通常存储在样式表中 外部样式表可以极大的提高工作效率 外部样式表通常存储后缀为CSS的文件中 多个样式定义可层叠为一","text":"CSS CSS值层叠样式表（Cascading Style Sheets），主要为了让我们的HTML页面具有花里胡哨的样式效果 样式定义如何显示HTML元素 样式通常存储在样式表中 外部样式表可以极大的提高工作效率 外部样式表通常存储后缀为CSS的文件中 多个样式定义可层叠为一 有了CSS，html中大部分表现样式的标签就可以不用了 html只负责文档的结构和内容，表现形式完全交给CSS，html文档变得更加简洁 CSS的引入方式 内联式引入：直接赋予标签style属性进行样式编写 1&lt;body style=\"background: #00ff00\"&gt; 嵌入式：直接在文档页面通过style标签创建嵌入的样式表 12345&lt;style type=\"text/css\"&gt; body&#123; background: black; &#125;&lt;/style&gt; 外部式：在文档中通过link标签，将外部样式文件引入到页面中： 1&lt;link rel=\"stylesheet\" type=\"text/css\" href=\"css/main.css\"&gt; 优先级：内联式 &gt; 嵌入式 &gt; 外部式 （就近原则） CSS语法 CSS语法规则由两部分构成：选择器 &amp; 一条或多条声明 1234selector&#123; declaration1; declaration2;&#125; selector：选择器，一般是你需要改变的HTML标签declaration1：每条声明，由一个属性和一个值组成 123selector&#123; property: value;&#125; 属性（property）是您希望设置的样式属性（style attribute） 每个属性有一个值；属性和值被冒号分开 当属性中的值为若干单词时，加引号 123h1&#123; font-family: \"sans serif\";&#125; 颜色的写法： 12345678910p&#123; color: #00FF00;&#125;h1&#123; color: #0F0&#125;body&#123; background: rgb(255,0,0); background: rgb(100%,0%,0%);&#125; 请注意，当使用RGB百分比时，即使当值为0时也要写百分比符号当尺寸为0像素时，0之后不需要使用px单位，因为0就是0，无论单位是什么 CSS选择器标签选择器 影响范围大，常做通用设置，或用在层级选择器中 123456&lt;p&gt;第一段文字&lt;/p&gt;&lt;p&gt;再来一段&lt;/p&gt;p&#123; color: blue;&#125;/*定义所有p标签字体为蓝色*/ 类选择器 通过类名来选择元素，一个类可以用于多个元素 一个元素也可以使用多个类，应用灵活，可复用 是CSS中使用最多的一种选择器 注意：类名的第一个字符不能使用数字 12345678910&lt;p class=\"big\"&gt;第一段文字&lt;/p&gt;&lt;p class=\"big red\"&gt;再来一段&lt;/p&gt;.big&#123; font-size: 20px&#125;/*定义big类字体大小为20像素*/.red&#123; color: red;&#125;/*定义类为red的字体颜色为红色*/ 类选择器还可基于所属标签进行派生选择： 12345678&lt;p class=\"red\"&gt;再来一段&lt;/p&gt;&lt;div class=\"red\"&gt; 文字测试&lt;/div&gt;div.red&#123; color: red;&#125;/*在页面中只有div类为red的字体颜色会变为红色*/ 属性选择器 对指定属性的HTML元素进行设置，而不限于class和id属性 通过属性 123456&lt;a href=\"https://www.baidu.com\"&gt;这是一个连接&lt;/a&gt;&lt;p href=\"test\"&gt;测试&lt;/p&gt;[href]&#123; color: blue;&#125;/*为所有具有href属性的元素设置字体颜色*/ 通过属性的值（整个匹配） 123456&lt;a href=\"https://www.baidu.com\"&gt;这是一个连接&lt;/a&gt;&lt;p href=\"test\"&gt;测试&lt;/p&gt;[href=\"test\"]&#123; font-size: 20px;&#125;/*为属性为test的元素设置字体大小*/ 属性的值（属性的值中包含所匹配的单词）：~= 12345678&lt;p attr=\"test\"&gt;测试&lt;/p&gt; √&lt;p attr=\"test-xx\"&gt;测试&lt;/p&gt; x&lt;p attr=\"test_xx\"&gt;测试&lt;/p&gt; x&lt;p attr=\"test xx\"&gt;测试&lt;/p&gt; √[attr~=test]&#123; font-size: 20px;&#125;/*为属性包含test的元素设置字体大小*/ 注意：不包含下划线和连字符的 属性的值（从开头整个匹配或带有连字符的属性值）：|= 12345678&lt;p attr=\"test\"&gt;测试&lt;/p&gt; √&lt;p attr=\"test-xx\"&gt;测试&lt;/p&gt; √&lt;p attr=\"test_xx\"&gt;测试&lt;/p&gt; x&lt;p attr=\"test xx\"&gt;测试&lt;/p&gt; x[attr|=test]&#123; font-size: 20px;&#125;/*为单词为test或开头为test-的元素设置字体大小*/ 注意：适用于由连字符分隔的属性值 属性的值（从属性值的开头进行匹配）：^= 12345678&lt;p attr=\"test\"&gt;测试&lt;/p&gt; √&lt;p attr=\"test-xx\"&gt;测试&lt;/p&gt; √&lt;p attr=\"test_xx\"&gt;测试&lt;/p&gt; √&lt;p attr=\"test xx\"&gt;测试&lt;/p&gt; √[attr^=test]&#123; font-size: 20px;&#125;/*为开头包含test的所有元素设置字体大小*/ 属性的值（从属性值的结尾开始匹配）：$= 12345678&lt;p attr=\"test\"&gt;测试&lt;/p&gt; √&lt;p attr=\"xx-test\"&gt;测试&lt;/p&gt; √&lt;p attr=\"xx_test\"&gt;测试&lt;/p&gt; √&lt;p attr=\"xx test\"&gt;测试&lt;/p&gt; √[attr$=test]&#123; font-size: 20px;&#125;/*为结尾是test的所有元素设置字体大小*/ 属性的值（只要含有则匹配）：*= 12345678&lt;p attr=\"test\"&gt;测试&lt;/p&gt; √&lt;p attr=\"xx-test\"&gt;测试&lt;/p&gt; √&lt;p attr=\"xx_test\"&gt;测试&lt;/p&gt; √&lt;p attr=\"xx test\"&gt;测试&lt;/p&gt; √[attr*=test]&#123; font-size: 20px;&#125;/*为含有test的所有元素设置字体大小*/ 几种属性选择的匹配方式 1~= ：用于选取属性值中包含指定 词汇 的元素； 必须是单独的词汇，不能是带有连字符或下划线组成的单词。 1|= ：用于选取带有以指定值开头的属性值的元素，该值必须是整个单词； 可以有连字符组成，word或者是word-wild ^=：匹配属性值以指定值开头的每个元素 $=：匹配属性值以指定值结尾的每个元素 *=：匹配属性值中包含指定值的每个元素 层级选择器 主要应用在标签嵌套的结构中，通过层级，限制样式的作用范围 1234567891011121314151617181920212223242526272829&lt;div class=\"header\"&gt; &lt;p class=\"title\"&gt;标题1&lt;/p&gt; &lt;span class=\"author\"&gt;作者1&lt;/span&gt; &lt;p class=\"content\"&gt; 主要内容 &lt;/p&gt;&lt;/div&gt;&lt;div class=\"footer\"&gt; &lt;p class=\"title\"&gt;标题2&lt;/p&gt; &lt;span class=\"author\"&gt;作者2&lt;/span&gt; &lt;p class=\"content\"&gt; 主要内容2 &lt;/p&gt;&lt;/div&gt;.header .title&#123; color: gold; font-size: 30px;&#125;/*生效所有header类下的title类*/.header .author&#123; color: blue; font-size: 15;&#125;/*生效所有header类下的author类*/.header p&#123; font-weight: bold;&#125;/*生效所有header类中的p标签*/ ID选择器 通过ID名进行元素选择，元素的ID名定义时在整个文档属于唯一 通过ID选择器只能对应页面元素中的一个 ID名通常作为JS脚本定位使用，不推荐ID选择器 1234567891011121314151617&lt;div class=\"header\"&gt; &lt;p id=\"title\"&gt;标题1&lt;/p&gt; &lt;span id=\"author\"&gt;作者1&lt;/span&gt; &lt;p id=\"content\"&gt; 主要内容 &lt;/p&gt;&lt;/div&gt;#title&#123; font-size: 25px; font-weight: bold;&#125;#author&#123; font-size: 10px;&#125;#content&#123; color: blue;&#125; 伪类选择器 CSS伪类选择器用于向某些选择器添加特殊的效果 伪类的语法 123selector:pseudo-class&#123; property: value;&#125; 与css类搭配使用 123selector.class:pseudo-class&#123; property: value;&#125; 锚伪类 控制连接访问状态，常见状态有：活动状态、已访问状态、未被访问状态、鼠标悬停状态 1234567891011121314151617&lt;a class=\"baidu\" href=\"https://www.baidu.com\"&gt;访问这里&lt;/a&gt;.baidu:link&#123; color: blue;&#125;/*未访问过的连接*/.baidu:visited&#123; color: black;&#125;/*访问过的连接*/.baidu:hover&#123; color: gold;&#125;/*鼠标划过的连接*/.baidu:active&#123; color: red;&#125;/*已选中的连接*/ link、visited、hover、active 注意 hover必须定义在link和visited之后，才是有效的 active必须定义在hover之后，才是有效的 CSS选择器的权重 当有多个同类样式作用于同一个元素时 权重高的样式对元素起作用 权重相同时后写的样式覆盖前面写的 使用!important将样式权重设置为10000，将!important写到样式属性值后 权重值：就近原则 内联式样式：1000 1&lt;p style=\"color: red;\"&gt;&lt;/p&gt; ID选择器：100 1#id &#123;color: red;&#125; 类选择器：10 1.class &#123; background: blue;&#125; 标签选择器：1 1p&#123;font-weight:bold;&#125; 1234&lt;p id=\"test\" style=\"color: blue;\"&gt;测试&lt;/p&gt;#test&#123; color: red !important;&#125; CSS基本属性布局属性 width：设置元素（标签）的宽 height：设置元素（标签）的高 1#button&#123;width:100px; height:100px;&#125; background：设置背景色或背景图 12345body&#123; width: 100%; height: 100%; background: #00FF00 url(\"../img/1.jpg\") no-repeat ;&#125; background属性可以分解为如下几个设置项： background-color：设置背景颜色 background-image：设置背景图片地址 background-repeat：设置图片如何重复平铺，可选参数有：repeat、repeat-x（水平方向重复）、repeat-y（垂直方向重复）、no-repeat（图片只显示一次） 12&gt; background-position`：设置图片的位置，可选参数有：`left`、`right`、`center&gt; background-attachment：设置图片是固定的还是会随页面滚动，可选参数有：scroll（背景图片会随着页面其余部分的滚动而移动）、fixed（页面的其余部分滚动时，背景图像不会移动） 注意：在背景图片路径填写时，如果使用内联式写法则从当前页面路径开始查找相对路径，如写在外部CSS文件中，则以CSS文件为相对基础。 border：设置元素周围的边框 123p&#123; border: 10px double blue;&#125; 依次设置：border-width、border-style、border-color 也可以拆分成四个边的样式选项 border-top：顶边框 border-buttom：底边框 border-left：左边框 border-right：右边框 123456[attr]&#123; border-top: 5px inset blue; border-bottom: 5px inset green; border-left: 5px outset red; border-right: 5px outset red;&#125; 设置时提供的边框样式属性 dotted：点状 solid：实线 double：双线 dashed：虚线 groove：3D凹槽边框 ridge：定义3D垄状边框 inset：定义3D inset 边框 outset：定义3D outset边框 inherit：规定应该从父元素继承边框样式 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;p class=\"p1\"&gt;aaaaaaa&lt;/p&gt;&lt;p class=\"p2\"&gt;bbbbbbb&lt;/p&gt;&lt;p class=\"p3\"&gt;ccccccc&lt;/p&gt;&lt;p class=\"p4\"&gt;ddddddd&lt;/p&gt;&lt;p class=\"p5\"&gt;ggggggg&lt;/p&gt;&lt;p class=\"p6\"&gt;eeeeeee&lt;/p&gt;&lt;p class=\"p7\"&gt;fffffff&lt;/p&gt;&lt;table class=\"table1\" border=\"1\"&gt; &lt;tr&gt; &lt;th&gt;姓名&lt;/th&gt; &lt;th&gt;性别&lt;/th&gt; &lt;th&gt;年纪&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;张三&lt;/td&gt; &lt;td&gt;女&lt;/td&gt; &lt;td&gt;18&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;李四&lt;/td&gt; &lt;td&gt;男&lt;/td&gt; &lt;td&gt;20&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;.p1&#123; border: 1px dotted blue;&#125;.p2&#123; border: 1px solid blue;&#125;.p3&#123; border: 1px double blue;&#125;.p4&#123; border: 1px dashed blue;&#125;.p5&#123; border: 10px groove green;&#125;.p6&#123; border: 10px ridge blue;&#125;.p7&#123; border: 10px inset blue;&#125;.table1&#123; border: 5px double red;&#125; padding：设置元素包含的内容和元素边框的距离，也叫内边距 1234p&#123; padding: 100px; border: 1px solid black;&#125; 这个样式属性也可以拆分成以下单独四种，可以分别设置对应位置的内边距 1padding-top ：设置上内边距 padding-bottom：设置下内边距 padding-left：设置左内边距 padding-right：设置右内边距 margin：设置元素和外界的边距，也叫外边距 1234p&#123; margin: 10px;&#125;/*同时设置四个边距为10px*/ 与padding类似，margin属性也可以拆分为四个方向的单独设置 margin-top：设置上外边距 margin-bottom：设置下外边距 margin-left：设置左外边距 margin-right：设置右外边距 float：定义元素在当前父元素下向哪个方向浮动，这个属性常用于图像，使文本围绕在图像周围 如果浮动方向空间不足，元素会跳至下一行，这个过程会持续到某一行拥有足够的空间为止 1234&lt;input type=\"submit\" value=\"提交\"&gt;input&#123; float: left;&#125; 文本常用属性 color：设置元素中的文字颜色 1p&#123;color: red;&#125; font-size：设置元素中的文字大小 1p&#123;font-size: 12px;&#125; font-family：设置元素中的文字字体 123p&#123;font-family:\"微软雅黑\"&#125;/*为了避免中文兼容问题，常用字体的英文标识*/p&#123;font-family:\"Microsoft Yahei\"&#125; font-widght：设置元素中的文字是否加粗 1234p&#123;font-widght:bold;&#125;/*设置加粗*/p&#123;font-widght:normal;&#125;/*设置不加粗*/ line-height：设置元素中的文字行高 1p&#123;line-height:24px;&#125; text-decoration ：设置元素中文字的 下划线 1p&#123;text-decoration:underline;&#125; none：默认文本格式，无下划线 underline：定义文本下的一条线 overline：定义文本上的一条线 line-through：定义穿过文本的一条线 blink：定义闪烁的文本 inherit：规定应该从父元素继承text-decoration属性的值 text-align：设置元素中文字对齐方式 1p&#123;text-align:center;&#125; text-indent：设置元素中文字的首行缩进 1p&#123;text-indent:24px;&#125; display：设置元素的类型及隐藏方式 1p&#123;display:none;&#125; none： 元素不会显示 block：元素将显示为块级元素，此元素前后会带有换行符 inline：此元素被显示为内联元素，元素前后没有换行符 list-item：元素作为列表显示 table：元素作为块级表格来显示（类似 ），表格前后带有换行符 inline-table：元素作为内联表格来显示（类似 ），表格前后没有换行符 table-cell：此元素会作为一个表格单元格显示（类似 和 ） table-caption：此元素会作为一个表格标题显示（类似 ） 元素溢出 overflow：当子元素的大小超过所承载的父元素大小时，需要设置父元素对于溢出的子元素显示方式 1234567&lt;p&gt;123456789&lt;/p&gt;p&#123; width:500px; text-indent: 498px; border: 1px solid blue; overflow:auto;&#125; visible：默认值;内容不会被修剪，会呈现在元素框之外 hidden：内容会被修剪，并且其余内容是不可见的 scroll：内容会被修剪，但是浏览器会显示滚动条以便查看其余的内容 auto：如果内容被修剪，则浏览器会显示滚动条以便查看其余的内容 盒子模型 使用浏览器F12查看元素 定位 文档流：文档流，是指盒子按照html标签编写的顺序依次从上到下，从左到右排列，块元素占一行，行内元素在一行之内从左到右排列，先写的先排列，后写的排在后面，每个盒子都占据自己的位置。 CSS3主要有三种定位：普通流、浮动、绝对定位 static：元素框正常生成，块级元素生成一个矩形框、作为文档流的一部分、行内元素则会创建一个或多个行框，置于其父元素中 relative：相对定位元素，元素还会保持定位前的形状，并且移动前的位置也会保留下来，不会脱离文档流 一般是将父级设置相对定位（relative），子级设置绝对定位（absolute），子级就以父级作为参照来定位，否则子级相对于body来定位 相对定位会按照元素的原始位置对该元素进行移动 absolute：绝对定位元素，元素脱离文档流，移动前的位置在文档流中关闭，定位后生成一个新的块级框，不论他之前在原始文档流中生成何种类型的框 也可以理解为漂流在文档流的上方，相对于上一个设置了定位的父级元素来进行定位，如果找不到，则相对于body元素进行定位 通过绝对定位，元素可以放置到页面上的任何位置 fixed：固定定位元素，元素脱离文档流，不占据文档流的位置，相对于浏览器窗口进行定位 元素偏移的设置： top：定位元素的上外边距边界与其包含块上边界之间的偏移 bottom：定位元素下外边距边界与其包含块下边界之间的偏移 right：定位元素右外边距边界与其包含块下边界之间的偏移 left：定位元素左外边距边界与其包含块下边界之间的偏移 z-index：设置堆叠元素的层级，这里的层级不是从上到下，而是从里到外 来一个小例子看看布局的效果 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051body&#123; padding: 0px; margin: 0px;&#125;.container&#123; position: relative; width: 100%; height: 100%; background: black; margin: 0px;&#125;.top&#123; position: relative; width: 100%; height: 20%; background: yellow;&#125;.left&#123; width: 20%; height: 70%; background: green;&#125;.right&#123; position: absolute; top: 20%; left: 30%; width: 70%; height: 70%; background: red;&#125;.bottom&#123; position: absolute; top: 90%; width: 100%; height: 10%; background: white;&#125;&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt; &lt;div class=\"container\"&gt; &lt;div class=\"top\"&gt;头部&lt;/div&gt; &lt;div class=\"left\"&gt;左&lt;/div&gt; &lt;div class=\"right\"&gt;右&lt;/div&gt; &lt;div class=\"bottom\"&gt;底部&lt;/div&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 这里的例子可以将页面简单的分成四个部分","categories":[],"tags":[{"name":"Django","slug":"Django","permalink":"http://laxe.top/tags/Django/"}]},{"title":"Html","slug":"Html","date":"2019-10-21T02:47:06.598Z","updated":"2019-10-21T02:47:56.925Z","comments":true,"path":"2019/10/21/Html/","link":"","permalink":"http://laxe.top/2019/10/21/Html/","excerpt":"HTML什么是HTML 超文本标记语言(HyperText Markup Language)，标准通用标记语言下的一个应用； 是网页制作必备的编程语言 超文本就是指页面内可以包含图片、链接，甚至音乐、程序等非文字元素 HTML不是一种编程语言，而是一种标记语言","text":"HTML什么是HTML 超文本标记语言(HyperText Markup Language)，标准通用标记语言下的一个应用； 是网页制作必备的编程语言 超文本就是指页面内可以包含图片、链接，甚至音乐、程序等非文字元素 HTML不是一种编程语言，而是一种标记语言 HTML基本结构1234567891011&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;title&gt;标题&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;我的第一个标题。&lt;/h1&gt; &lt;p&gt;我的第一个段落。&lt;/p&gt; &lt;/body&gt;&lt;/html&gt; 1&lt;!DOCTYPE html&gt; 声明为 1HTML 文档， 1HTML 文档也常称为网页， 一个文档包含HTML标签和文本 &lt;html&gt;与&lt;/html&gt;之间的文本描述网页，同时HTML元素也是当前页面的根元素 &lt;head&gt;是包含了文档的元(meta)数据，如定义网页编码格式&lt;meta charset=&quot;utf-8&quot;&gt; &lt;title&gt;元素描述当前文档页面的标题 &lt;body&gt;与&lt;body&gt;之间的文本是可见的页面内容 &lt;h1&gt;与&lt;/h1&gt;之间的文本被显示为标题 &lt;p&gt;与&lt;/p&gt;之间的文本被显示为段落 HTML注释123&lt;!-- 这是一段注释 --&gt;&lt;h5&gt;这是一个H5标题。&lt;/h5&gt;&lt;!-- 记得在此处添加信息 --&gt; HTML标签 HTML标记标签通常被称为HTML标签 (HTML tag) HTML标签是由尖括号包围的关键词，比如&lt;html&gt; HTML标签通常是成对出现的，比如 &lt;b&gt;和&lt;/b&gt; 标签对中的第一个标签是开始标签，第二个标签是结束标签 多数情况下，HTML文档中的标签可以互相嵌套，实现更复杂的功能 基本标签 标题标签：h1~h6 123&lt;h1&gt; 这是一个最大的标题&lt;/h1&gt; 段落标签：p 123&lt;p&gt; 每一个段落标签中的内容都会换行输出&lt;/p&gt; 块级标签：div 123456789&lt;div style=\"color: #FF0000\"&gt; &lt;h1&gt; div标签常用来组合一整块标签内容 &lt;/h1&gt; &lt;p&gt; 以便通过CSS样式来对其中这些元素进行格式化控制 比如当前div标签下的所有文本均为红色 &lt;/p&gt;&lt;/div&gt; 换行标签：br 123111&lt;br&gt;222 图片标签：img 1&lt;img src='xxx.img' alt=\"图片\" /&gt; src：用来指明当前图片路径 alt：光标位于图片时所显示的内容，或是当图片加载失败时所显示的内容 链接标签：a 1&lt;a src=\"https://www.baidu.com\"&gt;百度&lt;/a&gt; href：控制访问地址 a：标签的文本元素为页面展示内容 无序列表：ul、li 12345&lt;ul&gt; &lt;li&gt;无序列表项1&lt;/li&gt; &lt;li&gt;无序列表项2&lt;/li&gt; &lt;li&gt;无序列表项3&lt;/li&gt;&lt;/ul&gt; ul:指明当前为无序列表 li:具体列表项使用这个标签 单个列表项可不加ul标签 有序列表：ol、li 12345&lt;ol&gt; &lt;li&gt;A&lt;/li&gt; &lt;li&gt;B&lt;/li&gt; &lt;li&gt;C&lt;/li&gt;&lt;/ol&gt; ol：指明当前为有序列表 li：具体列表项使用这个标签 单个列表项可不加ul标签 连接外部文件 像img等类似的标签需要我们去访问一个外部文件，常用的方式有如下几种 引入外部图片： 1&lt;img src=\"img/1.jpg\" alt=\"图片\" /&gt; 引入另外一个网页： 1&lt;a src=\"other.html\"&gt;其他页面&lt;/a&gt; 引入CSS样式文件： 1&lt;link rel=\"stylesheet\" type=\"text/css\" href=\"css/main.css\" /&gt; rel：relationship的英文缩写，用于定义链接的文件和HTML文档之间的关系 stylesheet：样式表 type：外链文档的类型 href：外链文档的路径 引入js文件： 1&lt;script type=\"text/javascript\" src=\"js/jquery.js\"&gt;&lt;/script&gt; src与href： src用于引入资源，引入的资源为页面必不可少的一部分，类似换内裤 href只是引用资源，表示超文本引用，类似穿外套 相对路径：使用当前文件为起点定位资源 ./：表示位于当前文件所在目录下 ../：表示位于当前文件所处的上一层目录下 绝对路径：使用当前磁盘目录为起点定位资源 表格标签：table 表格标签由table标签进行定义 表格中的每一行由tr标签定义table row 每一行有几个单元格由td标签定义table data 表格的表头由th标签定义table header 123456789101112131415&lt;table border=\"20\"&gt; &lt;caption&gt;用户表&lt;/caption&gt; &lt;tr&gt; &lt;th&gt;名字&lt;/th&gt; &lt;th&gt;年龄&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;张三&lt;/td&gt; &lt;td&gt;18&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;李四&lt;/td&gt; &lt;td&gt;20&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt; border：定义表格边框，数字越大，边框越粗 caption ：定义表格标题 123456789101112131415&lt;table width=\"400\" border=\"1\" cellpadding=\"10\" cellspacing=\"3\" frame=\"box\"&gt; &lt;tr&gt; &lt;th&gt;名字&lt;/th&gt; &lt;td align=\"center\" &gt;张三&lt;/td&gt; &lt;td&gt;李四&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th&gt;年龄&lt;/th&gt; &lt;td&gt;18&lt;/td&gt; &lt;td&gt;20&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td colspan=\"3\" align=\"center\"&gt;合并单元格&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt; cellpadding：规定单元格边缘和内容的空白 cellspacing：增加单元格之间的距离 12&gt; align`：设置单元格内容靠齐，可选属性有`left`、`right`以及`center&gt; frame：控制围绕表格的边框box四面环山 above：上面 below：下面 hsides：上下两侧 vsides：左右两侧 colspan：合并列 rowspan：合并行 表单标签：form 表单用于收集不同类型的用户输入，表单由不同类型的标签组成 单行文本输入框 12&lt;label&gt;姓名：&lt;/label&gt;&lt;input type=\"text\" name=\"username\" value=\"张三\" /&gt;&lt;label&gt;密码：&lt;/label&gt;&lt;input type=\"password\" name=\"password\" placeholder=\"请输入密码\" /&gt; text：单行文本框 password：密码输入框 value：定义表单元素的值 name：定义表单元素的名称，提交到后台时通过该值获取对应表单中的数据 单选框 12&lt;input type=\"radio\" name=\"gender\" value=\"0\" /&gt; 男&lt;input type=\"radio\" name=\"gender\" value=\"1\" /&gt; 女 在单选框中的name属性可以控制哪几个表单为一组 复选框 123&lt;input type=\"checkbox\" name=\"like\" value=\"sing\" /&gt; 唱歌&lt;input type=\"checkbox\" name=\"like\" value=\"run\" /&gt; 跑步&lt;input type=\"checkbox\" name=\"like\" value=\"swiming\" /&gt; 游泳 上传文件 1&lt;input type=\"file\" name=\"picture\"&gt; 多行文本输入框 1&lt;textarea name=\"about\"&gt;&lt;/textarea&gt; 下拉表单元素：select 123456&lt;select name=\"site\"&gt; &lt;option value=\"0\"&gt;北京&lt;/option&gt; &lt;option value=\"1\"&gt;上海&lt;/option&gt; &lt;option value=\"2\"&gt;广州&lt;/option&gt; &lt;option value=\"3\"&gt;深圳&lt;/option&gt;&lt;/select&gt; option：下拉框中的具体属性 value：在表单提交时真正发送给服务器的值 提交按钮：submit 点击时触发form标签中的action动作 重置按钮：reset 重置所属表单中所有表单框的所填数据 普通按钮：button 123&lt;input type=\"submit\" value=\"提交\"&gt;&lt;input type=\"reset\" value=\"重置\"&gt;&lt;input type=\"button\" value=\"按钮\"&gt;","categories":[],"tags":[{"name":"Django","slug":"Django","permalink":"http://laxe.top/tags/Django/"}]},{"title":"Django-Views-视图层","slug":"Django-Views-视图层","date":"2019-10-21T02:17:20.957Z","updated":"2019-10-21T02:18:09.682Z","comments":true,"path":"2019/10/21/Django-Views-视图层/","link":"","permalink":"http://laxe.top/2019/10/21/Django-Views-视图层/","excerpt":"视图层 视图函数一般用来接收一个Web请求HttpRequest，之后返回一个Web响应HttpResponse HttpRequest 一个视图函数用来响应用户的Request请求，每个视图函数默认的第一个位置参数request用来接收用户发起请求的HttpRequest信息。 视图函数的返回值，为一个HttpResponse值，包括我们要返回给用户的HTML页面或者字符串等等，以及对应的头部字段信息","text":"视图层 视图函数一般用来接收一个Web请求HttpRequest，之后返回一个Web响应HttpResponse HttpRequest 一个视图函数用来响应用户的Request请求，每个视图函数默认的第一个位置参数request用来接收用户发起请求的HttpRequest信息。 视图函数的返回值，为一个HttpResponse值，包括我们要返回给用户的HTML页面或者字符串等等，以及对应的头部字段信息 123from django.http import HttpResponsedef index(request): return HttpResponse('Hello world') 常见请求方式 POST和GET是HTTP协议定义的与服务器交互的方法。 GET一般用于获取/查询资源信息，而POST一般用于更新资源信息。另外，还有PUT和DELETE方法 get 常用来从指定地址请求数据； 如果需要在请求时提交某些数据，则以路由形式传递参数，查询Query字符串如下格式所示： 1https://www.baidu.com/?key=abc&amp;pos=shanxi get请求可被浏览器缓存，保存在历史记录中 get不应在使用敏感数据时使用，明文包路在请求地址中 get有长度限制 post 向指定的资源提交要被处理的数据 使用POST，提交的数据保存在HTTP协议中的消息主体部分 post请求不会被浏览器缓存 post提交数据长度无限制 post比get更加安全 request 如果说urls.py是Django中前端页面和后台程序桥梁，那么request就是桥上负责运输的小汽车，可以说后端接收到的来至前端的信息几乎全部来自于requests中 request.method 获取当前用户请求方式， 请求方式字符串为纯大写：&#39;GET&#39;、&#39;POST&#39; 如用户以get方式发起请求，对应代码中获取到的结果以及在判断时像是这样 123def index(request): if request.method == 'GET': … request.GET 当用户通过get方式请求站点，并在路由中提供了查询参数，可以通过该属性获取到对应提交的值 123456789def index(request): print(request.GET) # &lt;QueryDict: &#123;'name': ['jack'], 'id': ['1']&#125;&gt; print(type(request.GET)) # &lt;class 'django.http.request.QueryDict'&gt; name_ = request.GET.get('name') id_ = request.GET.get('id') content = '%s:%s' % (name_,id_) return HttpResponse(content) 12&gt; request.GET`是一个类似字典的数据类型：`QueryDict&gt; 其中也支持类似对字典的get或直接dict.[key]键值访问方式，当然使用get方式进行对应key获取会更好，因为get在访问不到时不会报错 如果定义了如上所示的视图函数，那么在访问连接时，我们可以通过路由传参： 1http://127.0.0.1:8000/?name=jack&amp;id=1 这里对应页面会显示的结果： 1jack:1 注意：使用GET方法在连接中进行参数提交，后台接收到的数据类型均是字符串 request.POST 获取用户以post形式提交的数据并保存在后台，为类字典数据，这里和request.GET是一个东西； 在网页中，一般我们通过html的表单进行数据的提交，POST方式可以提交空数据 因为涉及到了表单页面，所以我们先来弄一个HTML页面 12345678910&lt;body&gt; &lt;div&gt;这是一个关于POST的测试&lt;/div&gt; &lt;form action=\"/\" method=\"POST\"&gt; &#123;% csrf_token %&#125; 账号:&lt;input type=\"text\" name=\"account\"&gt; &lt;br&gt; 密码:&lt;input type=\"password\" name=\"passwd\"&gt; &lt;input type=\"submit\" value=\"提交\"&gt; &lt;/form&gt; &lt;/body&gt; 在模板页面中，一旦涉及到了表单提交，那么一定要注意在表单区域添加csrf_token标签进行防跨站伪造令牌的加载，否则表单数据的将被认为是无效的。 在接下来的视图函数中会使用到input标签中的name属性； name值属性维护了post的数据传入到后台时的标示，会与表单的数据组合成类字典格式 如name属性为account的输入框中输入了test，那么后台数据接收到的值类似：{&#39;account&#39;:&#39;test&#39;} 写一个视图函数用来捕获当前表单使用POST形式提交的数据： 123456789def index(request): if request.method=\"POST\": print(request.POST) print(type(request.POST)) account = request.POST.get(\"account\") passwd = request.POST.get(\"passwd\") content = \"%s:%s\" % (account,passwd) return HttpResponse(content) return render(request,\"index.html\") #在使用get形式请求时，返回表单页面 如果在表单页面中账号填写为test，密码为123456；在视图函数中捕捉到的结果为： 1&lt;QueryDict: &#123;'csrfmiddlewaretoken': ['EmyGwsVcrXI2LDkYLS9qflkUH4N7bM1nfTQxr3fsOsZlI4vJFwci7TargtYRAGl2'], 'account': ['test'], 'passwd': ['123456']&#125;&gt; 表单多值提交 在request.POST中需要注意，某些情况下，使用POST提交数据的表单数据可能是多个值，类似复选框CheckBox，直接使用request.POST.get()进行获取是有一些问题的，比如修改模板页面如下所示 1234567&lt;form action=\"/\" method=\"POST\"&gt; &#123;% csrf_token %&#125; &lt;input type=\"checkbox\" name=\"taste\" value=\"eat\"&gt;吃 &lt;input type=\"checkbox\" name=\"taste\" value=\"sleep\"&gt;睡 &lt;input type=\"checkbox\" name=\"taste\" value=\"play\"&gt;耍 &lt;input type=\"submit\" value=\"提交\"&gt;&lt;/form&gt; 这是一个name值为taste的兴趣爱好采集的多选框，value值将会作为选中时，提交到后台的值，比如现在我们全选这些表单数据，那么后台接收到的值是这样的 1&lt;QueryDict: &#123;'csrfmiddlewaretoken': ['nuaLzxc2E0artYKUZiefMPv5iHTX5gLFY1sCu8wi1vrKqpVFTWh7EnlCR64Hua5k'], 'taste': ['eat', 'sleep', 'play']&#125;&gt; 但是问题接踵而至，我们发现使用get函数获取不到对应全选的整个结果，而是只拿到了选中的最后一项 request.POST.get(key, default=None) 返回对应key值的数据中的最后一个数据单独返回；key值不存在，取default 要想真正拿出所有的结果，应该使用getlist函数 request.POST.getlist(key, default=None) 将对应key值的所有数据以一个列表形式返回；key值不存在，取default request.META request.MATE获取的是一个标准的python字典。它包含了所有的HTTP请求信息 比如用户IP地址和用户Agent（通常是浏览器的名称和版本号）。 注意，Header信息的完整列表取决于用户所发送的Header信息和服务器端设置的Header信息 CONTENT_LENGTH：请求的正文的长度，字符串类型 CONTENT_TYPE：请求的正文的MIME 类型 HTTP_ACCEPT：响应可接收的Content-Type HTTP_ACCEPT_ENCODING：响应可接收的编码 HTTP_ACCEPT_LANGUAGE：响应可接收的语言 HTTP_HOST：客服端发送的HTTP Host头部 HTTP_REFERER：请求前的连接地址 HTTP_USER_AGENT：客户端的user-agent字符串 QUERY_STRING：单个字符串形式的查询字符串（未解析过的形式） REMOTE_ADDR：客户端的IP 地址 REMOTE_HOST：客户端的主机名 REMOTE_USER：服务器认证后的用户 REQUEST_METHOD：一个字符串，例如GET 或POST SERVER_NAME：服务器的主机名 SE0RVER_PORT：服务器的端口，字符串类型 request.FILES 接收用户上传文件及相关信息。同样类似于request.POST，提取到的数据为一个类字典的数据类型，包含所有文件上传的信息 f = request.FILES.get(&#39;upload_file&#39;) file_data = f.read()：读取整个上传文件的内容，适合小文件上传 yiled = f.chunks()：返回一个类似生成器（&lt;class &#39;generator&#39;&gt;）的数据，每一次读取按块返回文件，可以通过for迭代访问其中数据；适合上传大文件到服务器。 f.multiple_chunks()：返回文件大小，当文件大小大于2.5M时，返回True，反之返回False，可以通过该函数来选择是否使用chunks方法或read直接存储。 如果想要修改这个文件判定的默认值，可以通过：FILE_UPLOAD_MAX_MEMORY_SIZE在settings文件下进行设置 f.content_type：上传文件时头部中的Content-Type字段值，参考MIME类型 f.name：上传文件名字 f.charset：上传文件编码 f.size： 上传文件大小，字节为单位：byte 创建好静态资源目录，并在下面创建一个img文件夹，保存我们即将上传的图片； 完成上传文件的HTML表单页面 1234567&lt;form action=\"/\" method=\"POST\" enctype=\"multipart/form-data\"&gt; &#123;% csrf_token %&#125; &lt;input type=\"file\" name=\"upload_file\" /&gt; &lt;input type=\"submit\" value=\"提交\"&gt;&lt;/form&gt; &lt;img src=\"&#123;% static 'img/1.jpg' %&#125;\" alt=\"这是一张图片\"&gt;&lt;!-- 这里使用的是即将要上传的文件名字，只做文件是否上传成功的简单测试 --&gt; 注意：上传文件的页面表单，一定要记得设置属性enctype=&quot;multipart/form-data&quot; 视图函数如下编写，接收上传图片，并保存在静态目录下刚才创建好的img目录中 12345678910111213def index(request): if request.method == \"POST\": f = request.FILES.get(\"upload_files\") path = os.path.join(settings.STATICFILES_DIRS[0],'img/'+f.name) # 上传文件本地保存路径 with open(path,'wb') as fp: if f.multiple_chunks: #判断到上传文件为大于2.5MB的大文件 for buf in f.chunks(): #迭代写入文件 fp.write(buf) else: fp.write(f.read()) return HttpResponse(\"Success!\") return render(request, 'index.html') 测试上传一个名为1.jpg的图片，如果成功上传，那么后台static目录下会出现该图片，并且模板页面也可以展示对应图片效果 HTTPResponse 一个视图的返回值经常是为了向用户返回一个HttpResponse响应， 有如下常用的可以返回HttpResponse的函数 response HttpResponse(content=b&#39;&#39;) 返回一个字符串内容 from django.http import HttpResponse render(request,template_name,context=None,content_type=None,status=None) 返回一个可渲染HTML页面，状态码为200 from django.shortcuts import render request：固定参数，响应的request请求，来自于参数部分接收的HttpRequest template_name：返回的模板页面路径 context：模板页面渲染所需的数据，默认为字典格式 content_type：生成之后的结果使用的MIME类型 status：响应的状态码，默认为200 redirect(to, permanent=False) 一个重定向，浏览器通过该状态码自动跳转到一个新的路由地址，默认返回响应状态码302 from django.shortcuts import redirect to：可以是一个django项目中视图函数的路由映射，也可以是一个reverse的反向路由解析 permanent：如果设置为True，将返回301状态码，代表永久重定向 12302：临时重定向，旧地址资源临时不能用了，搜索引擎只会暂时抓取新地址的内容而保存旧的地址。301：永久重定向，旧地址资源已经不复存在，搜索引擎不光会抓取新地址的内容，还会替换旧地址为新地址 视图错误处理 为了方便我们开发，django提供了一个异常叫做Http404异常，我们可以在视图函数的代码中按照需求进行抛出，抛出之后django项目会自动捕获该异常，并会展示默认的404页面 1234from django.http import Http404def index(request): if request.GET.get(\"id\") == \"1\": raise Http404 在settings中的debug配置项为false时，访问http://127.0.0.1:8000/?id=1，可以看到django为我们提供的错误页面； 除了django默认提供的，我们还可以可以在模板目录下定义全局404.html进行错误页面的定制 123&lt;h1&gt; 抱歉，找不到你要的东西&lt;/h1&gt; 自定义错误处理视图 除去404错误的自定义，django还提供了覆盖默认错误行为处理的办法； 有些时候，django自动的错误处理可能不能满足我们的需求，那么我们可以重新定义一些新的视图函数， 来覆盖掉django所提供的错误处理视图函数，最后在urls.py路由配置文件下通过定义全局变量来重新设置默认的错误处理视图函数 1234567891011121314handler404：覆盖page_not_found()视图。handler500：覆盖server_error()视图。handler403：覆盖permission_denied()视图。 handler400：覆盖bad_request()视图from django.contrib import adminfrom django.urls import path,includeurlpatterns = [ path('admin/', admin.site.urls), path('', include(\"viewapp.urls\")),]handler404 = \"viewapp.views.error_404\"# APP.模块.视图函数handler500 = \"viewapp.views.error_500\" 相关定义好的错误处理视图函数 12345678def error_404(request): return HttpResponse(\"这是404错误\")def error_403(request): return HttpResponse(\"这是403错误\")def error_500(request): return HttpResponse(\"这是500错误\")","categories":[],"tags":[{"name":"Django","slug":"Django","permalink":"http://laxe.top/tags/Django/"}]},{"title":"Django-Models-模型层","slug":"Django-Models-模型层","date":"2019-10-21T02:12:43.264Z","updated":"2019-10-21T02:13:34.002Z","comments":true,"path":"2019/10/21/Django-Models-模型层/","link":"","permalink":"http://laxe.top/2019/10/21/Django-Models-模型层/","excerpt":"模型层 该层开发的首要任务就是定义模型类以及属性 每个模型都可以被映射为数据库中的一个数据表，而类属性被映射为为数据字段 配置Mysql数据库 在确保mysql数据库可以连接使用的情况下； 首先在数据库中创建专为django使用的库django_data","text":"模型层 该层开发的首要任务就是定义模型类以及属性 每个模型都可以被映射为数据库中的一个数据表，而类属性被映射为为数据字段 配置Mysql数据库 在确保mysql数据库可以连接使用的情况下； 首先在数据库中创建专为django使用的库django_data 1create database django_data; 配置django的settings.py文件中的DATABASES属性如下 12345678910DATABASES = &#123; 'default': &#123; 'ENGINE': 'django.db.backends.mysql', # 数据库引擎 'NAME': \"django_data\", # 使用的库名 \"USER\": \"root\", # 用户名 \"PASSWORD\": \"123456\", # 数据库密码 \"HOST\": \"localhost\", # 数据库主机地址 \"PORT\": \"3306\" &#125;&#125; 由于使用django的Python版本为3+； 此时对于mysql的支持已经变为pymysql，而对于django加载数据库引擎时还需要使用2版本的mysqldb名称 现在先需要我们安装pymysql之后在项目中重申mysql引擎 首先安装pymysql 1pip install pymysql -i https://pypi.tuna.tsinghua.edu.cn/simple 项目主目录下的__init__文件中添加如下内容 12import pymysqlpymysql.install_as_MySQLdb() 现在整个项目的数据库使用已经切换到了mysql 模型层字段 在模型层类中的字段即是数据库中表的字段，表的字段设计非常重要 每一个字段都是Field基类的一个实例（Field类用来建立字段与数据库之间的映射） 模型字段定义不能以下划线结尾 django会根据在模型类中定义的字段属性来确定以下几点工作 数据库中使用的数据类型 模型类对应的表单类渲染时使用的表单类型及HTML部件 必填字段等最低限度的验证要求检查，包括admin界面下自动生成的表单 BooleanField BooleanField(**options)：True/False字段，默认值为None 表单类型：CheckboxInput，&lt;input type=&#39;checkbox&#39; ...&gt; CharField CharField(max_length=None)：字符串字段 含有一个必须参数：max_length设置最大的字符数长度限制； 表单类型：TextInput，&lt;input type=&quot;text&quot; ...&gt; DateField DateField(auto_now=False, auto_now_add=False,**options)：以 datetime.date实例表示的日期 含有两个可选参数：auto_now、auto_now_add auto_now：该值为True时，每次在保存数据对象时，自动设置该字段为当前时间，也可以理解为自动更新最后一次修改时间 auto_now_add：该值为True时，该字段设置在第一次数据对象创建时，可以记录当前字段创建的时间值 注意：避免矛盾，auto_now，auto_now_add，default不能同时出现，一个字段属性只能有其中一条设置，当设置了auto_now，或auto_now_add时，也会让该字段默认具有blank=True（字段可以为空）属性 表单类型：TextInput，&lt;input type=&quot;text&quot; ...&gt; DatetimeField DatetimeField(auto_now=False, auto_now_add=False,**options)：以datetime.datetime实例表示的日期和时间 和DateField具有相同的字段属性 DecimalField DecimalField(max_digits=None,decimal_places=None, **options)：以Decimal实例标示的十进制浮点数类型 含有两个可选参数：max_digits、decimal_places max_digits：位数总数，包括小数点后的位数，必须大于decimal_places参数 decimal_places：小数点后的数字数量，精度 表单类型：TextInput，&lt;input type=&quot;text&quot; ...&gt; EmailField EmailField(max_length=254, **option)：CharField子类，表示Email字段，并会检查是否为合法邮箱地址 默认参数：max_length，表示邮箱地址长度，默认为254 表单类型：TextInput，&lt;input type=&quot;text&quot; ...&gt; FloatField FloatField(**options)：使用float实例来表示的浮点数 表单类型：TextInput，&lt;input type=&quot;text&quot; ...&gt; IntegerField 12&gt; IntegerField(**options)`：一个整数，范围由`-2147483648`到`2147483647&gt; GenericIPAddressField GenericIPAddressField(protocol=both, unpack_ipv4=False, **options)：一个IPV4或IPV6地址的字符串 默认参数：protocol、unpack_ipv4 protocol：IP协议，ipv4或ipv6，默认both为全选 unpack_ipv4：解析IP地址，只有当协议为both时才可以使用 表单类型：TextInput，&lt;input type=&quot;text&quot;...&gt; SlugField SlugField(max_length=50, **option)：只包含字母、数字、下划线的字符串，常用来表示连接中的path部分或者一些其他短标题类型数据 TextField TextField(**options)：大文本字段 表单类型：Textarea，&lt;textarea&gt;...&lt;/textarea&gt; URLField URLField(max_length=200, **options)：CharField的子类，存储URL的字段 表单类型：TextInput，&lt;input type=&quot;text&quot;...&gt; 字段属性 以上所介绍的字段，均支持以下属性 null 如果该值为True，Django将在数据库中将控制存储为NULL 字符串字段CharField与TextField要避免使用null，因为空值字符串将存储空字符串（””）,而不是null值。 对于字符串类型的数据字段，大多数情况下，django使用空字符串代表空值 blank 如果该值为True，则在验证时该字段值可以为空； null为数据库存储层面可以为空，而blank为表单验证层面可以填写空值 choices 一个二元组的列表或元组； 元组中第一个值为真正在数据库中存储的值，第二个值为该选项的描述 该值一旦被设定，表单样式会显示选择框，而不是标准的文本框，选择框内的选项为choices中的元组 1234567class TestTable(models.Model): CHAR_CHOICE = [ ('H',\"非常苦难\"), ('M',\"中等难度\"), ('S',\"非常简单\"), ] choicechar = modesl.CharField(max_length=1,choices=CHAR_CHOICE) choices字段也支持分类的写法 12345678910111213CHAR_CHOICE = [ ('A', ( ('H',\"Hard\"), ) ), ('B', ( ('M',\"Medium\"), ) ), …] 分类的名称作为元组中的第一个值， 元组的第二个值为该分类下的一个新的二元组序列数据 db_column 数据库中用来表示该字段的名称，如果未指定，那么Django将会使用Field名作为字段名 db_index 当该值为True时，为该字段创建索引 default 该字段默认值，可以是一个值或是一个回调函数 当是一个函数对象时，在创建新对象时，函数调用 editable 如果设置该值为False，那么这个字段将不允许被编辑 不会出现在admin后台界面下，以及其他ModelForm表单中，同时也会跳过模型验证 primary_key 设置该值为True时，该字段成为模型的主键字段，一个模型类同时只能有一个主键 如果一个表中不存在任意一个设置好的主键字段，django会自动设置一个自增的AutoField字段来充当主键，该值可以用pk，id方式获取。主键的设置还意味着，null=False，unique=True unique 如果该值为True，代表这个数据在当前的表中有唯一值 这个字段还会在模型层验证存储的数据是否唯一 unique的设置也意味着当前字段具备索引的创建 ManyToManyField、OneToOneField与FileField字段不可以使用该属性 verbose_name 对于字段的一个可读性更高的名称 如果没有设置该值，django将字段名中的下换线转换成空格，作为当前字段的数据库中名称 模型元属性 在模型类的Meta类中，可以提供一系列的元选项，可以方便对该模型类进行属性设置或约束等 12345class TestTable(models.Model): … class Meta: ordering = [Fields] … abstract 代表当前模型类为抽象基类，不会创建真正的数据表，只是为了其他模型类继承使用 1abstract = True app_label 当模型类被定义在了其他app下，这个属性用来描述当前表属于哪个app应用 1app_label = \"MyApp\" db_table 当前模型类所对应的表名，未设置时，django默认将表名与app名由下划线组成，作为表名 需要注意这个表名为真实在数据库中所使用的，所以该元选项的使用应在数据表创建之前 如果在表已经存在的情况下去修改，会导致数据库内表与模型类表名不一致而查找不到报错 ordering 当前表中的数据存储时的排序规则，这是一个字段名的字符串，可以是一个列表或元组； 每一个字符串前可以使用”-“来倒序排序，使用”?“随机排序 ordering排序规则的添加，也会增加数据库的开销 12ordering = ['-birthday', 'age']#先按照birthday倒序排序，再按照age字段进行排序。 unique_together 用来设置表中的不重复字段组合 格式为一个元组，元组中的每个数据都是一个元组，用来描述不重复的组合字段 如果只处理单一字段组合，可以是一个一维的元组 联合约束 1unique_together = (('name','phone'),) verbose_name 一般设置该表展示时所用的名称，名称被自动处理为复数，字符串后加一个”s” verbose_name_plural 与verbose_name功能相同，但是不会自动在字符串后加”s“以表复数 设置表的复数名称 模型操作 在进行模型操作的学习之前，可以先创建一个测试的数据库模型类，如下所示 123class Person(models.Model): name = models.CharField(max_length=10,verbose_name=\"姓名\") age = models.IntegerField(verbose_name=\"年龄\") 创建对象 django自带了一个数据库测试的shell工具 这是一个非常方便可以让我们对django代码进行测试的环境 可以直接通过python manage.py shell命令行管理工具来打开 实例save创建数据 通过模型类的关键词参数实例化一个对象来进行数据的创建 123&gt;&gt;&gt; from app.models import Person&gt;&gt;&gt; p1 = Person(name='张三',age=15)&gt;&gt;&gt; p1.save() 以上的代码，在为字段赋予值之后，通过实例的save函数进行该数据的保存 在数据库底层执行了SQL语句中的insert操作，并且，在我们显示调用save之前，django不会访问数据库，实例数据只存在于内存中 注意：save函数没有返回值 create方法创建数据1&gt;&gt;&gt; P1 = Person.objects.create(name='李四',age=20) 这条语句创建一条数据，并且返回一个数据在内存中的实例P1 之后可以通过这个实例字段P1对数据库中该条数据进行修改或删除操作 create 方法一步到位，save方式可以慢悠悠的赋予字段值，最后赋予结束再save 查找对象 接下来，我们将通过模型类中的管理器进行数据的查询； 管理器（Manager）是每一个模型类所具有的，默认名为objects 模型类通过模型类调用orm数据接口，其实就是在对数据表进行操作。 注意，具体的某一条数据无法访问这个管理器 all() 获取一个表中的所有数据，返回QuerySet数据对象 1all_person = Person.objects.all() filter(**kwargs) 返回一个包含数据对象的集合，满足参数中所给的条件 12res = Person.objects.all().filter(age__lt=16)res = Person.objects.filter(age__lt=16) 我们在查询过程中，除了直接使用字段属性进行验证 还可以在字段名之后使用双下化线来标明更加详细的字段筛选条件（在下一节会有详细的字段筛选条件介绍），也叫做链式过滤 这也是为什么表单类字段不可以以下换线结尾的原因 exclude(**kwargs) 返回一个包含数据对象的集合，数据为不满足参数中所给的条件 filter()查询会始终返回一个结果集，哪怕只有一个数据。 但是有些时候，我们对于一些在数据表中的唯一数据进行查询时，可以使用更加合适的get方法 注意：创建结果集的过程不涉及任何数据库的操作，查询工作是惰性的，在上面的查询方式中，查询代码不会实际访问数据库，只有查询集在真正使用时，django才会访问数据库 get(**kwargs) 获取唯一单条数据 get获取数据只会返回一条匹配的结果，获取的数据只能在数据库中有一条 如果返回多个结果，会引发MultipleObjectsReturned异常 如果没有任何匹配到的结果也会引发DoesNotExist异常 1Person.objects.get(pk=1) order_by(*field) 默认情况下，数据表使用模型类中的Meta中指定的ordering选项进行排序 现在也可以通过使用order_by函数进行查询结果的排序 1Person.objects.order_by('age') 1Person.objects.all().order_by('-age') count() 返回数据库中对应字段的个数，并且该函数永远不会引发异常 12models.Person.objects.filter(age=20).count()Person.objects.count() 使用count函数时，还需要对数据表进行迭代访问 所以有时使用已生产好的结果集，通过len函数获取长度，这种方式效率会更高 count方法的调用会导致额外的数据库查询 values(*fields) 返回一个查询集结果，但是迭代访问时返回的是字典，而不是数据实例对象 12models.Person.objects.all().values()models.Person.objects.values() 链式过滤条件 exact 如果在查询过程中，没有提供查询类型（没有双下划线），那么查询类型就会被默认指定为exact，这是一种严格查找的方式，用来在数据库中查找和查询时的关键词参数完全一致的内容 12&gt;&gt;&gt; Person.objects.filter(account='root')&gt;&gt;&gt; Person.objects.filter(account__exact='root') iexact 忽略大小写的匹配 12&gt;&gt;&gt; Person.objects.filter(account__iexact='root')#匹配到的结果可能是Root，ROot，ROOt，ROOT startswith、endswith 分别匹配开头和结尾，区分大小写 12&gt;&gt;&gt; Person.objects.filter(passwd__startswith='admin')#匹配以admin开头的数据 istartswith、iendswith 分别匹配开头和结尾，忽略大小写 12&gt;&gt;&gt; Person.objects.filter(passwd__istartswith='admin')匹配以不区分大小写的字符串admin为开头的数据 gte 大于或等于 1&gt;&gt;&gt; Person.objects.filter(reg_data__gte=datetime.date.today) lte 小于或等于 1&gt;&gt;&gt; Person.objects.filter(reg_data__lte=datetime.date.today) 修改对象 获取到对应的数据实例之后，通过.的方式访问数据实例中的属性，进行数据的字段修改 123p = models.Person.objects.get(pk=1)p.age = 21p.save() 对过滤出的结果链式调用update()函数，这样的修改，类似批量修改，update函数会返回成功修改的个数 12models.Person.objects.filter(age__gt=100).update(age=25)# 将所有年纪小于100的人的年纪改为20 删除对象 对于普通的单表数据删除，获取到数据实例对象后调用内置的delete()函数即可 1models.Person.objects.get(pk=1).delete() 需要注意的是，删除一条数据之后，默认占有的主键ID值并不会被下一个新插入的值所占用 比如 1，2，3，4；删除掉3之后，剩下：1，2，4；下一个值存储时，id是5，3不会被复用 字段关系 字段关系是django维护表关系的方式；其中主要有一对一，多对一以及多对多， 现在的一对一及多对一关系中需要设置on_delete属性用来描述当关联数据被删除时的操作，有如下一些 models.CASCADE：删除关联数据,与之关联也删除 models.PROTECT：删除关联数据,引发错误ProtectedError models.SET_NULL：与之关联的值设置为null（前提FK字段需要设置为可空） models.SET_DEFAULT： 删除关联数据,与之关联的值设置为默认值（前提FK字段需要设置默认值） models.DO_NOTHING：删除关联数据,什么也不做 一对一关系 模型类使用OneToOneField用来定义一对一关系； 比如当你拥有一个老师表时，紧接着你还需要一个教授表，那么教授表可能拥有老师表的一系列属性，那么你还不想把老师表中的字段直接复制到教授表那么可以通过OnToOneField来实现教授表继承老师表。 其实，在使用模型类继承时，也隐含有一个一对一关系 OneToOneField(to, on_delete, parent_link=False, options) 12345678910class Teacher(models.Model): name = models.CharField(max_length=50) age = models.CharField(max_length=50) def __str__(self): return self.nameclass Professor(models.Model): teacher = models.OneToOneField(Teacher,primary_key=True,on_delete=models.CASCADE) big_project = models.CharField(max_length=50) def __str__(self): return self.teacher.name 在manage.py shell下进行数据库操作 123456789&gt;&gt;&gt; t1 = Teacher.objects.create(name='Jack',age='22')&gt;&gt;&gt; t2 = Teacher.objects.create(name='Bob',age='17')&gt;&gt;&gt; p1 = Professor.objects.create(teacher=t1,big_project='雾霾净化术')&gt;&gt;&gt; p1.teacher&lt;Teacher: Jack&gt;&gt;&gt;&gt; p1.teacher = t2&gt;&gt;&gt; p1.save()&gt;&gt;&gt; p1.teacher&lt;Teacher: Bob&gt; 在上面的测试中，看似已经将p1对应的教授变成了Bob； 但是在数据库中之前t1老师所对应的教授信息还存在，此时的赋值操作并不会覆盖掉教授他之前的教授数据，只是重新创建了一条。 正确的做法应该是将某一条数据的一对一关系通过delete关系先删除之后再重新赋予 多对一关系 Django使用django.db.models.ForeignKey定义多对一关系。 ForeignKey需要一个位置参数：与该模型关联的类 生活中的多对一关系：班主任，班级关系。一个班主任可以带很多班级，但是每个班级只能有一个班主任 1234567891011121314151617class Headmaster(models.Model): name = models.CharField(max_length=50) def __str__(self): return self.nameclass Class(models.Model): class_name = models.CharField(max_length=50) teacher = models.ForeignKey(Headmaster,null=True,on_delete=models.SET_NULL) def __str__(self): return self.class_name&gt;&gt;&gt; H1 = Headmaster(name='渔夫')&gt;&gt;&gt; H1.save()&gt;&gt;&gt; H1&lt;Headmaster: 渔夫&gt;&gt;&gt;&gt; H2 = Headmaster(name='农夫')&gt;&gt;&gt; H2.save()&gt;&gt;&gt; Headmaster.objects.all()[&lt;Headmaster: 渔夫&gt;, &lt;Headmaster: 农夫&gt;] 以上创建了两条老师数据 由于我们设置外键关联可以为空null=True,所以此时在班级表创建时，可以直接保存，不需要提供老师数据 12345678&gt;&gt;&gt; C1 = Class(class_name='一班')&gt;&gt;&gt; C2 = Class(class_name='二班')#如果外键设置不为空时，保存会引发以下错误# IntegrityError: NOT NULL constraint failed: bbs_class.teacher_id&gt;&gt;&gt; C1.teacher = H1&gt;&gt;&gt; C2.teacher = H2&gt;&gt;&gt; C1.save()&gt;&gt;&gt; C2.save() 将老师分配个班级之后，由于班级表关联了老师字段，我们可以通过班级找到对应老师 虽然老师表中没有关联班级字段，但是也可以通过老师找到他所带的班级，这种查询方式也叫作关联查询 通过模型类名称后追加一个’_set’，来实现反向查询 12&gt;&gt;&gt; H1.class_set.all()&lt;QuerySet [&lt;Class: 一班&gt;]&gt; 由于我们这是一个多对一的关系，也就说明我们的老师可以对应多个班级 我们可以继续给H1老师分配新的班级 12345&gt;&gt;&gt; C3 = Class(class_name='三班')&gt;&gt;&gt; C3.teacher = H1&gt;&gt;&gt; C3.save()&gt;&gt;&gt; H1.class_set.all()[&lt;Class: 一班&gt;, &lt;Class: 三班&gt;] 一个班级只能对应一个老师，外键是唯一的，那么你在继续给C1班级分配一个新的老师时，会覆盖之前的老师信息，并不会保存一个新的老师 12345678&gt;&gt;&gt; H3 = Headmaster(name='伙夫')&gt;&gt;&gt; H3.save()&gt;&gt;&gt; C1.teacher&lt;Headmaster: 渔夫&gt;&gt;&gt;&gt; C1.teacher=H3&gt;&gt;&gt; C1.save()&gt;&gt;&gt; C1.teacher&lt;Headmaster: 伙夫&gt; 把这个班级的老师删除，由于设置了外键字段可以为null，此时班级的老师选项为null 123456789101112131415&gt;&gt;&gt; t1 = Headmaster.objects.all().first()&gt;&gt;&gt; t1&gt;&gt;&gt; c1 = Class.objects.all().first()&lt;Headmaster: 渔夫&gt;&gt;&gt;&gt; c1&lt;Class: 一班&gt;&gt;&gt;&gt; c1.teacher&lt;Headmaster: 渔夫&gt;&gt;&gt;&gt; t1.delete()(1, &#123;'modelsapp.Headmaster': 1&#125;)&gt;&gt;&gt; c1 = Class.objects.all().first()&gt;&gt;&gt; c1&lt;Class: 一班&gt;&gt;&gt;&gt; c1.teacher&gt;&gt;&gt; #这里什么都没有，因为此时C1的老师已经是个None了 要记得删除之后要重新获取一次数据，否则查看到的结果中还是之前获取到的有老师的班级数据 多对多关系 多对多关系在模型中使用ManyToManyField字段定义 多对多关系可以是具有关联，也可以是没有关联，所以不需要明确指定on_delete属性 生活中，多对多关系：一个音乐家可以隶属于多个乐队，一个乐队可以有多个音乐家 123456789class Artist(models.Model): artist_name = models.CharField(max_length=50) def __str__(self): return self.artist_nameclass Band(models.Model): band_name = models.CharField(max_length=50) artist = models.ManyToManyField(Artist) def __str__(self): return self.band_name 创建音乐家以及乐队 12345&gt;&gt;&gt; from bbs.models import Artist,Band&gt;&gt;&gt; A1 = Artist.objects.create(artist_name='Jack')&gt;&gt;&gt; A2 = Artist.objects.create(artist_name='Bob')&gt;&gt;&gt; B1 = Band.objects.create(band_name='FiveMonthDay')&gt;&gt;&gt; B2 = Band.objects.create(band_name='SHE') 创建出两个乐队之后对其进行音乐家的添加 多对多字段添加时，可以使用add函数进行多值增加 12&gt;&gt;&gt; B1.artist.add(A1,A2)&gt;&gt;&gt; B2.artist.add(A2) B1乐队含有A1,A2两名成员 B2乐队含有A1成员 1234&gt;&gt;&gt; B1.artist.all()[&lt;Artist: Bob&gt;, &lt;Artist: Jack&gt;]&gt;&gt;&gt; B2.artist.all() [&lt;Artist: Jack&gt;] 可以在音乐家表中查找某个乐家属于哪些乐队 1234&gt;&gt;&gt; Band.objects.filter(artist=A1) # 这里使用的是我们模型类来进行查找。[&lt;Band: SHE&gt;, &lt;Band: FiveMonthDay&gt;] # A1乐家属于，SHE以及FiveMonthDay&gt;&gt;&gt; Band.objects.filter(artist=A2)[&lt;Band: SHE&gt;] 也可以查找这音乐家在哪个乐队 1234&gt;&gt;&gt; A1.band_set.all() # 直接通过具体数据对象进行查找[&lt;Band: SHE&gt;, &lt;Band: FiveMonthDay&gt;]&gt;&gt;&gt; A2.band_set.all()[&lt;Band: SHE&gt;] 多对多关联字段的删除，要使用remove来进行关系的断开 而不是直接使用delete，remove只会断开数据之间的联系，但是不会将数据删除 现在在B1乐队中删除A1乐家 123&gt;&gt;&gt; B1.artist.remove(A1)&gt;&gt;&gt; B1.artist.all()&lt;QuerySet [&lt;Artist: Bob&gt;]&gt; 关联表的查询 如果想要查询的字段在关联表，则使用表名小写__字段来进行跨表查询操作 创建一个多对一关系的父子表，一个父亲可能有多个儿子 12345678910class Father(models.Model): name = models.CharField(max_length=30) age = models.CharField(max_length=30) def __str__(self): return self.nameclass Son(models.Model): father = models.ForeignKey(Father,on_delete=models.CASCADE) name = models.CharField(max_length=30) def __str__(self): return self.name 创建数据 123456&gt;&gt;&gt; f1 = Father.objects.create(name='Jack',age='30')&gt;&gt;&gt; s1 = Son.objects.create(name='Json',father=f1)&gt;&gt;&gt; s2 = Son.objects.create(name='Json2',father=f1)&gt;&gt;&gt; f2 = Father.objects.create(name='Bob',age='40')&gt;&gt;&gt; s3 = Son.objects.create(name='Json3',father=f2) 查询所有父亲名字是jack的孩子 12&gt;&gt;&gt; Son.objects.filter(father__name__exact='Jack')[&lt;Son: Json&gt;, &lt;Son: Json2&gt;] 查询所有儿子名开头为J的父亲 12&gt;&gt;&gt; Father.objects.filter(son__name__startswith='J')[&lt;Father: Jack&gt;, &lt;Father: Jack&gt;, &lt;Father: Bob&gt;] 获取到某一个父亲的所有孩子，通过某一条数据的小写表名_set反向查询 12&gt;&gt;&gt; f1.son_set.all()&gt;&gt;&gt; [&lt;Son: Json&gt;, &lt;Son: Json2&gt;] 数据的反向查询 默认的，当有某一条数据获取到之后，我们可以通过模型类名称加上一个 _set，来实现反向查询 现在设计两个表为军队和士兵表，并且士兵多对一关联军队 123456789class Aramy(models.Model): name = models.CharField(max_length=30) def __str__(self): return self.nameclass Soldier(models.Model): aramy = models.ForeignKey(Aramy,on_delete=models.CASCADE) name = models.CharField(max_length=30) def __str__(self): return self.name 创建一些数据 123456&gt;&gt;&gt; a1 = Aramy(name='一军')&gt;&gt;&gt; a1.save()&gt;&gt;&gt; s1 = Soldier(name='张三',aramy=a1)&gt;&gt;&gt; s1.save()&gt;&gt;&gt; s2 = Soldier(name='李四',aramy=a1)&gt;&gt;&gt; s2.save() 通过soldier_set我们就可以关联到对应的士兵表 并且对应返回结果可以执行我们常用的filter，exclude等查询操作 1234&gt;&gt;&gt; a1.soldier_set.all()[&lt;Soldier: 张三&gt;, &lt;Soldier: 李四&gt;]&gt;&gt;&gt; a1.soldier_set.filter(name='张三')[&lt;Soldier: 张三&gt;] 也可以通过定义关联字段中的related_name值，来实现自定义的反向查询名字 且related_name的值必须唯一 123456789class Aramy(models.Model): name = models.CharField(max_length=30) def __str__(self): return self.nameclass Soldier(models.Model): aramy = models.ForeignKey(Aramy,on_delete=models.CASCADE,related_name='soldier') name = models.CharField(max_length=30) def __str__(self): return self.name 接下来通过某条数据反向查询 1234&gt;&gt;&gt; a1 = Aramy.objects.all()[0]&gt;&gt;&gt; s1 = Soldier.objects.get(name='张三')&gt;&gt;&gt; a1.soldier.all()[&lt;Soldier: 张三&gt;, &lt;Soldier: 李四&gt;] 注意：related_name一定是一个唯一的值，否则反向查找时会出现二异性错误 也可以将related_name初始化为+，来取消反向查询","categories":[],"tags":[{"name":"Django","slug":"Django","permalink":"http://laxe.top/tags/Django/"}]},{"title":"Cookie和Session","slug":"Cookie和Session","date":"2019-10-21T02:11:28.147Z","updated":"2019-10-21T02:12:24.966Z","comments":true,"path":"2019/10/21/Cookie和Session/","link":"","permalink":"http://laxe.top/2019/10/21/Cookie和Session/","excerpt":"Cookie和Session Cookie及Session一直以来都是Web开发中非常关键的一环，因为HTTP协议本身为无状态，每一次请求之间没有任何状态信息保持，往往我们的Web服务无法在客户端访问过程中得知用户的一些状态信息，比如是否登录等等；那么这里通过引入Cookie或者Seesion来解决这个问题。","text":"Cookie和Session Cookie及Session一直以来都是Web开发中非常关键的一环，因为HTTP协议本身为无状态，每一次请求之间没有任何状态信息保持，往往我们的Web服务无法在客户端访问过程中得知用户的一些状态信息，比如是否登录等等；那么这里通过引入Cookie或者Seesion来解决这个问题。 当客户端访问时，服务端会为客户端生成一个Cookie键值对数据，通过Response响应给到客户端。当下一次客户端继续访问相同的服务端时，浏览器客户端就会将这个Cookie值连带发送到服务端。 Cookie值存储在浏览器下，一般在你的浏览器安装目录的Cookie目录下，我们也可以通过F12或者各种浏览器的开发者工具来获取到 因为cookie是保存在浏览器中的一个纯明文字符串，所以一般来说服务端在生成cookie值时不建议存储敏感信息比如密码 Cookie 在django的代码中，我们可以使用一些提供Response响应的类，如：HttpResponse，redirect等实例的内置set_cookie函数来进行django项目中的Cookie设置 set_cookie(key, value=&#39;&#39;, max_age=None, expires=None, path=&#39;/&#39;,domain=None, secure=False, httponly=False) key：Cookie的key值，未来通过该key值获取到对应设置好的Cookie。 value=&#39;&#39;：对应Cookie的key值的value，比如：set_cookie(key=&#39;value&#39;,value=&#39;shuai&#39;) max_age=None：Cookie生效的时间，单位为秒，如果Cookie值只持续在客户端浏览器的会话时长，那么这个值应该为None。存在该值时，expires会被计算得到。 expires=None：Cookie具体过期日期，是一个datetime.datetime对象，如果该值存在，那么max_age也会被计算得到 1234import datetimecurrent_time = datetime.datetime.now() # 当前时间expires_time = current_time + datetime.timedelta(seconds=10) # 向后推延十秒set_cookie('key','value',expires=expires_time) #设置Cookie及对应超时时间 path=&#39;/&#39;：指定哪些url可以访问到Cookie，默认/为所有。 domain=None：当我们需要设置的为一个跨域的Cookie值，那么可以使用该参数，比如：domain=&#39;.test.com&#39;，那么这个Cookie值可以被www.test.com、bbs.test.com等主域名相同的域所读取，否则Cookie只被设置的它的域所读取。为None时，代表当前域名下全局生效。 secure=False：https加密传输设置，当使用https协议时，需要设置该值，同样的，如果设置该值为True，如果不是https连接情况下，不会发送该Cookie值。 httponly=False：HTTPOnly是包含在HTTP响应头部中Set-Cookie中的一个标记。为一个bool值，当设置为True时，代表阻止客户端的Javascript访问Cookie。这是一种降低客户端脚本访问受保护的Cookie数据风险的有效的办法 设置COOKIE 简单的实现一下COOKIE的设置 12345678from django.shortcuts import render,HttpResponse# Create your views here.def set_cookie(request): # 在HTTPResponse部分设置COOKIE值 cookie_reponse = HttpResponse('这是一个关于cookie的测试') cookie_reponse.set_cookie('test','hello cookie') return cookie_reponse 以上视图函数返回一个HttpResponse对象，并在该对象中集成COOKIE值的设定，设置key值为test，value值为hello cookie 获取COOKIE 再来简单的实现一下COOKIE的获取 1234def get_cookie(request): # 获取cookie值，从request属性中的COOKIE属性中 cookie_data = request.COOKIES.get('test') return HttpResponse('Cookie值为:%s' % cookie_data) Cookie值存储在，request中的COOKIES属性中 并且该属性获取到的结果与字典类似，直接通过内置函数get获取即可 删除COOKIE 这里通过该视图函数路由进行COOKIE的删除 1234def delete_cookie(request): response = HttpResponseRedirect('/check_cookie/') response.delete_cookie('test') return response delete_cookie(key, path=&#39;/&#39;, domain=None) 在Cookie中删除指定的key及对应的value，如果key值不存在，也不会引发任何异常。 由于Cookie的工作方式，path和domain应该与set_cookie时使用的值相同，否则Cookie值将不会被删除 通过response相应类的delete_cookie方法，本来应该在会话结束之后才消失的Cookie值，现在已经被直接删除掉。后台中通过Request中的Cookie字典获取到值也为None 不要忘记字典的get，获取不到结果时，返回None 但是，现在还有一个问题，我们在用户浏览器存储的Cookei值为明文，具有极大的安全隐患，django也提供了加密的Cookie值存储及获取方式 防止篡改COOKIE 通过set_signed_cookie函数进行持有签名的COOKIE值设置，避免用户在客户端进行修改 要记得，这个函数并不是对COOKIE值进行加密 HttpResonse.set_signed_cookie(key, value, salt=&#39;&#39;, max_age=None, expires=None, path=&#39;/&#39;, domain=None, secure=None, httponly=True) 为cookie值添加签名，其余参数与set_cookie相同 Request.get_signed_cookie(key, salt=&#39;&#39;, max_age=None) 从用户请求中获取通过salt盐值加了签名的Cookie值。 这里的salt要与之前存储时使用的salt值相同才可以解析出正确结果。 还要注意的是，如果对应的key值不存在，则会引发KeyError异常，所以要记得异常捕获来确定是否含有Cookie值 123456789def check_salt_cookie(request): try: salt_cookie = request.get_signed_cookie(key='salt_cookie',salt='nice') except KeyError: #获取不到该key值的Cookie response = HttpResponse('正在设置一个salt Cookie值') response.set_signed_cookie(key='salt_cookie',salt='nice',value='salt_cookie') return response else: #获取到了对应key值，展示到新的HttpResonse中 return HttpResponse('获取到的salt Cookie值:%s' % salt_cookie) 第一次访问的时候，还没有加Cookie值，所以我们在获取的时候会抛出KeyError异常 此时捕获异常，并且设置Cookie即可； 再次刷新的时候，因为这里已经给出了Cookie值，则不会引发异常，会在页面中展示获取到的加盐Cookie Session 虽然说有了Cookie之后，我们把一些信息保存在客户端浏览器中，可以保持用户在访问站点时的状态，但是也存在一定的安全隐患，Cookie值被曝露，Cookie值被他人篡改，等等。我们将换一种更健全的方式，也就是接下来要说的Session。 Session在网络中，又称会话控制，简称会话。用以存储用户访问站点时所需的信息及配置属性。当用户在我们的Web服务中跳转时，存储在Session中的数据不会丢失，可以一直在整个会话过程中存活。 在django中，默认的Session存储在数据库中session表里。默认有效期为两个星期。 session创建流程 客户端访问服务端，服务端为每一个客户端返回一个唯一的sessionid，比如xxx。 客户端需要保持某些状态，比如维持登陆。那么服务端会构造一个{sessionid: xxx }类似这样的字典数据加到Cookie中发送给用户。注意此时，只是一个随机字符串，返回给客户端的内容并不会像之前一样包含实际数据。 服务端在后台把返回给客户端的xxx字符串作为key值，对应需要保存的服务端数据为一个新的字典，存储在服务器上，例如：{xxx : {id:1}} 之后的一些客户端数据获取，都是通过获取客户端向服务端发起的HttpRequest请求中里Cookie中的sessionid之后，再用该sessionid从服务端的Session数据中调取该客户端存储的Session数据 注意：补充说明，默认存储在数据库的Session数据，是通过base64 编码的，我们可以通过Python的base64模块下的b64decode()解码得到原始数据 整个过程结束之后：客户端浏览器存储的其实也只是一个识别会话的随机字符串（xxx） 而服务器中是通过这个随机的字符串（xxx:value）进行真正的存储 Session的使用必须在Settings配置下 12345678910INSTALLED_APPS = ( ... 'django.contrib.sessions', ...)MIDDLEWARE_CLASSES = ( 'django.contrib.sessions.middleware.SessionMiddleware', ...) 当settings.py中SessionMiddleware激活后 在视图函数的参数request接收到的客户端发来的HttpResquest请求对象中都会含有一个session属性 这个属性和之前所讨论的Cookie类似，是一个类字典对象，首先支持如下常用字典内置属性 获取Session session_data = request.session.get(Key) session_data = request.session[Key] 在Session中获取对应值，get方法获取时，如不存在该Key值，不会引发异常，返回None 而第二种直接通过字典获取，如Key值不存在，引发KeyErro 删除Session del request.seesion[Key] 删除对应session，Key值不存在时，引发KeyError request.session.clear() 清空Session中的所有数据。这里客户端还会保留sessionid 只不过在服务端sessionid对应的数据没有了。 request.session.flush() 直接删除当前客户端的的Seesion数据。这里不光服务端sessionid对应的数据没有了，客户端的sessionid也会被删除 设置有效期 request.session.set_expiry(value)： 设置Session的有效时间。 value：有效时间。 为整数时：将在value为秒单位之后过期 为0时：将在用户关闭浏览器之后过期。 为None时：使用全局过期的设置，默认为两个星期，14天。 为datetime时：在这个指定时间后过期。 request.session.get_expiry_age() 返回距离过期还剩下的秒数。 request.session.clear_expired() 清除过期的Session会话。 编写一个简单的视图函数来玩耍Session吧 1234567891011121314151617from django.shortcuts import render,HttpResponseimport datetimedef set_session(request): if request.session.get('test_id'): session_data = request.session.get('test_id')# 用户拿到的的session随机字符串 session_key = request.session.session_key # 获取客户端浏览器中的SessionID值 session_expire = request.session.get_expiry_age() now = datetime.datetime.now() expire_time = now + datetime.timedelta(seconds=session_expire) response = '&lt;div&gt;SessionID : %s&lt;/div&gt;' % session_key + \\ '&lt;div&gt;Session : %s&lt;/div&gt;' % session_data + \\ '&lt;div&gt;ExpireTime : %s&lt;/div&gt;' % expire_time return HttpResponse(response) else: request.session['test_id'] = 'TEST' request.session.set_expiry(None) return HttpResponse('已设置好Session') 用户在第一次访问时，会走else分支，此时还没有任何服务端的Session及客户端的Cookie值设定 那么我们会通过request.session[Key]的方式来设置一个Session值，值为TEST 当用户第二次访问时将展示出所设置好的Session值及在客户端浏览器中存储的sessionid 在编写一个删除Session的视图函数吧 123456def delete_session(request): if request.session.get('test_id'): del request.session['test_id'] return HttpResponse('Session被删了') else: return HttpResponse('目前没有任何需要删除的session') 这里温柔的使用del request.session[Key]的方式来进行Session的删除 如果存在对应test_id的Session值则删除，反之返回一个字符串 Session删除总结 使用的是del的针对性删除方式，这样不会将整个客户端的session删除掉 使用request.session.clear()，只是清空了服务端Session中的数据，但是客户端的Cookie中还会保存sessionid，只不过这个值对应的字符串所对应的用户数据是一个空 使用request.session.flush()，那么客户端Cookie中保存的sessionid首先会被删除，其次服务端通过sessionid值保存的用户数据也会被全部删除。","categories":[],"tags":[{"name":"Django","slug":"Django","permalink":"http://laxe.top/tags/Django/"}]},{"title":"Django的消息框架(message)与Django分页组件(paginator)","slug":"Django的消息框架(message)与Django分页组件(paginator)","date":"2019-10-21T02:10:07.945Z","updated":"2019-10-21T02:11:00.796Z","comments":true,"path":"2019/10/21/Django的消息框架(message)与Django分页组件(paginator)/","link":"","permalink":"http://laxe.top/2019/10/21/Django的消息框架(message)与Django分页组件(paginator)/","excerpt":"Messages消息框架 在网页应用中，你经常需要在处理完表单或其它类型的用户输入后。显示一个通知消息（也叫做flash message给用户 对于这个功能，Django提供基于Cookie 和会话的消息，无论是匿名用户还是认证的用户。 其消息框架允许你临时将消息存储在请求中，并在接下来的请求（通常就是下一个请求）中提取它们并显示。每个消息都带有一个特定level 标签，表示其优先级（例如info、warning 或error）","text":"Messages消息框架 在网页应用中，你经常需要在处理完表单或其它类型的用户输入后。显示一个通知消息（也叫做flash message给用户 对于这个功能，Django提供基于Cookie 和会话的消息，无论是匿名用户还是认证的用户。 其消息框架允许你临时将消息存储在请求中，并在接下来的请求（通常就是下一个请求）中提取它们并显示。每个消息都带有一个特定level 标签，表示其优先级（例如info、warning 或error） django-admin startproject 创建的默认settings.py 已经包含启用消息框架功能需要的所有的设置 INSTALLED_APPS 中的&#39;django.contrib.messages&#39;。 MIDDLEWARE_CLASSES 中的&#39;django.contrib.sessions.middleware.SessionMiddleware&#39; 和&#39;django.contrib.messages.middleware.MessageMiddleware&#39; 默认的后端存储 依赖[sessions] 所以MIDDLEWARE_CLASSES 中必须启用SessionMiddleware 并出现在MessageMiddleware 之前 TEMPLATES 设置中定义的DjangoTemplates 的&#39;context_processors&#39; 选项包含&#39;django.contrib.messages.context_processors.messages&#39; 消息级别 12&gt; from django.contrib import messages&gt; messages.debug messages.info messages.success messages.warning messages.error 使用消息框架 视图函数只需要创建messages消息对象即可 12messages.warning(request,'登陆失败，用户名或密码无效')return render(request,'login.html',locals()) 前端模板中判断是否含有messages消息，遍历取出即可 也可以结合bootstrap框架让提示消息变得更加美丽 1234567&#123;% if messages %&#125; &#123;% for message in messages %&#125; &lt;div class=\"alert alert-&#123;&#123; message.tags &#125;&#125; fade in\"&gt; &#123;&#123; message &#125;&#125; &lt;/div&gt; &#123;% endfor %&#125;&#123;% endif %&#125; 注意：messages对象是一个数据集，并不是单独的一条消息，需要我们在使用时，必须通过for循环进行访问 Paginator分页组件 12&gt; from django.core.paginator import Paginator, EmptyPage, PageNotAnInteger&gt; 1Paginator ：创建分页对象 分页对象内置属性 1234567891011121314all_ = models.objects.all()p = Paginator(all_, 10)# 分页all_数据，每页显示10条数据p.count # 总数据量p.num_pages() # 分页数p.page_range() # 列表形式返回当前可有的页数 [1,2,3]page_1 = p.page(1) # 选择第一页，返回第一页数据对象page_1.object_list # 返回第一页所有数据for var in page_1: print(var)ABC... 某一页内置属性12345678page_1.number # 当前页的页码page_1.has_next() # 是否有下一页page_1.has_previous() # 是否有上一页page_1.has_other_pages() # 是否含有其他页page_1.next_page_number() # 下一页的页码page_1.previous_page_number() # 上一页的页码page_1.start_index() # 该页第一个数据的索引page_1.end_index() # 该页最后一个数据的索引 EmptyPage：取不到页面数据，抛出该异常 1234567all_ = models.objects.all()p = Paginator(all_, 10)try: list_ = p.page(page_num)except EmptyPage: #没有第page_num页 list_ = paginator.page(1) # 取不到该也数据，直接返回第一页数据 PageNotAnInteger：当页数是一个非整数类型时，抛出该异常 模板页面基本使用方式1234567891011&#123;% if topic_list.has_previous %&#125; &lt;!-- 当前页是否含有上一页 --&gt; &lt;a href=\"?page=&#123;&#123; list_.previous_page_number &#125;&#125;\"&gt;上一页&lt;/a&gt; &lt;!-- 连接传参形式传递上一页的页码ID --&gt;&#123;% endif %&#125;&#123;% if topic_list.has_next %&#125; &lt;!-- 当前页是否含有下一页 --&gt; &lt;a href=\"?page=&#123;&#123; list_.next_page_number &#125;&#125;\"&gt;下一页&lt;/a&gt; &lt;!-- 连接传参形式传递下一页的页码ID --&gt;&#123;% endif %&#125;","categories":[],"tags":[{"name":"Django","slug":"Django","permalink":"http://laxe.top/tags/Django/"}]},{"title":"Django-Forms-表单层","slug":"Django-Forms-表单层","date":"2019-10-21T02:09:00.549Z","updated":"2019-10-21T02:09:48.626Z","comments":true,"path":"2019/10/21/Django-Forms-表单层/","link":"","permalink":"http://laxe.top/2019/10/21/Django-Forms-表单层/","excerpt":"Forms django提供了一整套健全的机制来帮助我们自动创建对应HTML中的表单，类似序列化器 开发者可以方便的使用已经设定好的一系列字段进行表单的设计 可以在某个app下面新建一个forms.py文件，在这个文件编写django自带表单类的编写 比如像下面这样","text":"Forms django提供了一整套健全的机制来帮助我们自动创建对应HTML中的表单，类似序列化器 开发者可以方便的使用已经设定好的一系列字段进行表单的设计 可以在某个app下面新建一个forms.py文件，在这个文件编写django自带表单类的编写 比如像下面这样 123from django import formsclass TestForm(forms.Form): name = forms.CharField(label='名字:',max_length=100) 在这个表单类中，设置了一个CharField字段，并且具有label标签值为name 此外在&lt;input&gt;标签处还会设置maxlength=100的属性 django在接收到这样表单内的数据时，还将验证数据的长度 实例化该类，然后打印出来查看效果 1&lt;tr&gt;&lt;th&gt;&lt;label for=\"id_name\"&gt;名字:&lt;/label&gt;&lt;/th&gt;&lt;td&gt;&lt;input type=\"text\" name=\"name\" maxlength=\"100\" required id=\"id_name\" /&gt;&lt;/td&gt;&lt;/tr&gt; 在渲染后的结果中不包含提交的按钮，以及外层的form标签，还需要我们自己手动在模板页面中进行添加 form表单实例的使用也非常简单，直接在模板页面处将表单实例以模板变量形式传递赋值即可 12345678910# views.pydef index(request): form = forms.TestForm() return render(request,'index.html',locals())&lt;!-- index.html --&gt;&lt;form action=\"/\" method=\"POST\"&gt; &#123;% csrf_token %&#125; &#123;&#123; form &#125;&#125; &lt;input type=\"submit\" value=\"提交\"&gt;&lt;/form&gt; is_valid 每一个form类的实例都具有一个is_valid()方法，验证表单内的字段是否合法，并将表单中合法的的数据将放到表单中的cleaned_data属性中 如果全部数据都没有问题，那么该函数将会返回True，返回的合法数据。结果是一个字典的数据类型 123456789101112form = TestFrom()if form.is_valid(): data = form.cleaned_datadef post_test(request): if request.method == \"POST\": form = TestForm(request.POST) if form.is_valid(): name = form.cleaned_data.get('name') return HttpResponse('OK') else: form = TestForm() return render(request, \"xxx.html\",&#123;\"form\":form&#125;) 在视图函数中，当用户以post形式提交数据，此时将post数据与表单类进行关联 使用post数据做为类实例化的参数，这种操作也叫作绑定数据到表单 如果用户在表单中填写张三并提交，那么绑定数据之后的表单实例像是这样 12&lt;label for=\"id_name\"&gt;名字:&lt;/label&gt;&lt;input id=\"id_name\" maxlength=\"100\" name=\"name\" type=\"text\" value=\"张三\" /&gt; input标签中的value值为用户post所提交的数据 如果绑定数据的表单实例经过is_valid函数校验并通过，那么正确的数据将存储在cleaned_data中，cleaned_data中的数据同时也是处理好的Python数据类型，比如这里为一个字典数据类型 接下来在视图函数中可以直接通过字典的操作方式来获取到用户在对应表单标签中所填写的数据 表单字段类型 所有表单字段Field的子类均带有默认参数require BooleanField 控件：CheckboxInput 复选框：&lt;input type=&#39;checkbox&#39; ...&gt; 空值：False 12&gt; Python`：`True\\False&gt; 错误键：required CharField 控件：TextInput 文本输入：&lt;input type=&quot;text&quot; ...&gt; 空值：空字符串 12&gt; Python`：`str&gt; 错误键：max_length、min_length、required ChoiceField 控件：Select 选择框：&lt;select&gt;&lt;option ...&gt;...&lt;/select&gt; 空值：空字符串 Python：Unicode str 必选参数：choices，该参数为一个二元组组成的可迭代对象，二元组中的第一个值为获取到的数据，第二个值为表单中展示的内容。 错误键：required、invalid_choice 123456class TestForm(forms.Form): choices = ( ('0','男'), ('1','女'), ) gender = forms.ChoiceField(choices=choices) DateField 控件：DateInput 日期以普通的文本框输入：&lt;input type=&#39;text&#39; ...&gt; 空值：None Python：datetime.date 验证是否为一个指定日期格式的字符串 错误键：required、invalid 可选参数：input_formats，一个时间格式化字符串，用来将表单中的数据转换为datetime.date对象 可选参数格式参考如下： 123'%Y-%m-%d', # '2006-10-25''%m/%d/%Y', # '10/25/2006''%m/%d/%y' # '10/25/06' DateTimeField 控件：DateTimeInput 日期/时间以普通的文本框输入：&lt;input type=’text’ …&gt; 空值：None Python：datetime.datetime 验证是否为一个指定日期格式的字符串 可选参数：input_formats，一个时间格式化字符串，用来将表单中的数据转换为datetime.datetime对象 错误键：required、invalid DecimalField 控件：当Field.localize 是False 时为NumberInput，否则为TextInput 123&gt; NumberInput`文本输入：`&lt;input type=\"number\" ...&gt;&gt; TextInput`文本输入：`&lt;input type=\"text\" ...&gt;&gt; 空值：None Python：decimal 验证给定值是否为一个十进制数字 可选参数：max_value、min_value控制大小值范围 max_digits：值允许的最大位数（小数点之前和之后的数字总共的位数，前导的零将被删除） decimal_places：允许的最大小数位 错误键：required，invalid， max_value， min_value， max_digits， max_decimal_places max_whole_digits EmailField 控件：文本输入：&lt;input type=&quot;email&quot; ...&gt; 空值：空字符串 Python：Unicode str 使用正则验证给定的值是否为一个合法的邮件地址 可选参数：max_length与min_length，限定邮件地址字符串大小长度。 错误键：required、invalid FileField 控件：ClearableFileInput 文件上传输入：&lt;input type=&#39;file&#39; ...&gt; 空值：None Python：UploadedFile 验证非空的文件数据绑定到表单 使用该字段时，在使用表单实例获取上传文件数据时，表单标签中需要具备enctype=&quot;multipart/form-data&quot;属性，此外还需要绑定文件数据在表单上 1form = TestForm(request.POST,request.FILES) FloatField 控件：当Field.localize是False 时为NumberInput，否则为TextInput NumberInput文本输入：&lt;input type=&quot;number&quot; ...&gt; TextInput文本输入：&lt;input type=&quot;text&quot; ...&gt; 空值：None Python：Float 验证给出的值是一个浮点数，对比float函数 可选参数：max_value、min_value限定大小值范围 错误键：required， invalid， max_value，min_value ImageField 控件：ClearableFileInput 文件上传输入：&lt;input type=&#39;file&#39; ...&gt; 空值：None Python：UploadedFile 验证文件数据并且检验是否是一个可以被pillow所解释的图像 使用该字段，需要安装pillow模块。 错误键：required，invalid，missing，empty，invalid_image IntergerField 控件：当Field.localize 是False时为NumberInput，否则为TextInput NumberInput文本输入：&lt;input type=&quot;number&quot; ...&gt; TextInput文本输入：&lt;input type=&quot;text&quot; ...&gt; 空值：None Python：int 验证给定的值是否是一个整数 可选参数：max_value、min_value限定大小值范围 错误键：required，invalid，max_value，min_value GenericIPAddressField 控件：TextInput 文本输入：&lt;input type=&quot;text&quot; ...&gt; 空值：空字符串 Python：Unicode str 可选参数 protocol：默认值为both，可选IPv4或IPv6。 错误键：required，invalid MultipleChoiceField 控件：SelectMultiple &lt;select multiple=&#39;multiple&#39;&gt;...&lt;/select&gt; 空值：一个空列表 Python：list 验证表单中的值是否存在于选择列表中，对比ChoiceField，该字段支持多选 必选参数：choices，与ChoiceField类似，接收一个二元组可迭代对象 错误键：required，invalid_choice，invalid_list RegexField 控件：TextInput 文本输入：&lt;input type=&quot;text&quot; ...&gt; 空值：空字符串 Python：Unicode str 验证表单中值与某个正则表达式匹配 必选参数：regex，字符串或编译的正则表达式 可选参数：max_length、min_length 错误键：required，invalid SlugField 控件：TextInput 文本输入：&lt;input type=&quot;text&quot; ...&gt; 空值：空字符串 Python：Unicode对象 验证给定的值为字母、数字、下划线及连字符组成 错误键：required，invalid URLField 控件：TextInput 文本输入：&lt;input type=&quot;text&quot; ...&gt; 空值：空字符串 Python：Unicode对象 验证给定值是一个有效的URL 可选参数：max_length、min_length 错误键：required，invalid TimeField 控件：TextInput 文本输入：&lt;input type=&quot;text&quot; ...&gt; 空值：None Python：datetime.time 验证给定值是否为一个给定格式的时间字符串 可选参数：input_formats，控制表单输入的格式 表单属性 required： 表单字段为必填值，当传递数据为一个空值，不管是空字符串还是None 在表单验证时，将引发ValidationError异常，这个异常将会在表单上展示错误信息 label 指定当前字段的label标签值，字段默认Label为字段名所有下换线转换为空格 且一个字母大写生成 label_suffix 修改label提示字符串的追加符号，默认表单类实例化过程会自动在label属性后加: initial 字段的初始值。不能将初始值直接作为参数传入，会造成直接验证表单数据而报错。 1form = forms.TestForm(initial=&#123;'name':'Bob'&#125;) widget 表单字段渲染时使用的Widget类，如果不想使用默认的表单类型，通过该参数指明所需表单控件 可以使用类似的表单类型，在下面会有详细的介绍。 help_text 指定字段的描述文本，该文本一般会紧挨着字段显示 表单控件：widget 默认django会为每一个表单字段设置默认的HTML控件 控件用来渲染HTML中输入元素与提取提交的原始数据 如果你希望使用一个不同的控件Widget，可以为字段设置widget参数 1234from django import formsclass CommentForm(forms.Form): comment = forms.CharField(widget=forms.Textarea)#修改CharField默认控件TextInput为Textarea 此外，我们还可以为字段的Widget设置额外的属性 比如一些之后在HTML渲染时候将会使用到的标签class值等等 只需要在widget参数部分使用attrs形参指定即可，该参数设置这个字段控件的对应HTML属性 1234name = forms.CharField( max_length=5, widget=forms.TextInput(attrs=&#123;'class':'green'&#125;)) 还可以使用日期控件覆盖默认日期控件 1234567YEARS = ('2016', '2017', '2018')MONTHS = &#123; 1:'一月', 2:'二月', 3:'三月', 4:'四月',5:'五月', 6:'六月', 7:'七月', 8:'八月',9:'九月', 10:'十月', 11:'十一月', 12:'十二月'&#125;birth_year = forms.DateField(widget=froms.SelectDateWidget(years=YEARS,months=MONTHS)) 文本输入控件 TextInput 文本输入：&lt;input type=&quot;text&quot; ...&gt; NumberInput 文本输入：&lt;input type=&quot;number&quot; ...&gt; EmailInput 文本输入：&lt;input type=&quot;email&quot; ...&gt; URLInput 文本输入：&lt;input type=&quot;url&quot; ...&gt; PasswordInput 密码输入：&lt;input type=&#39;password&#39; ...&gt; HiddenInput 隐藏输入：&lt;input type=&#39;hidden&#39; ...&gt; DateInput 日期以普通的文本框输入：&lt;input type=&#39;text&#39; ...&gt; 可选参数：format，时间的字符串格式 DateTimeInput 日期/时间以普通的文本框输入：&lt;input type=&#39;text&#39; ...&gt; 可选参数：format，时间的字符串格式 TimeInput 时间以普通的文本框输入：&lt;input type=&#39;text&#39; ...&gt; 可选参数：format，时间的字符串格式 Textarea 文本区域：&lt;textarea&gt;...&lt;/textarea&gt; 选择和复选框 CheckboxInput 复选框：&lt;input type=&#39;checkbox&#39; ...&gt; 可选参数：check_test 这个参数接收一个函数对象，函数对象的参数为当前CheckboxInput的值，函数对象如果返回True，该控件在字段渲染时自动勾上。 1comment = forms.CharField(widget=forms.CheckboxInput(check_test=lambda *arg: True)) Select 单选框：&lt;select&gt;&lt;option ...&gt;...&lt;/select&gt; 可选参数：choices，与字段设置相同，但是会被字段设置所覆盖。 NullBooleanSelect 单选框：选项为Unknown、Yes和No，Unknown也代表False。 SelectMultiple 多选框：&lt;select multiple=&#39;multiple&#39;&gt;...&lt;/select&gt; RadioSelect 单选框，与select类似，但是会将选择渲染为一个单选按钮列表 CheckboxSelectMultiple 多选框：与SelectMultiple类似，但是会渲染为一个复选框列表/ 复合控件 SelectDateWidget 封装了三个Widget，分别用于年、月、日 可选参数：可以来指定日期表单的选择 years：一个列表或元组的序列数据类型，用来确定年的选择。 months：一个字典数据类型，字典的key值为月份数字，从1开始，value值为在表单中渲染展示的字符串，比如 12345MONTHS = &#123; 1:'一月', 2:'二月', 3:'三月', 4:'四月', 5:'五月', 6:'六月', 7:'七月', 8:'八月', 9:'九月', 10:'十月', 11:'十一月', 12:'十二月'&#125; 表单API 表单类的实例，只有两种，一种是绑定了数据的，一种是未绑定的。都可以渲染成为html Form.is_valid() 对于绑定了数据的表单，进行验证并返回一个数据是否合法的布尔值 并在所有数据有效时将数据放入cleaned_data中 Form.is_bound() 区分绑定表单和未绑定表单，当表单类绑定数据时，返回True Form.errors 当验证发生错误时的错误信息的字典，字典key值为字段名称，value为报错信息列表，可能有多个报错 表单的数据将会在调用is_valid时或访问errors属性时验证 并且验证过程只会调用一次，不论访问errors和调用is_valid多少次 12345678class TestForm(forms.Form): name = forms.CharField(max_length=5,) email = forms.EmailField(required=True) def clean_name(self): cleaned_data = super(TestForm,self).clean() if self.cleaned_data.get('name') == '小红': raise forms.ValidationError(\"不允许小红\") return cleaned_data 123&gt;&gt;&gt; f = forms.TestForm(&#123;'name':'小红','emali':'123'&#125;)&gt;&gt;&gt; a.errors&#123;'name': ['不允许小红'], 'email': ['This field is required.']&#125; Form.errors.as_data 返回报错信息的字典，映射字段报错信息到一个ValidationError实例 12345&gt;&gt;&gt; f.errors.as_data()&#123; 'name': [ValidationError(['不允许小红'])], 'email': [ValidationError(['This field is required.'])]&#125; Form.errors.as_json(escape_html=False) 以json格式返回错误信息 12345&gt;&gt;&gt; a.errors.as_json()'&#123; \"name\": [&#123;\"message\": \"\\\\u4e0d\\\\u5141\\\\u8bb8\\\\u5c0f\\\\u7ea2\", \"code\": \"\"&#125;], \"email\": [&#123;\"message\": \"This field is required.\", \"code\": \"required\"&#125;]&#125;' Form.initial 声明当前表单类的默认数据，参数为一个字典数据类型 key对应需要填充默认数据的表单字段，value值为实际数据 12class TestForm(forms.Form): name = forms.CharField(max_length=5,initial='Jack',) 1234567&gt;&gt;&gt; f = TestForm(initial=&#123;'name':'Bob'&#125;)&gt;&gt;&gt; print(f)&lt;tr&gt;&lt;th&gt;&lt;label for=\"id_name\"&gt;Name:&lt;/label&gt;&lt;/th&gt;&lt;td&gt;&lt;input id=\"id_name\" maxlength=\"5\" name=\"name\" type=\"text\" value=\"Bob\" /&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt; Form.has_changed() 检查表单当前的数据是否与默认值不同 123&gt;&gt;&gt; f = TestForm(data=&#123;'name':'Jack'&#125;,initial=&#123;'name':'Bob'&#125;)&gt;&gt;&gt; f.has_changed()True Form.cleaned_data 在对绑定数据的表单实例进行is_valid验证之后，如果数据无误 那么返回的数据将保存在cleaned_data中 如果有部分数据没有经过验证，那么cleaned_data中也会保留合法的字段 并且，在cleaned_data属性中获取到的数据，只包含表单类中含有的字段 1234class TestForm(forms.Form): name = forms.CharField(max_length=5,) email = forms.EmailField(required=True) active = forms.BooleanField() 1234567891011&gt;&gt;&gt; data = &#123;... 'name':'Jack', ... 'email':'111',... 'active':True,... &#125;&gt;&gt;&gt;&gt;&gt;&gt; f = TestForm(data=data)&gt;&gt;&gt; f.is_valid()False&gt;&gt;&gt; f.cleaned_data&#123; 'name':'Jack', 'active': True&#125; Form.as_p() 将表单渲染为一系列的&lt;p&gt;标签，每个标签内含一个字段 12class TestFrom(forms.Form): name = forms.CharField(max_length=5) 123&gt;&gt;&gt; f = TestForm()&gt;&gt;&gt; print(f.as_p())&lt;p&gt;&lt;label for=\"id_name\"&gt;Name:&lt;/label&gt; &lt;input id=\"id_name\" maxlength=\"5\" name=\"name\" type=\"text\" /&gt;&lt;/p&gt; Form.as_ul() 渲染表单为一系列的&lt;li&gt;标签，并且不包含&lt;ul&gt;标签，可以自行指定&lt;ul&gt;的HTML属性 12&gt;&gt;&gt; print(f.as_ul())&lt;li&gt;&lt;label for=\"id_name\"&gt;Name:&lt;/label&gt; &lt;input id=\"id_name\" maxlength=\"5\" name=\"name\" type=\"text\" /&gt;&lt;/li&gt; Form.as_table() 渲染表单为&lt;tr&gt;&lt;th&gt;标签 12&gt;&gt;&gt; print(f.as_table())&lt;tr&gt;&lt;th&gt;&lt;label for=\"id_name\"&gt;Name:&lt;/label&gt;&lt;/th&gt;&lt;td&gt;&lt;input id=\"id_name\" maxlength=\"5\" name=\"name\" type=\"text\" /&gt;&lt;/td&gt;&lt;/tr&gt; 配置表单元素的HTML id值与默认自带的label标签 通过表单类进行渲染时，默认会包含以下属性 表单元素的HTML id属性 辅助的label标签 有些时候，想要设置自定义HTML id值或者取消label标签，可以使用如下内置函数 Form.auto_id=True 修改对应渲染表单属性 当auto_id值为False时，表单类的渲染将不会包含&lt;label&gt;以及id属性 123&gt;&gt;&gt; f = TestForm(auto_id=False)&gt;&gt;&gt; print(f)&lt;tr&gt;&lt;th&gt;Name:&lt;/th&gt;&lt;td&gt;&lt;input maxlength=\"5\" name=\"name\" type=\"text\" /&gt;&lt;/td&gt;&lt;/tr&gt; 模板中表单实例属性 模板页面接收到的form表单实例支持循环遍历访问 123&#123;% for field in form %&#125; &#123;&#123; field &#125;&#125;&#123;% endfor %&#125; 其中for迭代访问之后的每一个表单字段又支持如下操作 ``：字段的label，例如Email address。 ``：包含在HTML 标签中的字段值。 ``：这个字段的ID值。 ``：字段的值 ``：该字段的标签中name属性使用的值。 ``：该字段的帮助文档。 ``：字段的验证错误信息，字段标签会在 ``：如果该字段为隐藏字段，返回True。反之返回False。 ``：获取当前字段实例，可以用该属性来访问字段实例的属性 1&#123;&#123; field.field.max_length &#125;&#125; 与模型类关联的表单 除了以上我们自定义表单类来进行表单的初始化 django还提供了另外一种表单类的创建方法，可以通过与模型关联来构建表单 这种办法可以更加省时省力，直接使用模型类中已经定义好的字段来进行表单字段的生成 1234567class TestTable(modes.Model): name = models.CharField(max_length=10) class TestTableForm(forms.ModelForm): class Meta: model = TestTable fields = ['name'] 生成的表单实例将具备模型类中的字段，表单生成的字段顺序也与模型类中的定义顺序相同 fields属性用来显示的设置所有需要在表单中处理的字段 也可以直接为该字段设置fields = &#39;__all__&#39;来使用所有模型类中的字段作为未来的表单字段 注意 ： 如果模型类中字段定义了blank=True，那么对应关联的表单类中字段会默认具有require=False的属性 模型类中字段的verbose_name属性对应关联表单类字段的Label属性 如果模型类字段中设置了choices值，那么对应关联表单字段的widget将会设置为select 当然，除了根据关联模型类来创建表单类，还可以在关联表单类中选择性的覆盖某些字段的设置 比如使用表单类Meta元类中的widgets属性可以以字典形式设置对应字段的控件 12345678class TestTableForm(forms.ModelForm): name = forms.URLField() class Meta: model = TestTable fields = ['name'] widgets = &#123; 'name':forms.Textarea(attrs=&#123;'class':'green'&#125;) &#125; 除此之外，还可以指定labels、help_texts和error_messages等信息 1234567891011121314151617class TestTableForm(forms.ModelForm): name = forms.URLField() class Meta: model = TestTable fields = ['name'] labels = &#123; 'name':'您的名字' &#125; help_texts = &#123; 'name':'请输入您的名字' &#125; error_messages = &#123; 'name':&#123; 'required':'你必须填写这个名字', 'max_length':'你的名字太长了' &#125; &#125; 与模型关联的表单验证 表单的验证在我们调用is_valid函数时执行，也可以通过访问errors属性或调用full_clean函数 验证的出错会引发ValidationError异常，该异常会向表单传达一个错误信息 验证的步骤主要分为两步，表单验证，如果关联了模型，则还会进行模型验证 表单字段的验证分为以下过程 字段to_python，这个方法将字段的值根据字段的类型转换为Python中的数据类型，如果不能转换则引发ValidationError异常 字段的clean函数，该函数用来运行对应的验证器，根据顺序执行to_python，validate特异性验证，以及run_validators（用于将错误信息汇总）验证，如果有任何验证过程引发了ValidationError异常，验证都将停止。其余通过验证的字段数据插入到表单的cleaned_data字典中 表单中的字段clean函数，这个验证用于完成特定属性，与表单字段类型无关；比如我们经常需要验证用户输入的字段值不能为小红，那么可以编写字段的clean函数，函数命名为clean_&lt;fields_name&gt;，fileds_name为字段名 123456class TestTableForm(forms.ModelForm):def clean_name(self): name = self.cleaned_data.get('name') if name == '小红': raise forms.ValidationError('不允许小红') return name 表单的clean函数，这个方法进行表单中多个字段值的联合验证，验证之后的数据返回为cleaned_data，可以通过重写该函数来提供的额外验证方法，并且为了维持clean方法的验证行为，在代码中，表单类需要调用父类的clean方法 123456def clean(self): cleaned_data = super(TestTableForm,self).clean() name = cleaned_data.get('name') if '1' in name: cleaned_data['name'] = name.replace('1','一') return cleaned_data 最后总结的来说： 一个表单在验证时，首先验证每一个字段，接着调用字段的clean_fields函数，最后使用表单类的clean函数进行验证 如果表单与模型关联，那么现在还有第二步验证，模型的验证 模型的验证为如下过程 验证关联模型的字段及相关属性：Model.clean_fields(exclud=None)，该方法将验证模型的所有字段属性，如果有字段验证错误，引发ValidationError异常 验证模型的完整性：Model.clean(exclude=None)，可以对模型做整体的检验，如果想要自己验证模型中通过属性校验的数据，可以在模型类中重新定义这个函数 123456from django.core.exceptions import ValidationErrorclass TestTable(models.Model): name = models.CharField(max_length=10,verbose_name='名字',unique=True) def clean(self): if '$' in self.name: raise ValidationError('无法使用$符号') 验证模型的唯一性：Model.validate_unique(exclude=None)，如果模型中所有唯一约束性，比如使用类似unique属性，会校验表单中的值是否唯一 并且，除了通过绑定模型的表单实例is_valid函数可以来进行以上的验证过程，如果想自己控制验证 可以直接使用模型的full_clean(exclude=None,validate_unique=True)方法进行以上三个步骤的验证 与模型关联的表单保存 与模型关联的表单，在校验成功之后，表单实例可以直接通过save函数来进行表单数据的保存数据库 123456def form_test(request): if request.method == \"POST\": form = TestTableForm(request.POST,request.FILES) if form.is_valid(): form.save() return HttpResponse('OK:%s' % value) 该函数也支持在模型类中进行重写，但是要切记使用父类的save方法，确保数据可以正确存储到数据库中 12345def save(self, *args, **kwargs): if self.name == 'abc': return False#不做存储 else: super(TestTable,self).save(*args, **kwargs)","categories":[],"tags":[{"name":"Django","slug":"Django","permalink":"http://laxe.top/tags/Django/"}]},{"title":"Django的CBV类视图","slug":"Django的CBV类视图","date":"2019-10-21T02:07:49.040Z","updated":"2019-10-21T02:08:32.370Z","comments":true,"path":"2019/10/21/Django的CBV类视图/","link":"","permalink":"http://laxe.top/2019/10/21/Django的CBV类视图/","excerpt":"CBV CBV（class base views） 就是在视图里使用类处理请求 之前的代码中，我们的视图函数都是通过函数来进行request的响应以及response的返回，并且通常我们需要判断的请求方式get或是post都需要我们在代码中通过if进行条件判断，这样的视图功能编写就叫做FBV","text":"CBV CBV（class base views） 就是在视图里使用类处理请求 之前的代码中，我们的视图函数都是通过函数来进行request的响应以及response的返回，并且通常我们需要判断的请求方式get或是post都需要我们在代码中通过if进行条件判断，这样的视图功能编写就叫做FBV 但现在在django中还提供了一种方式叫做CBV，在类中编写视图功能， 并且将传统的get、post判断设置为了类中函数，这样当用户发起不同的请求，会自动进入到对应的类中函数上，像是下面这样 1234567891011from django.views import Viewclass ArticleView(View): def get(self,request): raise Http404 def post(self,request): if request.is_ajax(): id_ = request.POST.get('id_') result = models.Article.objects.get(id=id_).content data = result.replace('\\r\\n','&lt;br&gt;') return HttpResponse(json.dumps(data,ensure_ascii=False) ) raise Http404 通过将请求类型定义为函数，可以更加方便进行请求方式判断 用户访问时，会经由View基类中的as_view -&gt; dispatch进行判断，通过请求类型分发到不同对应请求的函数名下；也就是通过get方式访问，那么对应会调用到名为get的函数 此外，类中函数必须为小写， 对应路由此时设置为，需要使用试图类的as_view函数进行实例化 12#url.pypath('article/',ajaxviews.ArticleView.as_view()) 通过类视图可以方便我们进行请求条件的判断 并且可以在进行接口开发时，实现同一资源路由在使用不同请求访问时的功能解耦和 意思就是不用再把所有的功能都堆到一个视图函数里啦。多方便！ 并且，在Django-Restframework框架中，也将频繁使用CBV形式进行视图编写 类视图装饰器 在类视图中使用为函数视图准备的装饰器时，不能直接添加装饰器 需要使用method_decorator将其转换为适用于类视图方法的装饰器 12&gt; from django.utils.decorators import method_decorator&gt; 全部装饰 1234567891011121314151617from django.views import Viewfrom django.utils.decorators import method_decoratordef my_decorator(func): def nei(request): # dispatch函数有参数request print('这是装饰器在调用') return func(request) return nei@method_decorator(my_decorator, name='dispatch')# 为全部请求方法添加装饰器class DemoView(View): def get(self, request): print('get方法') return HttpResponse('ok') def post(self, request): print('post方法') return HttpResponse('ok') 为部分装饰，只需要通过method_decorator方法的name参数选择装饰的函数名即可 123456789@method_decorator(my_decorator, name='post')class DemoView(View): def get(self, request): print('get方法') return HttpResponse('ok') def post(self, request): print('post方法') return HttpResponse('ok') 为特定的多个类视图函数进行装饰，只需要在每个函数上使用method_decorator装饰器即可 1234567class DemoView(View): @method_decorator(my_decorator) # 为get方法添加了装饰器 def get(self, request): return HttpResponse('ok') @method_decorator(my_decorator) # 为post方法添加了装饰器 def post(self, request): return HttpResponse('ok') 类视图csrf_token装饰 当类视图需要允许跨站提交数据时，使用csrf_exempt装饰器装饰函数可以被跨域访问 但是使用上面的方法进行csrf_exempt是不行的，需要在类视图基类的dispatch函数上进行装饰 123456789101112from django.views.decorators.csrf import csrf_exempt#@method_decorator(csrf_exempt,name='dispatch') # 直接加载类视图上也是可以修饰的class DemoView(View): @method_decorator(csrf_exempt) def dispatch(self, request, *args, **kwargs): return super(DemoView,self).dispatch(request, *args, **kwargs) def get(self, request): print('get方法') return HttpResponse('ok') def post(self, request): print('post方法') return HttpResponse('ok') csrf装饰只能在类视图的dispatch函数上才能被生效 除了在类视图的dispatch函数上进行装饰，在路由映射处使用csrf_exempt函数修饰路由规则也是可以的 123456#urls.pyfrom django.views.decorators.csrf import csrf_exempturlpatterns = [ ... path('',csrf_exempt(ajaxviews.DemoView.as_view()))]","categories":[],"tags":[{"name":"Django","slug":"Django","permalink":"http://laxe.top/tags/Django/"}]},{"title":"Ajax及Axios异步请求，接口数据序列化处理","slug":"Ajax及Axios异步请求，接口数据序列化处理","date":"2019-10-21T02:06:42.088Z","updated":"2019-10-21T02:07:27.363Z","comments":true,"path":"2019/10/21/Ajax及Axios异步请求，接口数据序列化处理/","link":"","permalink":"http://laxe.top/2019/10/21/Ajax及Axios异步请求，接口数据序列化处理/","excerpt":"Ajax ajax可以使当前浏览器不需要整个重新加载，只是局部刷新，给用户的体验良好，也因为只是刷新局部页面，相对而言效率更高一些 同步交互：客户端发出一个请求后，需要等待服务器相应结束后，才可以发起第二个请求 异步交互：客户端发出一个请求后，无需等待该次服务器的相应，即可发起第二个请求","text":"Ajax ajax可以使当前浏览器不需要整个重新加载，只是局部刷新，给用户的体验良好，也因为只是刷新局部页面，相对而言效率更高一些 同步交互：客户端发出一个请求后，需要等待服务器相应结束后，才可以发起第二个请求 异步交互：客户端发出一个请求后，无需等待该次服务器的相应，即可发起第二个请求 json数据类型 数据在键值对中 数据由逗号分隔 花括号存储数据 方括号保存数组 12345[ &#123; \"name\":\"Bill\", \"age\":1 &#125;, &#123; \"name\":\"George\", \"age\":2 &#125;, &#123; \"name\":\"Thomas\", \"age\": 3 &#125;]; jQuery-Ajax 使用ajax进行django后台数据的异步获取，django只是提供的数据，并不承担前端页面的渲染工程 这里使用jQuery所提供的ajax方法进行异步通信 首先测试数据库中模型类定义如下： 12345678class Article(models.Model): title = models.CharField(max_length=50,verbose_name=\"标题\") author = models.CharField(max_length=20,verbose_name=\"作者\") date = models.DateField(auto_now_add=True,verbose_name=\"发表日期\") content = models.TextField(verbose_name=\"文章内容\") def __str__(self): return self.title 测试数据可由用户自行添加，非常简单 编写主页视图函数，返回所有数据库中内容 123def index(request): articles = models.Article.objects.all() return render(request,'ajax/index.html',locals()) 此处的index.html页面不光承担所有数据的渲染工作 还将负责未来ajax异步请求，获取对应文章的详细内容 index.html页面代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;style&gt; label&#123; border: 5px outset gray; width: 150px; margin-top: 10px; &#125;&lt;/style&gt;&lt;head&gt; &#123;% load staticfiles %&#125; &lt;meta charset=\"utf-8\"&gt; &lt;title&gt;Ajax测试&lt;/title&gt; &lt;script type=\"text/javascript\" src=\"&#123;% static 'js/jquery-1.10.2.min.js' %&#125;\"&gt;&lt;/script&gt; &lt;script type=\"text/javascript\" src=\"&#123;% static 'js/jquery.cookie.js' %&#125;\"&gt;&lt;/script&gt; &lt;!-- 该js文件用来引入jquery所提供的获取cookie值的库 为了提取对应csrf_token--&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;这是一个ajax的请求测试&lt;/h1&gt; &#123;% for article in articles %&#125; &lt;label class=\"&#123;&#123; article.id &#125;&#125;\"&gt;&#123;&#123; article.author &#125;&#125;:&#123;&#123; article.title &#125;&#125;&lt;/label&gt; &#123;% endfor %&#125; &lt;p class=\"content\"&gt;&lt;/p&gt;&lt;/body&gt;&lt;script type=\"text/javascript\"&gt; $(document).ready(function () &#123; $(\"label\").click(function () &#123; $.ajax(&#123; url: '/article/', // 请求地址，对应Django某个路由映射 type: 'POST', // 请求方式 post data: &#123; 'csrfmiddlewaretoken': $.cookie('csrftoken'), // 提交数据需有当前csrf_token 防跨站请求伪造令牌 'id_': $(this).attr('class'), // 获取当前的id值 传递到视图后台 &#125;, success: function (result) &#123; var data = JSON.parse(result) // 解析获得实际字符串 $('.content').html(data) // 将内容以html形式显示到对应的p标签上 &#125; &#125;) &#125;) &#125;)&lt;/script&gt; 有了前端页面，并且ajax的请求地址为/article/，那么就需要我们定义一个视图函数返回对应的json数据，并且设置路由为/article/ 123456789101112131415161718192021#urls.pypath('ajax/',ajaxviews.index), # 首页路由path('article/',ajaxviews.article) # ajax请求路由#views.pydef article(request): if request.is_ajax(): # 判断是否为ajax请求 if request.method == \"POST\": # 为ajax的post方式请求 id_ = request.POST.get('id_') if id_: try: content = models.Article.objects.get(id=id_).content.replace('\\r\\n','&lt;br&gt;') # 这里还将获取到的文章字符串内容中的换行替换为HTML的换行标签 except models.Article.DoesNotExist: raise Http404 else: data = json.dumps(content,ensure_ascii=False,cls=JsonEncoder) # 返回get对应取到的实际属性 return HttpResponse(data) raise Http404 这里要注意的是，后端返回的数据得是序列化之后的才可以被前端js所解析，直接返回一个django model数据实例是不行的。所以需要我们视图函数对需要返回的数据进行序列化操作 对于数据的序列化操作主要有以下两种 json序列化 普通Python数据直接使用json模块进行序列化 12345content = models.Article.objects.get(id=id_).content.replace('\\r\\n','&lt;br&gt;')#这里将文章内容对应返回，之所以有replace函数，是因为文章数据是通过admin后台复制添加，需要将其中的\\r\\n换行转换为HTML可以解析的&lt;br&gt;标识符data = json.dumps(content,ensure_ascii=False)# 第二个参数是因为序列化时对中文默认使用的ascii编码，此时需要将该值设置为False，这样前端接收到时才是一个正常中文结果return HttpResponse(data) 但如果要序列化的数据中包含时间类型date 或datetime时，这种办法就会报错啦 12&gt; TypeError: Object of type date is not JSON serializable&gt; 12345678910111213class JsonEncoder(json.JSONEncoder): # 自定义json处理器 def default(self, obj): if isinstance(obj, datetime): # 如果判断到类型为datetime格式 return obj.strftime('%Y-%m-%d %H:%M:%S') # 处理为字符串类型的 (年-月-日 时:分:秒) elif isinstance(obj, date): # 如果判断到json处理数据为date类型 return obj.strftime('%Y-%m-%d') else: return json.JSONEncoder.default(self,obj) # 其他数据类型按照默认的序列化方式处理即可 使用cls指定序列化方式，即可轻松解决特殊格式没有办法被json序列化的问题 1234content = models.Article.objects.get(id=id_).datedata = json.dumps(content,ensure_ascii=False,cls=JsonEncoder)# 通过json.dumps的cls参数指明所使用的自定义序列化类return HttpResponse(data) 对应前端接收展示 12var data = JSON.parse(result) // 普通json传输方式$('.content').html(data) 如果返回的数据并不是一个单独的数据属性，那么也可以通过json进行处理，以一个数据列表的形式返回 123456content = models.Article.objects.filter(id=id_).values()# ----------------------------------------------# content = models.Article.objects.all().values()# ----------------------------------------------data = json.dumps(list(content),ensure_ascii=False,cls=JsonEncoder)return HttpResponse(data) 对应前端接收展示 12345678910111213141516171819&lt;div class=\"content\"&gt; &lt;!-- 这里用到的不是之前的p标签 而是一个div容器 --&gt;&lt;/div&gt;success: function (result) &#123; var data = JSON.parse(result)[0]['content'] $('.content').html(data.replace(/\\r\\n/g,\"&lt;br&gt;\"))&#125;// ---------------------------------------------// 如果需要展示的是所有的结果，可以通过js的for循环success: function (result) &#123; var data = JSON.parse(result) var tag = '' for (var i = 0, len = data.length; i &lt; len; i++) &#123; tag += '&lt;p&gt;' + data[i]['content'].replace(/\\r\\n/g, \"&lt;br&gt;\") + '&lt;/p&gt;' tag += '&lt;hr&gt;' &#125; $('.content').html(tag)&#125;// ---------------------------------------------- Vue-Axios 除去jQuery所提供的异步通信ajax方法 在Vue中也提供了ajax的异步通信方法，叫做Axios Axios会自动转换json数据 简单的来编写一个视图函数 get：返回当前页面 post：返回一条json数据 1234567891011121314151617181920212223window.onload = function () &#123; new Vue(&#123; el: '#content', // Vue接管的区域 data: &#123; message: '这个是表单内容', &#125;, methods: &#123; getajax() &#123; axios.get('/get_ajax/', &#123; params: &#123; // 这部分为get方式进行传参时使用的 id: 123 &#125; &#125;) .then(function (response) &#123; console.log(response) // 打印输出get方式进行ajax请求时获取到的数据 &#125;) .catch(function (error) &#123; console.log(error) // 当get方式ajax请求报错时，会进入该函数 &#125;) &#125; &#125;, &#125;)&#125; 对应的HTML页面 12345&lt;body&gt; &lt;div id=\"content\"&gt; &lt;button @click='getajax'&gt;点我发送ajax的get请求&lt;/button&gt; &lt;/div&gt;&lt;/body&gt; 后台视图函数 1234if request.method == 'GET': message = request.GET.get('message') print(message) return render(request,'axios/index.html') 当使用的是post形式获取服务端数据时，首先要注意，axios默认的提交post 数据不是普通的form-data 12&gt; axios`的`post`使用的是`request payload`方式，参数格式是`application/json;charset=UTF-8&gt; 而我们之前的表单提交数据的类型都是application/x-www-form-urlencoded，所以直接再django后台通过request.POST.get是获取不到任何数据的 解决办法，需要我们在axios提交数据时，指明提交时的头部信息 1234567891011121314151617181920212223242526window.onload = function () &#123; new Vue(&#123; el: '#content', // Vue接管的区域 data: &#123; message: '这个是表单内容', &#125;, methods: &#123; getajax() &#123; axios(&#123; method: 'post', url: '/get_ajax/', data: &#123; message:this.message, name: '张三' &#125;, headers: &#123; 'Content-Type':'application/x-www-form-urlencoded', &#125;, &#125;).then((response) =&gt; &#123; console.log(response.data) this.message = response.data &#125;) &#125; &#125;, &#125;)&#125; 虽然通过添加头部信息，可以让axios发送的数据被django后台所接收到，但是此时的数据还是有问题的 获取到的POST提交的数据被django打包成了一个QueryDict中的key值，value为空数组 导致后台按照平时的解析方式是获取不到的 解决办法也很简单，把QueryDict单独处理为一个字典 12345if request.method == 'POST': data = eval(list(request.POST.keys())[0]) # 将获取到的数据转换为字典 message = data.get('message') data = json.dumps(message + '我被服务端后台修改过') return HttpResponse(data) 接下来，当用户点击按钮时，post提交表单数据，给到django后台，后台追加字符串并返回，返回的数据被then回调函数所接收到，重新赋值给绑定的表单变量中 第二种办法，在前端vue提交数据时， serializer序列化 serializer是由django所提供的一个专门用来处理django数据对象(django model)变为序列化数据的框架 并且Django的序列化不支持单个对象，比如像objects.get获取到的数据，或是Python中的 str等数据类型 该序列化框架所提供的功能类位于django.core.serializers 12345678#views.py from django.core import serializerscontent = models.Article.objects.filter(id=id_)data = serializers.serialize('json',content,ensure_ascii=False)return HttpResponse(data)var data = JSON.parse(result)[0]['fields']['content'] // 序列化传输方式$('.content').html(data.replace(/\\r\\n/g,\"&lt;br&gt;\"))console.log(data) 总结：通过管理器的get方法获取到的是一个独立的结果，并不是一个QuerySet数据对象，也不是一个普通Python数据类型；只能对数据其中的某条属性进行json格式的处理或是将其变为列表等序列数据类型之后再进行序列化处理 serializer反序列化 序列化：serializers.serialize 反序列化：serializers.deserialize 12345from django.core import serializerscontent = models.Article.objects.filter(id=id_) # QuerySetdata = serializers.serialize('json',content,ensure_ascii=False) # strcontent = serializers.deserialize(\"json\", data)return HttpResponse(data) Ajax跨域 浏览器有一个很重要的概念：同源策略(Same-Origin Policy) 所谓同源是指，域名，协议，端口相同 不同源的客户端脚本javascript、ActionScript在没明确授权的情况下，不能读写对方的资源 同源：请求资源的地址与请求的发起方都属于同一域名下 JSONP JSONP是JSON with padding（填充式JSON 或参数式 JSON）的简写 JSONP实现跨域请求的原理简单的说，就是动态创建标签，然后利用的src不受同源策略约束来跨域获取数据。 JSONP由两部分组成：回调函数和数据 回调函数是当响应到来时应该在页面中调用的函数；回调函数的名字一般是在请求中指定的，而数据就是传入回调函数中的参数 注意：JSONP方式解决AJAX跨域，必须使用get方式，并且该方式常在一些数据量级比较小的情况下，因为需要服务端后台构建回调函数带参数的字符串，像是下面这样 123456def index(request): name = request.GET.get('name') + '哈哈哈哈哈' callback = request.GET.get('callback') data = '%s(\"%s\")' % (callback,name) # 这里以前端生成的回调函数名作为函数名，待返回数据作为参数返回 return HttpResponse(data) 前端代码：点击按钮传送表单的值到后台，并由后台处理后追加内容返回，返回的结果展示再p标签处 12345&lt;input type='text' id='ajax_data'&gt;&lt;button&gt; 按钮&lt;/button&gt;&lt;p id=\"content\"&gt;&lt;/p&gt; Ajax代码，获取当前表单数据，并使用get方式传递到服务端 12345678910111213141516$(document).ready(function () &#123; $(\"button\").click(function () &#123; $.ajax(&#123; url: 'http://127.0.0.1:8000/axios/', // 请求地址，对应Django某个路由映射 type: 'get', // 请求方式 post dataType: \"jsonp\", // 指定服务端返回的数据为jsonp格式 data: &#123; 'name': $('#ajax_data').val(), &#125;, success: function (result) &#123; console.log(result) $('#content').html(result) &#125; &#125;) &#125;)&#125;) ajax发起请求，并指定服务端返回数据类型为jsonp格式 服务端构建函数包含参数的字符串，为jsonp请求发起时，给定的回调参数名，参数为要返回的数据 客户端先会调用回调函数，然后会调用 1success 回调函数可以接收处理服务端返回的数据 success回调函数是成功返回数据后必定会调用的函数 CORS 跨域资源共享CORS(Cross-Origin Resource Sharing)是一种机制，它使用额外的HTTP头来告诉浏览器，让运行在一个 origin (domain) 上的Web应用被准许访问来自不同源服务器上的指定的资源 当一个资源从与该资源本身所在的服务器不同的域、协议或端口请求一个资源时，资源会发起一个跨域 HTTP 请求 注意：不一定是浏览器限制了发起跨站请求，也可能是跨站请求可以正常发起，但是返回结果被浏览器拦截了 实现CORS通信的关键是服务器。只要服务器实现了CORS接口，就可以跨源通信 这里需要我们将后端视图函数在接收到请求时，返回结果指明头部信息 123456789101112class Cors(View): def post(self,request): #判断是否为ajax请求 name = request.POST.get('name') response = HttpResponse(json.dumps('OK')) response[\"Access-Control-Allow-Origin\"] = \"http://127.0.0.1:5500\" # 允许可以跨域请求的站点 response[\"Access-Control-Allow-Methods\"] = \"POST, GET, OPTIONS\" # 允许可以跨域访问的请求方式 response[\"Access-Control-Allow-Headers\"] = \"*\" # 允许可以跨域请求时的头部字段 return response 前端页面的ajax代码正常提交数据即可 123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;title&gt;Page Title&lt;/title&gt; &lt;script type=\"text/javascript\" src=\"js/jquery-1.10.2.min.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;input type=\"text\" id='name'&gt; &lt;button id='button'&gt;提交&lt;/button&gt;&lt;/body&gt;&lt;script&gt; $('#button').click(function ()&#123; $.ajax(&#123; url: 'http://127.0.0.1:8000/', type: 'post', data: &#123; name: $('#name').val() &#125;, success: function(result)&#123; console.log(result) &#125; &#125;) &#125;)&lt;/script&gt;&lt;/html&gt; django-cors-headers 除了以上手动构建返回结果的头部信息用来解决跨域问题 在django中还可以通过一个先成可以自动添加CORS-Header的中间件，只需要在settings.py中做一些简单的配置即可 要想使用该中间件需要安装django的三方插件 1pip install django-cors-headers 安装完成之后，在django的settings文件中加载app 123456# settings.pyINSTALLED_APPS = [ ... 'django.contrib.staticfiles', 'corsheaders',] 接下来在中间件配置部分加载该插件所提供的中间件 1234567891011# settings.pyMIDDLEWARE = [ 'django.middleware.security.SecurityMiddleware', 'django.contrib.sessions.middleware.SessionMiddleware', 'corsheaders.middleware.CorsMiddleware', # 顺序需要在common组件之前 'django.middleware.common.CommonMiddleware', #'django.middleware.csrf.CsrfViewMiddleware', 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware', 'django.middleware.clickjacking.XFrameOptionsMiddleware',] 继续配置允许跨站请求的白名单设置等属性 12345678910111213# settings.pyCORS_ORIGIN_ALLOW_ALL = False # 是否允许其他所有站点发起跨站请求CORS_ORIGIN_WHITELIST = ( 'http://127.0.0.1:5500',) # 跨站请求白名单CORS_ALLOW_METHODS = ( 'POST',) # 允许跨站访问的请求方式CORS_ALLOW_HEADERS = ( '*',) # 允许跨站请求头中的字段类型 注：其中某些设置的默认值为如下所示 1234567891011121314151617181920default_headers = ( 'accept', 'accept-encoding', 'authorization', 'content-type', 'dnt', 'origin', 'user-agent', 'x-csrftoken', 'x-requested-with',)default_methods = ( 'DELETE', 'GET', 'OPTIONS', 'PATCH', 'POST', 'PUT',)","categories":[],"tags":[{"name":"Django","slug":"Django","permalink":"http://laxe.top/tags/Django/"}]},{"title":"Django邮件发送及华丽呼哨的邮件格式","slug":"Django邮件发送及华丽呼哨的邮件格式","date":"2019-10-21T02:05:03.231Z","updated":"2019-10-21T02:05:55.339Z","comments":true,"path":"2019/10/21/Django邮件发送及华丽呼哨的邮件格式/","link":"","permalink":"http://laxe.top/2019/10/21/Django邮件发送及华丽呼哨的邮件格式/","excerpt":"发送邮件 django中内置了许多方法可以使开发者方便的进行邮件发送 邮件配置 发送邮件，首先需要在项目的settings.py文件下配置邮件服务器连接等信息 123456EMAIL_USE_SSL = 真 ＃安全套接字层安全套接层，取决于邮件服务器是否开启加密协议 EMAIL_HOST = 'smtp.qq.com' ＃邮件服务器地址 EMAIL_PORT = 465 ＃邮件服务器端口 EMAIL_HOST_USER = 'account@qq.com' ＃登陆邮件服务器的账号EMAIL_HOST_PASSWORD = '密码' ＃登陆邮件服务器的密码 DEFAULT_FROM_EMAIL = EMAIL_HOST_USER ＃邮件的发送者","text":"发送邮件 django中内置了许多方法可以使开发者方便的进行邮件发送 邮件配置 发送邮件，首先需要在项目的settings.py文件下配置邮件服务器连接等信息 123456EMAIL_USE_SSL = 真 ＃安全套接字层安全套接层，取决于邮件服务器是否开启加密协议 EMAIL_HOST = 'smtp.qq.com' ＃邮件服务器地址 EMAIL_PORT = 465 ＃邮件服务器端口 EMAIL_HOST_USER = 'account@qq.com' ＃登陆邮件服务器的账号EMAIL_HOST_PASSWORD = '密码' ＃登陆邮件服务器的密码 DEFAULT_FROM_EMAIL = EMAIL_HOST_USER ＃邮件的发送者 注意：EMAIL_HOST_PASSWORD所设置的登陆邮件服务器的密码为邮件客户端后台所设置的第三方客户端登陆密码，这个值并非直接账号密码 如：QQ邮箱的该值密码在网页版QQ邮件客户端的设置-&gt;帐户-&gt;开启POP3/SMTP服务|IMAP/SMTP服务 发送文本邮件 发送普通邮件可以使用django.core.mail模块下的send_mail函数进行 send_mail(subject, message, from_email, recipient_list, fail_silently=False, html_message=None) 将邮件发送至recipient_list中的每一个收件人处 subject：发送邮件标题 message：发送邮件正文 from_email：发件人邮箱地址 recipient_list：一个字符串列表，每一个数据为接收者的邮箱地址 html_message：如果指定该值，则发送的内容类型为text/html为一个html邮件内容 发送普通邮件视图函数 12345678910从 django.core.mail 导入 send_mail def send_email （请求）： subject = '邮件测试' message = '&lt;a href=\"http://www.python.org\"&gt;学习Python，我很快乐&lt;/a&gt;' send_mail（ 主题=主题， 消息=消息， from_email ='from@qq.com'， 收件人列表= [ 'recv@qq.com'，'recv1@qq.com' ] ）return HttpResponse（'Down'） 发送HTML邮件 发送这里的邮件内容为一个HTML的a标签，但是真正接收者接到该邮件时，a标签并不会解释称为真正的a标签，只是一个普通的字符串，这是因为当前发送邮件的类型为text/plain，可以使用html_message参数进行HTML内容的发送 1234567891011从 django.core.mail 导入 send_mail def send_email （请求）： subject = '邮件测试' message = '&lt;a href=\"http://www.python.org\"&gt;学习Python，我很快乐&lt;/a&gt;' send_mail（ subject = subject， message = ''，＃该参数为必须参数，必须填写 html_message =消息， from_email ='from@qq.com'， 收件人列表= [ 'recv@qq.com'，'recv1 @ qq。 com' ] ）返回 HttpResponse（'Down'） 发送html格式邮件还可以使用django.core.mail模块下的EmailMultiAlternatives类进行邮件体的构造，然后进行邮件发送 EmailMultiAlternatives(subject=&#39;&#39;, body=&#39;&#39;, from_email=None, to=None) subject：邮件标题 body：邮件内容 from_email：邮件发送者 to：邮件接收人列表 EmailMultiAlternatives.attach_alternative(content, mimetype) 向EmailMultiAlternatives实例中添加mimetype支持的邮件内容 content：添加的邮件内容 mimetype：添加内容的mime类型 EmailMultiAlternatives.send() 发送邮件 12345678910111213从 django.core.mail 导入 EmailMultiAlternatives def send_email （请求）： subject = '邮件测试' text_message = '学习Python，我很快乐' html_message = '&lt;a href=\"http://www.python.org\"&gt;学习Python，我很快乐&lt;/a&gt;' email = EmailMultiAlternatives（ subject = subject， body = text_message， from_email ='1747266529@qq.com'，收件人 = [ 'recv@qq.com'，'recv1@qq.com' ] ） email.attach_alternative（html_message，'text / html'）＃添加HTML邮件部分 email.send（）＃发送邮件返回 HttpResponse（'Down'） 发送富文本邮件 经常需要我们在邮件中加入图片等静态资源 需要用到python中email.mime.image模块下的MIMEImage类进行图片内容的构造 这里发送邮件使用EmailMessage类，来自于django.core.mail模块下 并在使用对应该类实例的attach添加图片资源数据 最后使用实例的send函数发送邮件 EmailMessage(subject=&#39;&#39;, body=&#39;&#39;, from_email=None, to=None) ``subject`：邮件标题 body：邮件内容 from_email：邮件发送者 to：邮件接收人列表 123456789101112131415161718192021222324252627282930313233从 sendmailpro.settings 导入 STATICFILES_DIRS 进口 OS 从 email.mime.image 进口 MIMEImage 从 django.core.mail 进口 EmailMessage DEF SEND_EMAIL （请求）： 受试者= '图片邮件测试' file_1 = os.path.join（STATICFILES_DIRS [ 0 ]，'img / 1.png'）以 open（file_1，'rb'）作为 fp：＃：第一张图片 image_1 = MIMEImage（fp.read（）） file_2 = os.path.join（STATICFILES_DIRS [ 0 ]，' img / 2.png' ），以 open（file_2，'rb'）as fp：＃：第二张图片 image_2 = MIMEImage（fp.read（）） body = “ &lt;img src ='cid：first_id'&gt; &lt;br&gt; &lt;img src =' cid：sec_id'&gt;“ ＃发送邮件主体内容 image_1.add_header（'Content-ID'，'&lt;％s&gt;'％'first_id'）＃通过CID对称图片在邮件内容中的位置 image_2.add_header（'Content- ID'，'&lt;％s&gt;'％'sec_id'） message = EmailMessage（＃构建发送的邮件主体 subject = subject， body = body， from_email ='from@qq.com' ， to = [ 'recv@qq.com'，'recv1@qq.com' ] ） message.content_subtype = ' html'message.attach（image_1）＃添加两张图片的 message.attach（image_2） message.send（）＃发送邮件返回 HttpResponse（'Down'） 发送附件邮件 发送附件，也可以使用django.core.mail模块下的EmailMessage类进行附件邮件体构造 通过EmailMessage实例的attach|attach_file两个函数在邮件主体中添加附件内容 attach_file添加邮件附件直接加入路径即可，但是attach添加附件内容需要提供附件内容 attach(filename=None, content=None, mimetype=None) 添加附件内容 filename：附件文件名称 content：附件内容 mimetype：附件的MIME类型 attach_file(path, mimetype=None) 直接通过路径添加附件 path：附件路径 mimetype：附件的MIME类型 1234567891011121314151617181920从 sendmailpro.settings 导入 STATICFILES_DIRS 进口 OS 从 email.mime.image 进口 MIMEImage 从 django.core.mail 进口 EmailMessage DEF SEND_EMAIL （请求）： 受试者= '附件邮件测试' 电子邮件= EmailMessage（ 受试者=受试者 身体= “这是一篇具有图片附件的邮件”， from_email = 'from@qq.com'， to = [ 'recv@qq.com'，'recv1@qq.com' ] ） file_1 = os.path.join（STATICFILES_DIRS [ 0]，'img / 1.png'） image_1 =打开（file_1，'rb'）.read（） email.attach（'1.png'，image_1，'image / png'）＃使用attach实例函数添加附件内容 file_2 = os.path.join（STATICFILES_DIRS [ 0 ]，'img / 2.png '）email.attach_file（file_2，mimetype = 'image / png'）＃使用attach_file实例函数添加附件路径 email.send（）返回 HttpResponse（'Down'）","categories":[],"tags":[{"name":"Django","slug":"Django","permalink":"http://laxe.top/tags/Django/"}]},{"title":"HayStack全文检索在Django中应用","slug":"HayStack全文检索在Django中应用","date":"2019-10-21T02:03:30.461Z","updated":"2019-10-21T02:04:17.438Z","comments":true,"path":"2019/10/21/HayStack全文检索在Django中应用/","link":"","permalink":"http://laxe.top/2019/10/21/HayStack全文检索在Django中应用/","excerpt":"全文检索官方文档 全文检索就是针对所有内容进行动态匹配搜索的概念 针对特定的关键词进行建立索引并精确匹配取出搜索结果，并且达到性能优化的目的 为啥要有全文检索 最常见的全文检索就是我们在数据库中进行的模糊查询 但是模糊查询是针对整体内容的一个动态匹配过程，在数据量较大的情况下匹配效率极低 常规项目中数据量一般都比较多并且内容繁杂，所以正常的项目搜索功能中很少会使用模糊查询进行操作 如果你开发的项目用户量较少并且项目数据较少，那么此时模糊查询可以是你值得考虑的选项","text":"全文检索官方文档 全文检索就是针对所有内容进行动态匹配搜索的概念 针对特定的关键词进行建立索引并精确匹配取出搜索结果，并且达到性能优化的目的 为啥要有全文检索 最常见的全文检索就是我们在数据库中进行的模糊查询 但是模糊查询是针对整体内容的一个动态匹配过程，在数据量较大的情况下匹配效率极低 常规项目中数据量一般都比较多并且内容繁杂，所以正常的项目搜索功能中很少会使用模糊查询进行操作 如果你开发的项目用户量较少并且项目数据较少，那么此时模糊查询可以是你值得考虑的选项 django使用啥进行全文检索 Python提供了各种模块进行全文检索，最常见的是haystack模块 该模块设计为支持whoosh、solr、Xapian、Elasticsearch四种全文检索引擎后端 使用haystack模块，不用更改代码，直接切换引擎，可以极大的减少代码量 haystack属于一种全文检索的框架 whoosh 纯Python编写的全文搜索引擎，是目前最快的python所编写的检索引擎，虽然性能比不上solr、Xapian、Elasticsearch等；但是无二进制包，程序不会莫名其妙的崩溃，对于小型的站点，whoosh已经足够使用 solr Solr是一个高性能，采用Java5开发，基于Lucene的全文搜索服务器。同时对其进行了扩展，提供了比Lucene更为丰富的查询语言，同时实现了可配置、可扩展并对查询性能进行了优化，并且提供了一个完善的功能管理界面，是一款非常优秀的全文搜索引擎 Lucene：不是一个完整的全文检索引擎，是一个全文检索引擎的架构，提供了完整的查询引擎和索引引擎，Lucene的目的是为软件开发人员提供一个简单易用的工具包，以方便的在目标系统中实现全文检索的功能 Xapian 12&gt; Xapian`是一个用`C++`编写的全文检索程序，他的作用类似于`Java`的`lucene&gt; Elasticsearch ElasticSearch是一个基于Lucene的搜索服务器它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口 Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。该引擎常设计用于云计算中；能够达到实时搜索，稳定，可靠，快速，安装使用方便 中文分词 whoosh作为一个全文搜索引擎模块 分词功能和检索功能已经非常强大，但是针对中文的处理还是比较欠缺 可以通过Jieba模块重写分词操作，支持whoosh对中文的强大操作 安装中文分词模块 1pip install jieba 除了jieba分词，现在还有很多付费的中文分词模块 中科院计算所NLPIR ansj分词器 哈工大的LTP 清华大学THULAC 斯坦福分词器 Hanlp分词器 结巴分词 KCWS分词器(字嵌入+Bi-LSTM+CRF) ZPar IKAnalyzer 安装 首先安装HayStack框架以及whoosh搜索引擎 12pip install django-haystackpip install whoosh settings配置 添加haystack应用到项目的settings文件下的app部分 12345INSTALLED_APPS = [ 'django.contrib.admin', ... 'haystack',] 添加搜索引擎，这里使用whoosh引擎 123456789HAYSTACK_CONNECTIONS = &#123; 'default': &#123; 'ENGINE': 'haystack.backends.whoosh_cn_backend.WhooshEngine', 'PATH': os.path.join(BASE_DIR, 'whoosh_index'), &#125;&#125;#这里使用django的信号机制，在数据表发生改动时自动更新whoosh的查询索引HAYSTACK_SIGNAL_PROCESSOR = 'haystack.signals.RealtimeSignalProcessor' 这里要注意的是，我们使用的引擎为whoosh_cn_backend 本身的whoosh引擎名为：whoosh_backend whoosh_cn_backend将在接下来我们对安装目录下的引擎文件复制修改得来 在项目的路由文件下配置查询的路由映射 12345from django.urls import include,re_pathurlpatterns = [ path('admin/', admin.site.urls), re_path('^search/',include('haystack.urls')),] 当查询条件被提交时，会跳转至search路由 并且查询条件会作为get请求时的连接参数传入，参数key值为q 创建索引文件 接下来，在需要被搜索的app下建立search_indexes.py文件，该文件名不许变更 1234567891011121314151617181920212223#app.models.pyclass User(models.Model): # 用户表 name = models.CharField( max_length=50, verbose_name='昵称' ) account = models.CharField(max_length=50,verbose_name='账号',unique=True) passwd = models.CharField(max_length=50,verbose_name='密码') def __str__(self): return self.name#app.search_indexes.pyfrom haystack import indexesfrom . import modelsclass UserIndex(indexes.SearchIndex, indexes.Indexable): text = indexes.CharField(document=True, use_template=True) def get_model(self): return models.User # 当前模型文件下需要被检索的模型类 def index_queryset(self, using=None): return self.get_model().objects.all() 该类为索引类，类名为模型类的名称+Index：比如模型类为People,则这里类名为PeopleIndex get_model函数用来获取当前索引类所关联的模型类，这里我们关联上面的User 类对象 text=indexes.CharField语句指定了将模型类中的哪些字段建立索引，而use_template=True说明后续我们将通过一个数据模板文件来指明需要检索的字段 12&gt; document=True&gt; 为什么要创建索引：索引就像是一本书的目录，可以为读者提供更快速的导航与查找 创建模板数据文件 创建数据模板文件 数据模板文件路径：templates/search/indexes/yourapp/note_text.txt 放在任何一个你的Django能搜索到的模板文件夹template下面均可，这个文件主要确定要检索的字段，为他们建立索引 文件名必须为要索引的类名_text.txt，比如这里我们检索的类名是User，那么对应的数据模板文件名为user_text.txt，文件名小写即可 1234#template.search.indexes.people.user_text.txt&#123;&#123; object.name &#125;&#125;&#123;&#123; object.account &#125;&#125;&#123;&#123; object.online_time &#125;&#125; 在数据模板文件中使用模板语法，写入需要建立索引的字段，这里我们将模型类中name、account以及online_time字段设置索引，当检索时会对这三个字段去做全文检索 接下来创建一个搜索结果展示页面 检索结果模板页面 创建检索结果展示页面 检索结果展示页面，需要在固定的目录路径下进行模板页面的编写 路径为：templates/search/ 12345678910111213141516171819202122232425262728293031323334353637&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&#123;% if query %&#125; &lt;h3&gt;搜索结果如下：&lt;/h3&gt; &#123;% for result in page.object_list %&#125; &#123;&#123; result.object.name &#125;&#125; &lt;br&gt; &#123;&#123; result.object.account &#125;&#125; &lt;br&gt; &#123;&#123; result.object.online_time &#125;&#125; &lt;br&gt; &#123;% empty %&#125; &lt;p&gt;没找到&lt;/p&gt; &#123;% endfor %&#125; &#123;% if page.has_previous or page.has_next %&#125; &lt;div&gt; &#123;% if page.has_previous %&#125; &lt;a href=\"?q=&#123;&#123; query &#125;&#125;&amp;amp;page=&#123;&#123; page.previous_page_number &#125;&#125;\"&gt; 上一页 &lt;/a&gt; &#123;% endif %&#125; &#123;% if page.has_next %&#125; &lt;a href=\"?q=&#123;&#123; query &#125;&#125;&amp;amp;page=&#123;&#123; page.next_page_number &#125;&#125;\"&gt; 下一页 &lt;/a&gt; &#123;% endif %&#125; &lt;/div&gt; &#123;% endif %&#125;&#123;% endif %&#125;&lt;/body&gt;&lt;/html&gt; 这个模板页面中已经自带了分页功能，可以按照需求修改 创建检索模板页面内容 还需要有一个表单，提交检索信息 1234&lt;form method='get' action=\"/search/\" &gt; &lt;input type=\"text\" name=\"q\"&gt; &lt;input type=\"submit\" value=\"查询\"&gt;&lt;/form&gt; 这部分检索的模板页面内容可以在你的项目中进行添加，查询方式为get，并且检索输入的表单框name属性必须为q 中文分词配置 接下来，需要创建有关中文检索的配置文件，这里的配置文件创建为全局 进入到python的安装目录下，比如我的目录为：C:\\Python37\\Lib\\site-packages\\haystack\\backends 在该路径下创建名为ChineseAnalyzer.py的中文分词文件 1234567891011121314151617181920import jiebafrom whoosh.analysis import Tokenizer, Tokenclass ChineseTokenizer(Tokenizer): def __call__(self, value, positions=False, chars=False, keeporiginal=False, removestops=True,start_pos=0, start_char=0, mode='', **kwargs): t = Token(positions, chars, removestops=removestops, mode=mode, **kwargs) seglist = jieba.cut(value, cut_all=True) for w in seglist: t.original = t.text = w t.boost = 1.0 if positions: t.pos = start_pos + value.find(w) if chars: t.startchar = start_char + value.find(w) t.endchar = start_char + value.find(w) + len(w) yield tdef ChineseAnalyzer(): return ChineseTokenizer() 在这个文件中，定义了一个ChineseAnalyzer的函数，这个函数将替代搜索引擎配置文件中的分词方式 复制引擎文件，修改分词方式为中文 同样在该文件夹下C:\\Python37\\Lib\\site-packages\\haystack\\backends，复制whoosh_backend.py文件，创建一个新的文件名为whoosh_cn_backend.py，这里复制出一份文件也是为了之后如果不需要使用中文分词，可以直接在settings配置文件中修改引擎为&#39;ENGINE&#39;:&#39;haystack.backends.whoosh_backend.WhooshEngine&#39;, 修改该引擎配置文件中的：analyzer=StemmingAnalyzer()变为analyzer=ChineseAnalyzer() 并且要记得在头部引入刚才所编写的中文分词文件 12#whoosh_cn_backend.pyfrom .ChineseAnalyzer import ChineseAnalyzer 初始化索引 最后，初始化索引数据 1python manage.py rebuild_index","categories":[],"tags":[{"name":"Django","slug":"Django","permalink":"http://laxe.top/tags/Django/"}]},{"title":"Tinymce富文本编辑器","slug":"Tinymce富文本编辑器","date":"2019-10-21T02:02:17.921Z","updated":"2019-10-21T02:03:05.974Z","comments":true,"path":"2019/10/21/Tinymce富文本编辑器/","link":"","permalink":"http://laxe.top/2019/10/21/Tinymce富文本编辑器/","excerpt":"图文混排 在某些富文本编辑器中，我们可以支持文件与图片的同时编写，将文字与图片混合排列 在django中可以使用TimyMce富文本编辑器进行图文混排功能的实现 TinyMce TinyMCE：是一个轻量级的基于浏览器的所见即所得编辑器，支持目前流行的各种浏览器，由JavaScript写成 功能配置灵活简单，两行代码就可以将编辑器嵌入网页中，并且支持AJAX，加载速度非常快 最重要的是，TinyMCE是一个根据LGPL license发布的自由软件，你可以把它用于商业应用。下图是此编辑器的界面 配置上传路径 首先配置整个项目的上传文件路径，为了区别与自身的static静态目录 这里的上传文件我们将另外保存至upload文件夹 123&gt; #settings.py&gt; UPLOAD_ROOT = os.path.join(BASE_DIR,'upload')&gt;","text":"图文混排 在某些富文本编辑器中，我们可以支持文件与图片的同时编写，将文字与图片混合排列 在django中可以使用TimyMce富文本编辑器进行图文混排功能的实现 TinyMce TinyMCE：是一个轻量级的基于浏览器的所见即所得编辑器，支持目前流行的各种浏览器，由JavaScript写成 功能配置灵活简单，两行代码就可以将编辑器嵌入网页中，并且支持AJAX，加载速度非常快 最重要的是，TinyMCE是一个根据LGPL license发布的自由软件，你可以把它用于商业应用。下图是此编辑器的界面 配置上传路径 首先配置整个项目的上传文件路径，为了区别与自身的static静态目录 这里的上传文件我们将另外保存至upload文件夹 123&gt; #settings.py&gt; UPLOAD_ROOT = os.path.join(BASE_DIR,'upload')&gt; 配置模板页面 首先需要在使用到tinymce富文本编辑器的html页面下导入必备js文件 12345&gt; &lt;script src=\"&#123;% static 'js/jquery-1.10.2.min.js' %&#125;\" &gt;&lt;/script&gt;&gt; &lt;script src=\"&#123;% static 'js/tinymce_setup.js' %&#125;\"&gt;&lt;/script&gt;&gt; &gt; &lt;script src=\"&#123;% static 'tinymce/js/tinymce/tinymce.min.js' %&#125;\"&gt;&lt;/script&gt;&gt; 接下来，在模板页面中加入一个id为content的输入表单，这里我们以一个文章数据为例 首先是模型层文件定义 123456&gt; #models.py &gt; class Article(models.Model):&gt; title = models.CharField(max_length=100,verbose_name='标题')&gt; author = models.CharField(max_length=100,verbose_name='作者')&gt; content = models.TextField(verbose_name='内容')&gt; 这里的content内容要用到富文本编辑器 接着是模板页面的主要部分 1234567891011&gt; &lt;form method=\"POST\" action='/' enctype=\"multipart/form-data\"&gt;&gt; &#123;% csrf_token %&#125;&gt; &lt;input type=\"text\" placeholder=\"文章标题\"&gt;&gt; &lt;br&gt;&gt; &lt;input type=\"text\" placeholder=\"文章作者\"&gt;&gt; &lt;br&gt;&gt; &lt;input id=\"rich_content\" name=\"content\" value=\" \"&gt;&gt; &lt;br&gt;&gt; &lt;button type=\"submit\"&gt;提交&lt;/button&gt;&gt; &lt;/form&gt;&gt; 修改插件配置 这里搭配了一个tinymce_setup.js文件，用来控制富文本编辑器所使用的插件等 全文配置如下 12345678910111213141516171819202122232425262728293031323334353637&gt; tinymce.init(&#123;&gt; // 选择id为content的标签作为编辑器&gt; selector: '#rich_content',&gt; // 方向从左到右&gt; directionality:'ltr',&gt; // 语言选择中文&gt; language:'zh_CN',&gt; // 高度为400 宽度为一半&gt; height:300,&gt; width: '50%',&gt; // 工具栏上面的补丁按钮&gt; plugins: [&gt; 'advlist autolink link image lists charmap print preview hr anchor pagebreak spellchecker',&gt; 'searchreplace wordcount visualblocks visualchars code fullscreen insertdatetime media nonbreaking',&gt; 'save table contextmenu directionality template paste textcolor',&gt; 'codesample imageupload',&gt; ],&gt; // 工具栏的补丁按钮&gt; toolbar: 'insertfile undo redo | \\&gt; styleselect | \\&gt; bold italic | \\&gt; alignleft aligncenter alignright alignjustify | \\&gt; bullist numlist outdent indent | \\&gt; link image | \\&gt; print preview media fullpage | \\&gt; forecolor backcolor emoticons |\\&gt; codesample fontsizeselect fullscreen |\\&gt; imageupload',&gt; // 字体大小&gt; fontsize_formats: '10pt 12pt 14pt 18pt 24pt 36pt',&gt; // 按tab不换行&gt; nonbreaking_force_tab: true,&gt; imageupload_url: \"/upload_img/\",&gt; // 上传后图片保存为绝对路径&gt; relative_urls : false,&gt; &#125;);&gt; 注释已经很清晰 要注意的是imageupload_url配置用来确定当前图片上传所对应的视图路由 上传视图配置 接下来编写富文本编辑器的上传图片路由函数及对应的路由配置 路由映射tinymce_setup.js与中的imageupload_url配置路由相同 这里还要注意，由于此时tinymce的上传图片表单并不是和本身所容纳的form表单一起上传，所以并不会具备csrf_token值，需要我们将上传图片的函数额外进行装饰器装饰，取消csrf_token验证 123456789101112131415161718192021222324&gt; #views.py&gt; from django.views.decorators.csrf import csrf_exempt&gt; def md5(str_):&gt; import time&gt; m = hashlib.md5()&gt; m.update(str(time.time()).encode())&gt; filename = m.hexdigest()&gt; return filename + '.' + str_.split('.')[-1]&gt; &gt; @csrf_exempt&gt; def upload_img(request):&gt; if request.method == 'POST':&gt; img = request.FILES.get('file')&gt; if img:&gt; file_name_md5 = md5(img.name)&gt; with open(os.path.join(UPLOAD_ROOT,file_name_md5), 'wb') as fp:&gt; for buf in img.chunks():&gt; fp.write(buf)&gt; # 迭代读取文件并写入到本地&gt; response = &#123;&#125;&gt; response['path'] = '/upload/' + file_name_md5&gt; response['error'] = False&gt; return HttpResponse(json.dumps(response))&gt; 视图函数还是老样子去接收上传文件并保存即可 这里还使用了md5的方式进行文件名保存，避免重名文件上传互相覆盖 路由配置 123&gt; #urls.py&gt; path('upload_img/',views.upload_img),&gt; 表单接收视图 以上的视图函数只能处理上传图片的内容接收 我们的模板页面中还有作者及标题两样表单内容会被POST提交到后台 并且要主要的是，富文本编辑器里除了图片的内容，还有文字等其他内容，这里也需要我们保存下来 这里还需要一个视图函数去接管处理 1234567891011121314&gt; def index(request):&gt; if request.method == 'GET':&gt; return render(request, 'index.html')&gt; if request.method == 'POST':&gt; title = request.POST.get('title')&gt; author = request.POST.get('author')&gt; content = request.POST.get('content')&gt; models.Article.objects.create(&gt; title = title,&gt; author = author,&gt; content = content,&gt; )&gt; return redirect('/show/')&gt; 表单路由 123&gt; #urls.py&gt; path('',views.index),&gt; 这里上传之后，保存在后台的content数据是这个样子 12&gt; &lt;p&gt;&lt;img src=\"/upload/ec8f8c9a56ed32464a6727741fd58d8d.png\" /&gt;&lt;/p&gt;&lt;p&gt;今天&lt;em&gt;一切&lt;/em&gt;都是&lt;strong&gt;美丽&lt;/strong&gt;的，哈哈哈&lt;/p&gt;&gt; 图片访问路由 当有了上传图片的视图函数及所有内容的接收视图函数 这里还有一个特殊的问题，现在如果在富文本编辑器中选择上传图片，你会发现图片已经在选择时就已经存储到了后台upload文件夹下，这也是为什么我们的图片上传视图函数要单独编写，并且还需要取消csrf_token的验证的原因 除了这个问题你还会发现，在富文本编辑器中，上传的图片是看不到的，是一个坏掉的图片； 使用F12开发者工具你可以看到，这里的图片展示为一个img标签，而标签的src属性内容正是通过上传视图函数返回的response中的path值 想让这个path值在访问时，能获取到实际的图片效果，需要我们在路由文件中继续配置，配置专门的upload/xxxx.jpg的图片路由访问，让图片真正展示出来 1234&gt; #urls.py&gt; from django.views.static import serve&gt; re_path('^upload/(?P&lt;path&gt;.*)/$',serve,&#123;'document_root':UPLOAD_ROOT&#125;),&gt; 上传后图片的访问路径是/upload/，那么这里的路由也是upload/，之后通过静态文件映射函数serve查找upload文件夹下的同路径同名图片资源 当有了这条路由配置之后，再次再富文本编辑器中加入图片，你就会发现图片出现啦 上传并展示 最后，我们将测试上传图片及文字 并且上传成功之后，重定向到show视图函数 这个视图函数用来提取当前最新的上传数据并返回到模板页面 123456&gt; #views.py&gt; def show(request):&gt; if request.method == 'GET':&gt; article = models.Article.objects.all().last()&gt; return render(request,'show.html',locals())&gt; 展示的模板页面 12345678910111213141516&gt; &lt;!DOCTYPE html&gt;&gt; &lt;html&gt;&gt; &lt;head&gt;&gt; &lt;meta charset=\"utf-8\"&gt;&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt;&gt; &lt;title&gt;展示文章&lt;/title&gt;&gt; &lt;/head&gt;&gt; &lt;body&gt;&gt; &#123;% if article %&#125;&gt; &lt;h3&gt;&#123;&#123; article.title &#125;&#125;&lt;/h3&gt;&gt; &lt;h4&gt;&#123;&#123; article.author &#125;&#125;&lt;/h4&gt;&gt; &lt;div&gt;&#123;&#123; article.content|safe &#125;&#125;&lt;/div&gt;&gt; &#123;% endif %&#125;&gt; &lt;/body&gt;&gt; &lt;/html&gt;&gt; 其实本身富文本编辑器上传的文本内容就已经在一个p标签中，所以这里没有用段落标签 另外由于保存在数据库的文本为html格式，而后台传递来的模板变量django出于安全考虑会自动进行转义，直接观看到的效果不会html样式，只是一些普通字符串； 这里可以使用safe过滤器将内容认定为安全，展示为原始的html效果，其实还不错 总结 富文本编辑器其实就是将用户输入的内容变为html代码 这里的图文混排，只是在图片加入时，单独将图片上传保存，并且回调获取到上传的路径 之后只需要服务端后台配置好相关的上传图片访问路由配置即可","categories":[],"tags":[{"name":"Django","slug":"Django","permalink":"http://laxe.top/tags/Django/"}]},{"title":"Django缓存系统","slug":"Django缓存系统","date":"2019-10-21T01:58:40.498Z","updated":"2019-10-21T01:59:26.327Z","comments":true,"path":"2019/10/21/Django缓存系统/","link":"","permalink":"http://laxe.top/2019/10/21/Django缓存系统/","excerpt":"缓存 Django 是动态Web后台框架，需要实时生成用户访问的页面，进行多次的数据库操作，但是多次的数据库访问操作对于整个Web系统来说，会影响效率，尤其是当访问量增大时，数据库的压力也会越来越大。 相对于磁盘及内存操作，数据库的访问操作付出的成本要大的多","text":"缓存 Django 是动态Web后台框架，需要实时生成用户访问的页面，进行多次的数据库操作，但是多次的数据库访问操作对于整个Web系统来说，会影响效率，尤其是当访问量增大时，数据库的压力也会越来越大。 相对于磁盘及内存操作，数据库的访问操作付出的成本要大的多 浏览器第一次请求时，cache会缓存单个变量或整个网页等内容到硬盘或者内存中，同时设置response头部 当浏览器再次发起请求时，会与缓存中的过期时间相比较，如果缓存时间比较新，则会重新请求数据，并缓存起来然后返回response给客户端，如果缓存没有过期，则直接从缓存中提取数据，返回给response给客户端 Cache-Control 12&gt; HTTP`协议头`Cache-Control`，`Cache-Control`与`Expires`的作用一致，都是指明当前资源的有效期，控制浏览器是否直接从浏览器缓存取数据还是重新发请求到服务器取数据。只不过`Cache-Control`的选择更多，设置更细致，如果同时设置的话，其优先级高于`Expires&gt; 在python中使用memcached需要我们额外安装memcached作为memcache客户端的支持 1pip3 install python-memcached -i https://pypi.tuna.tsinghua.edu.cn/simple Cache设置memcached 安装memcached 12apt-get install memcached # debianyum install memcached # centos 配置文件：/etc/memcached.conf 配置文件中有两个可能需要修改的参数 12-m 64 #memcached所能使用的内存大小-l 127.0.0.1 #监听的IP地址 开启|关闭memcached服务 12systemctl start memcached # 开启systemctl stop memcached # 关闭 查看服务状态 1systemctl status memcached settings配置 使用memcached缓存，首先需要在项目的settings文件下进行配置 12345678CACHES = &#123; 'default': &#123; 'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache', # 指定缓存使用的引擎 'LOCATION':'172.16.19.26:11211', # 指定缓存服务器地址，常为本机地址 &#125;&#125; 视图缓存 可以只为某些视图函数进行缓存 使用django.views.decorators.cache下的装饰器cache_page进行视图函数装饰即可 模型类的表代码 12class People(models.Model): name = models.CharField(max_length=20,verbose_name='名字') 视图函数代码 1234567from django.views.decorators.cache import cache_page@cache_page(10) # 缓存10秒def index(request): print('视图函数被调用') ss = models.People.objects.all() return render(request, 'index.html', locals()) 模板页面代码 12345678910111213&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;title&gt;展示数据&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &#123;% for s in ss %&#125; &lt;li&gt;&#123;&#123; s.name &#125;&#125; &lt;/li&gt; &#123;% endfor %&#125;&lt;/body&gt;&lt;/html&gt; 在第一次刷新浏览器之后， 立即在数据库中添加一个新的数据对象 接着继续刷新浏览器，前端页面将会读取缓存中的结果，而不会显示刚才添加的用户 除了在视图函数上使用装饰器进行缓存设置，还可以在路由匹配部分使用相同装饰器函数进行设置 全站缓存 将整站所有视图设置缓存，需要在配置文件的中间件设置首尾部分添加如下内容 12345678MIDDLEWARE = [ 'django.middleware.cache.UpdateCacheMiddleware', # 首部要添加的中间件 # 将response缓存起来 'django.middleware.security.SecurityMiddleware', ... 'django.middleware.cache.FetchFromCacheMiddleware',# 尾部要添加的中间件 # 将缓存的response取出来] 以及搭配设置当前全站缓存有效时间的全局变量 1CACHE_MIDDLEWARE_SECONDS = 10 # 每页页面缓存的秒数，默认为600 局部缓存 局部缓存主要为在模板页面，选择某个区域进行缓存，当用户再次访问相同页面时，如设置缓存未过期，则渲染时局部缓存不会重新生成 12345&#123;% load cache %&#125; 局部缓存首先需要加载cache标签 &#123;% cache sec key %&#125;&#123;% endcache %&#125; 以时间模板变量为例，做一个简单的测试，后台视图函数每次在访问时，返回当前时间 12import time now = time.strftime('%H:%M:%S', time.localtime()) 模板页面在使用时的代码 123456&#123;% load cache %&#125;&lt;p&gt;这里是未缓存的时间:&#123;&#123; now &#125;&#125;&lt;/p&gt;&#123;% cache 10 time %&#125;&lt;p&gt;这里是缓存的时间:&#123;&#123; now &#125;&#125;&lt;/p&gt;&#123;% endcache %&#125; 手动缓存 除了以上应用于各个业务中的缓存方式，还可以使用django所提供的cache接口进行缓存设置以及获取 设置缓存 1234from django.core.cache import cache#存储缓存数据cache.set('cache_key',data,60*15)#cache_key为存储在缓存中的唯一值，data为存储的数据，60*15为缓存有效时间 获取缓存 123#获取缓存数据cache.get('cache_key','获取不到的默认值')#cache_key为储存缓存数据的唯一值 避免key值重复导致更新缓存，可以使用cache.add函数，基本用法与set相同 123status = cache.add('add_key', 'New value')# 当指定key值的缓存存在，add方法不会尝试更新缓存# 返回值status为True时，代表存储成功，False代表存储失败 清除缓存，通过cache.delete方法，该方法接收一个缓存key值 1cache.delete('cache_key') 清空缓存，通过cache.clear方法，直接从缓存中清除所有 1cache.clear() 注意 memcached不允许使用超过250个字符或包含空格或控制字符的缓存键值 使用这样的键值将会导致异常","categories":[],"tags":[{"name":"Django","slug":"Django","permalink":"http://laxe.top/tags/Django/"}]},{"title":"Django中的Admin组件","slug":"Django中的Admin组件","date":"2019-10-21T01:54:12.526Z","updated":"2019-10-21T01:57:16.741Z","comments":true,"path":"2019/10/21/Django中的Admin组件/","link":"","permalink":"http://laxe.top/2019/10/21/Django中的Admin组件/","excerpt":"管理员 Django-admin界面是框架为我们提供的Web-APP的管理工具 在之前的练习中，我们已经多次使用它进行APP中表的DML语句操作 接下来，我们可以继续来学习，如何将Admin界面进行优化扩展，更加方便我们后台管理","text":"管理员 Django-admin界面是框架为我们提供的Web-APP的管理工具 在之前的练习中，我们已经多次使用它进行APP中表的DML语句操作 接下来，我们可以继续来学习，如何将Admin界面进行优化扩展，更加方便我们后台管理 管理员注册设置 在admin界面中，我们可以通过继承admin.ModelAdmin类进行自定义admin类的编写，用作控制展示后台所显示的数据，以及排序规则等等属性，基本语法像是下面这样 123456789＃models.py 类 用户（models.Model）： 名称= models.CharField（max_length = 20） age = models.IntegerField （）def __str__ （self）：返回 self.name ＃admin.py 类 UserAdmin （admin.ModelAdmin）： 字段=（'name'，'age'）＃控制管理界面模型类展示位置 admin.site.register（User，UserAdmin） 常用的 list_display：在admin控制台数据列表页面展示更多的细分 list_display_links：用于设置当前列表中由list_display所设置的附加部分可以点击 fieldsets：将admin界面下的表单输入栏进行分块 12345类 UserAdmin （admin.ModelAdmin） ： 字段=（ '姓名'， '年龄'） 字段集=（ （ '第一个区域'， &#123; '字段'：（ '姓名'） &#125; ） （ '第二个区域'， &#123; 'fields'：（ 'age'，） &#125; ） ） search_fields：在admin数据展示页，设置一个搜索框，设置的分段是可查找的属性 1search_fields =（'name'，） list_filter：以什么分解进行过滤，在admin页面上方展示 ordering：数据列表可以通过某些细分进行排序 利用现有用户系统 12&gt; from django.contrib.auth.models import User&gt; 用户细分 username 必选。少于等于30个字符。用户名可以包含字母，数字，_， ，@，。+状语从句：-字符 first_name 任选。等于等于30个字符 last_name 可选。可以输入30个字符 email 任选。邮箱地址 password 必选。密码的哈希及元数据。（Django不保存原始密码）。原始密码可以无限长而且可以包含任意字符 is_staff 布尔值。指示用户是否可以访问Admin站点 is_active 布尔值。用户的账号是否激活。长使用这个标志为False来代替删除账号 is_superuser 布尔值。指定这个用户拥有所有的权限而不需要给他们分配明确的权限 last_login 用户最后一次登录的时间。如果这个用户没有登录过，这个细分将会是null 之前版本默认设置为的当前的datetime date_joined 帐户创建的时间。当账号创建时，替代设置为当前的datetime 用户实例方法 get_username() 获取到当前的用户的用户名属性 is_authenticated() 检查用户是否已通过认证 is_anonymous() 检查用户是否未通过认证 set_password(password) 设置保存用户的密码，和会负责密码的哈希加密工作 通常修改密码之后还需要调用save()方法进行数据更新 用户表方法 create_user(username, email=None, password=None, **extra_fields) django的用户创建需要使用User表管理器中的create_user函数进行 该函数可以创建并保存一个用户 create_superuser(username, email, password, **extra_fields) 与上一个创建用户函数功能相同，但是额外会设置用户的is_staff及is_superuser属性为True 创建一个admin后台超级用户 其他方法 authenticate(username,password) 验证是否为合法用户，如果用户存在合法则返回一个用户对象 logout() 清除当前浏览器下用户session login(request,user) 登录并保存当前用户session 接受参数为HttpRequest请求及一个User用户对象 参数user必须为使用authenticate验证过后的用户对象 用户登录 登陆所需表单类 123456789101112131415＃forms.py 从 django的进口形式从 django.contrib.auth.models 导入用户进口重新类 LoginForm的（forms.Form） ： 用户名= forms.CharField（标记= “用户名”，需要= 真，） 密码=形式。 CharField（ widget = forms.PasswordInput（）， label = '密码'， required = True， ）def clean_username （self）： username = self.cleaned_data.get（“ username”）.strip（）try ： User.objects.get（用户名=用户名），但 User.DoesNotExist 除外：引发 Forms.ValidationError（“用户名％s不存在”％用户名）else：返回用户名 登录所需模板页面 12345678910111213141516171819202122232425&lt;！DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;登录&lt;/ title&gt; &lt;/ head&gt; &lt;body&gt; &lt;form action ='/ login /'method =“ POST”&gt; &#123;％csrf_token％&#125; &#123;&#123;错误&#125; &#125; &#123;％表示形式为％的字段&#125; &lt;label&gt; &#123;％表示field.errors％&#125; &lt;ul&gt; &#123;％表示error。％s错误&#125; &lt;li&gt; &#123;&#123;error&#125;&#125; &lt;/ li&gt; &#123;％endfor％&#125; &lt;/ ul&gt; &#123;％endif％&#125; &lt;/ label&gt; &lt;p&gt; &#123;&#123;field.label&#125;&#125;：&#123;&#123;field&#125;&#125; &lt;/ p&gt; &#123;％endfor％&#125; &lt;input type =“ submit” value =“登录” &gt; &lt;/ form&gt; &lt;/ body&gt; &lt;/ html&gt; 登陆主要视图逻辑 12345678910111213＃views.py 从 django.contrib.auth 进口身份验证，注销作为 auth_logout，登录作为 auth_login DEF 登录（请求）：如果 request.method == 'GET' ： 形式=用户窗体（）返回渲染（请求，“的login.html “，&#123; 'form'：form&#125;） form = userForm（request.POST） 用户名= form.data [ 'username' ] 密码= form.data [ 'password' ] user = authenticate（username = username，password = password）＃验证当前账号密码是否符合合法如果用户 和 user.is_active： auth_login（请求，用户）返回 redirect（'/'）else：返回 render（request，“ login.html”，&#123; 'form'：form，'errors'：'用户名或密码错误' &#125; ） 在用户登录成功之后，将会重新进入主页，主页展示当前登录用户 登录用户可以直接在request.user属性中获取到，主页的模板内容如下 主页模板 123&lt;！DOCTYPE html&gt; &lt; html &gt; &lt; head &gt; &lt; title &gt;主页&lt;/ title &gt; &lt;/ head &gt; &lt; body &gt; 欢迎你：&#123;&#123;user&#125;&#125; &lt;/ body &gt; &lt;/ html &gt; 主页视图函数可以通过装饰器@login_required或判断is_authenticated状态来查看用户是否登录 只有登录用户可以访问该站点 使用当装饰器@login_required时，在需要settings下设置LOGIN_URL = &#39;/login/&#39; 引入属性设置为登录路由 首页视图函数 123从 django.contrib.auth.decorators中导入 login_required ＃@ login_required def 索引（请求）：如果 request.user.is_authenticated（）：返回 render（请求，“ index.html”）否则：返回重定向（'/ login /'） 注册功能 注册所需表单 123456789101112131415161718192021222324＃forms.py 类 RegisterForm （forms.Form）： 用户名= form.CharField（label = “用户名”， max_length = 30， required = True， error_messages = &#123; 'max_length'：'账号长度最长为30' &#125;， ） password = form.CharField（label = “密码”， min_length = 6，max_length = 30， widget = forms.PasswordInput（）， required = True， error_messages = &#123; 'min_length'：'密码长度最短为6' &#125;， ） check_password = forms.CharField（label = “重复密码”， min_length = 6，max_length = 30， widget = forms.PasswordInput（）， required = True， error_messages = &#123; 'min_length'：'密码长度最短为6' &#125;， ）def clean_check_password （self）： 密码= self.cleaned_data.get（'password'） check_password = self.cleaned_data.get（'check_password'）如果 password！= check_password 和 password 和 check_password：提高 ValidationError（“重复输入密码错误”）def clean_username （self）： username = self.cleaned_data.get（'username'）if username [：1 ] == '_'：提出表格。ValidationError（“用户名不能以下划线打头“）尝试： User.objects.get（username = username）除外 User.DoesNotExist：返回用户名引发表单。ValidationError（”用户名已存在“） 表单中，将对用户两次输入的密码进行校验和判断是否为空，而且分开下划线作为用户名的开头字符 注册主要视图函数逻辑 1234567891011121314＃views.py def 寄存器（请求）：if request.method == 'POST'： form = RegisterForm（request.POST）if form.is_valid（）： username = form.cleaned_data [ 'username' ] 密码= form.cleaned_data [ 'password' ] User.objects.create_user（username = username，password = password） user = authenticate（username = username，password = password） auth_login（request，user）return redirect（'/'）else： form = RegisterForm（ ）返回 渲染（请求，“ register.html”，&#123; 'form'：form&#125;） 通过表单验证，并获取到对应的用户账号密码，创建成功之后，验证并登录，并重定向到首页 主页模板页面 12345678910111213141516171819202122232425262728&lt;！DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;注册&lt;/ title&gt; &lt;/ head&gt; &lt;body&gt; &#123;％如果request.user.is_authenticated％&#125; &lt;p&gt;您已登录：&lt;/ p&gt; &#123;&#123;用户&#125;&#125; &#123;％else％&#125; &lt;form action ='/ register /'method =“ POST”&gt; &#123;％csrf_token％&#125; &#123;％表示形式为％的字段&#125; &lt;label&gt; &#123;％if field.errors％&#125; &lt;ul&gt; &#123; ％for field.errors％&#125; &lt;li&gt; &#123;&#123;error&#125;&#125; &lt;/ li&gt; &#123;％endfor％&#125; &lt;/ ul&gt; &#123;％endif％&#125; &lt;/ label&gt; &lt;p&gt; &#123;&#123;field.label&#125;&#125;： &#123;&#123;field&#125;&#125; &lt;/ p&gt; &#123;％endfor％&#125; &lt;input type =“ submit”value =“注册”&gt; &lt;/ form&gt; &#123;％endif％&#125; &lt;/ body&gt; &lt;/ html&gt; 当用户已经登录时，显示当前登录用户，反之则展示表单，以供用户填写 重载admin用户系统 django自带的admin模块下的用户系统主要负责用户帐户，组，权限和基于cookie的会话等业务 认证系统由以下部分组成： 用户：包含用户数据细分，是实现业务功能逻辑的基础 权限：控制用户进入否可以执行某项任务的二进制（是/否）标志。 组：一种为多个用户加上标签和权限的常用方式。 消息：一种为指定用户生成简单消息嵌入的方式 默认预设 username 必选项，小于等于30个字符；只能是字母数字（字母，数字和下划线） first_name 可选项，等于等于30个字符 last_name 可选项，等于等于30个字符 email 可选项。电子邮件地址 password 必选，密码（哈希值，元数据） Django不储存原始密码 原始密码可以是任意长度的，包含任何字符 密码由哈希类型，盐值和哈希值组成，用美元符合分隔 is_staff 布尔值，指明这个用户是否可以进入管理站点的权限 is_active 布尔值，指明这个用户帐户是否是活动的 我们建议把这个标记设置为False来代替删除用户帐户，这样就不会影响指向用户的外键 这个属性不控制用户是否可以登录。登录验证时不会核查is_active标志。 因此，如果在登录时需要检查is_active标志，需要你在自己的登录视图中实现 用于login()视图的AuthenticationForm会执行这个检查，判断用户是否是活跃账户 is_superuser 布尔值，规范用户拥有所有权限（包括显式赋予和非显式赋予的） last_login 预期情况下设置为用户最后一次登录的日期时间 date_joined 预期情况下设置为用户帐户创建的日期时间 默认方法 在项目中，我们将使用电子邮件作为用户的用户名，那么可以在自带用户表中写明 12&gt; USERNAME_FIELD = 'email'&gt; 该属性设置当前表的登陆细分 描述我们自定义用户模型上作的唯一标识符分割名称的字符串，分段必须是唯一的，在定义中设置unique=True 12&gt; REQUIRED_FIELDS = ['username']&gt; 设置当前该基线为必填细分 is_authenticated() 判断用户是否已通过身份验证的方法，不意味任何权限，而且不检查用户的活动状态 get_username() 返回由USERNAME_FIELD制定的细分的值 get_full_name（） 返回first_name加上last_name 中间加上一个空格，由于我们重新设置了表分区，那么这个变量函数需要我们重新给定返回值 get_short_name() 一个短的且非正式用户的标识符，返回first_name 当你的项目重写该静态或直接去掉了first_name，所以我们必须重新给定这个函数的返回值 set_password() 将用户的密码设置为给定的字符串 has_perm(perm, obj=None) 用户是否具有某个权限，如果给定obj，则需要根据特定对象实例检查权限 has_module_perms(app_label) 如果用户有权访问给定应用中的模型，则返回True 这里我们这两个分区都设置为True，可以让用户访问任一APP is_staff()@property 如果用户允许访问管理网站，则返回True 这里我们返回is_admin的随机属性即可 关于细分属性，如果需要进行高度扩展 可以使用继承AbstractBaseUser这个类 这个类中只含有password， ，last_login以及is_active三个字段属性 重载管理器 由于已经覆盖了替代的admin用户表，现在需要将其对应的管理器函数进行编写 编写时主要关注一下两个父类函数的重写 1234567891011121314151617181920212223create_user（username_field，password_filed = None，** other_fields） normalize_email（）将邮件地址规范化的类方法 user.save（using = self._db）create_superuser（用户名，电子邮件，密码）＃用户创建，is_admin设置为真 user.save（using = self._db） 从 django.contrib.auth.models 导入 BaseUserManager 类 MyUserManager （BaseUserManager） ：高清create_user （个体经营，用户名，电子邮件，密码=无）：如果没有电子邮件：提高 ValueError异常（“用户必须拥有一个电子邮件地址”），如果没有用户名：引发 ValueError（'用户必须具有用户名'）＃判断邮件和用户名是否具有 now = timezone.now（）＃获取当前django的时间 user = self.model（ 用户名=用户名， email = self.normalize_email（email） ， date_joined = now， last_login = now， ） user.set_password（password） user.save（using = self._db）返回用户def create_superuser （self，username，email，password）： user = self.create_user（username， email， password = password， ） user.is_admin = True user.save（using = self._db）返回用户 重新定义新用户表的管理器之后，想要生效，还需要在对应的模型类表中覆盖objects属性 objects = MyUserManager() 重载表 下面是一个真实的重载自带用户表的模型类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172从 django.contrib.auth.models 导入 AbstractBaseUser 类 成员（AbstractBaseUser）：#AbstractBaseUser中只包含3个字段：password，last_login和is_active。 email = models.EmailField（verbose_name = '邮箱'，max_length = 255，unique = True，） 用户名= models.CharField（verbose_name = “用户名”，max_length = 16，unique = True） weibo_id = models.CharField（verbose_name = “新浪微博”，max_length = 30，空白= True） 博客= models.CharField（verbose_name = “个人网站” ，max_length = 200，blank = True） 位置=模型。CharField（verbose_name = “城市”，max_length = 10，blank = True） profile =模型。CharField（verbose_name = “个人简介”，max_length = 140，blank = True） 头像= models.CharField（verbose_name = “头像”，max_length = 128，blank = True） au = models.IntegerField（verbose_name = “用户活跃度”，默认= 0） last_ip = models.IPAddressField（verbose_name = “上次访问IP”，默认= “ 0.0.0。0“） email_verified = models.BooleanField（verbose_name = “邮箱是否验证”，默认= False） date_joined = models.DateTimeField（verbose_name = “用户注册时间”，default = timezone.now） topic_num = models.IntegerField（verbose_name = “帖子数”，默认= 0） comment_num = models.IntegerField（verbose_name = “评论数”，default = 0） is_active = models.BooleanField（default = True） is_admin = models.BooleanField（默认= False） objects = MyUserManager（）#objects就是我们之前一直使用的管理器＃管理器用来维护我们的增删改查 USERNAME_FIELD = '电子邮件' REQUIRED_FIELDS = [ '用户名' ] 高清 __str__ （个体经营）：返回 self.username＃标签中的数据实例高清is_email_verified （个体经营）：返回 self.email_verified＃我们可以在模板中，通过实例出来的对象数据进行这个函数的调取，获取他是否验证过def get_weibo （个体）：返回 self.weibo_id def get_username （self）：返回 self.username＃方法的圆括号在模板标签中必需省略！！def get_username （self）：返回 self.username＃方法的圆括号在模板标签中必需省略！！ def get_full_name （self）：＃用户通过其电子邮件地址return self进行标识。email # get_full_name本来是获取名字和姓氏的＃但由于我们重新设置了表结构，所以此函数必须自定义＃方法的圆括号在templates标签中必需省略！！ def get_short_name （self）：＃用户通过其电子邮件地址返回 self.username进行标识 def has_perm （self，perm，obj = None）：“用户是否具有特定权限？” 返回True def has_module_perms （自己，app_label）：“用户是否有权查看应用程序`app_label`？” 返回True DEF calculate_au （个体）：“”， “ 计算活跃度 公式的：主题* 5 +注释* 1 ”“” self.au = self.topic_num * 5 + self.comment_num * 1 返回 self.au @ property＃类中函数可以直接做为属性使用def is_staff （个体）：“用户是工作人员吗？” ＃最简单的答案：所有管理员都是员工返回 self.is_admin 重载Admin表单 由于修改了默认的django表结构，此时在admin界面修改密码或添加用户数据已经不能再按照之前的表单系统啦 需要在app的admin.py中重写UserCreationForm和UserChangeForm 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768＃用户创建表单从 Django的进口形式从 django.contrib中输入管理员从 django.contrib.auth.admin 进口 UserAdmin 从 django.contrib.auth.forms 导入 ReadOnlyPasswordHashField 从 people.models 导入会员，跟随class UserCreationForm （forms.ModelForm）：“”“用于创建新用户的表单。包括所有必填 字段以及重复的密码。”“” password1 = form.CharField（label = '密码'，widget = forms.PasswordInput） password2 = Forms.CharField（label = '确认密码'，widget = forms.PasswordInput）类Meta： model =成员 字段=（ 'email'， 'username'） def clean_password2 （self）： password1 = self.cleaned_data.get（ “ password1”） password2 = self.cleaned_data.get（ “ password2”）如果 password1和 password2和 password1！= password2：提出 form.ValidationError（ “输入确认失败“） return password2＃在窗体中的clean__field函数会在is_valid（）函数验证时自动调用def save （self，commit = True）： user = super（UserCreationForm，self）.save（commit = False） user.set_password （self.cleaned_data [ “ password1” ]）#set_password将采用django的加密算法将密码设置到对应的模型实例中＃在内存中创建的好的对象只能通过commit = True才被真正执行到数据库上如果提交： user.save（）return用户 ＃密码更改时的展示表单类 UserChangeForm （forms.ModelForm）： 密码= ReadOnlyPasswordHashField（）类Meta： 模型=成员 字段=（'email'，'password'，'username'，'is_active'，'is_admin'，）def clean_password （self）：返回 self.initial [ “ password” ] ＃使用替代的保存函数即可 ＃真正的用户管理界面管理方式类 MyUserAdmin （UserAdmin）： 形式= UserChangeForm add_form = UserCreationForm list_display =（'id'，'email'，'username'，'email_verified'，'last_login'，'is_active'，'is_admin'，'last_ip'） list_display_links =（'id'，'email'，'用户名'） list_filter =（'email'，'email_verified'，） 字段集=（ （无，&#123; 'fields'：（（'username'，'email'，'date_joined'，'password'，'is_active'，'is_admin'，'avatar'）&#125;）， （'状态'，&#123; 'fields'：（' email_verified'，'last_ip'，'au'，'topic_num'，'comment_num'）&#125;）， （'社交网络'，&#123; 'fields'：（'weibo_id'，'blog'）&#125;）， ） add_fieldsets =（ （无，&#123; 'classes'：（'wide'，），#admin样式设置#Fieldsets使用wide样式将会有额外的水平间距。'fields'：（（'email'，'username'，'password1'，'password2'，'is_active'，'is_admin'）&#125; ） ）） search_fields =（'id'，'email'，'username'） ordering = （'id'，'email'，'email_verified' admin.site.register（成员，MyUserAdmin）admin.site.register（跟随者） 最终 还需要在settings.py文件下进行设置，覆盖最小的User模型 AUTH_USER_MODEL = &#39;people.Member&#39;","categories":[],"tags":[{"name":"Django","slug":"Django","permalink":"http://laxe.top/tags/Django/"}]},{"title":"Websocket","slug":"Websocket","date":"2019-10-21T01:39:19.954Z","updated":"2019-10-21T01:57:26.918Z","comments":true,"path":"2019/10/21/Websocket/","link":"","permalink":"http://laxe.top/2019/10/21/Websocket/","excerpt":"Websocket WebSocket实现了浏览器与服务器的全双工通信，扩展了浏览器与服务端的通信功能，使服务端可以主动向客户端发送数据。 传统的HTTP协议是无状态的，种客户端是主动方，服务端是被动方的；对于涉及实时信息的Web应用带来了很大的不便，如带有即时通信、实时数据、订阅推送等功能的应用。在之前有两种办法解决这个问题","text":"Websocket WebSocket实现了浏览器与服务器的全双工通信，扩展了浏览器与服务端的通信功能，使服务端可以主动向客户端发送数据。 传统的HTTP协议是无状态的，种客户端是主动方，服务端是被动方的；对于涉及实时信息的Web应用带来了很大的不便，如带有即时通信、实时数据、订阅推送等功能的应用。在之前有两种办法解决这个问题 轮询是最原始的实现实时Web应用的解决方案。轮询技术要求客户端以设定的时间间隔周期性地向服务端发送请求，频繁地查询是否有新的数据改动。这种方法会导致过多不必要的请求，浪费流量和服务器资源。 Comet技术又可以分为长轮询和流技术；长轮询改进了上述的轮询技术，减小了无用的请求。它会为某些数据设定过期时间，当数据过期后才会向服务端发送请求；这种机制适合数据的改动不是特别频繁的情况。流技术通常是指客户端使用一个隐藏的窗口与服务端建立一个HTTP长连接，服务端会不断更新连接状态以保持HTTP长连接存活；这样的话，服务端就可以通过这条长连接主动将数据发送给客户端；流技术在大并发环境下，可能会考验到服务端的性能。 WebSocket真正实现了Web的实时通信，使B/S模式具备了C/S模式的实时通信能力 WebSocket的工作流程是这样的：浏览器通过JavaScript向服务端发出建立WebSocket连接的请求，在WebSocket连接建立成功后，客户端和服务端就可以通过 TCP连接传输数据。因为WebSocket连接本质上是TCP连接，不需要每次传输都带上重复的头部数据，所以它的数据传输量比轮询和Comet技术小了很多 Websocket在建立连接之前有一个Handshake（Opening Handshake）过程，在关闭连接前也有一个Handshake（Closing Handshake）过程，建立连接之后，双方即可双向通信 HTML的Websocket 初始化websocket 1var ws = new WebSocket(url, [protocol] ); 12&gt; url`：指定连接的`websocket&gt; protocol：可接受的子协议 响应事件 当ws套接字初始化成功之后，我们可以通过定义回调函数在某些事件触发时执行，以下是常见响应事件 当ws连接建立时触发 123ws.onopen = function()&#123; // 连接开启&#125; 当ws连接接收到数据时触发 123ws.onmessage = function(evt)&#123; // evt.data即是接收到的数据对象&#125; 当ws连接发生通信错误时触发 123ws.onerror = function()&#123; // 连接出错&#125; 当连接关闭时触发 123ws.onclose = function()&#123; // 连接关闭&#125; 初次之外，还可以通过一些方法函数进行数据的传输或连接的关闭 方法 通过ws连接发送数据 1ws.send(str) 关闭连接 1ws.close() 简单的示例12345678910111213141516171819var ws = new WebSocket('ws://127.0.0.1:3000')ws.onopen = function()&#123; console.log('连接建立')&#125;ws.onmessage = function(ev)&#123; console.log('server:',ev.data)&#125;ws.onerror = function()&#123; console.log('连接建立') ws.close()&#125;ws.onclose = function()&#123; console.log('连接关闭') ws.close()&#125; Django的Websocket dwebsocket是一个在django用来实现websocket服务端的三方模块，使用上手非常简单，安装方式如下 1pip install dwebsocket git地址 https://github.com/duanhongyi/dwebsocket 方法 在后台中，通过该三方模块可以让我们在django的视图中实现对于websocket的操作 首先是两个基本的装饰器，用来限定过滤websocket的连接 dwebsocket.accept_websocket 允许http与websocket连接 dwebsocket.require_websocke 只允许websocket连接 除去两种装饰器方法进行过滤判断，还可以通过在视图函数中的request进行websocket的判断 request.is_websocket 如果是个websocket请求返回True，如果是个普通的http请求返回False 可以用这个方法区分普通连接与websocket request.websocket 在一个websocket请求建立之后，这个请求将会有一个websocket属性，用来给客户端提供一个简单的api通讯，如果request.is_websocket()是False，这个属性将是None request.websocket.wait 接收客户端发来的一条消息；如果在收到消息或客户端关闭连接之前，它不会有任何返回，只会返回None request.websocket.read 如果从客户端接收到新消息，read函数返回这条消息；如果没有新消息，则返回None 这是一个替代wait的非阻塞读取数据的方法 request.websocket.count_messages() 返回消息队列数量 request.websocket.has_messages() 如果有新消息返回True，否则返回False request.websocket.send(message) 向客户端发送消息 requqest.websocket.__iter__ websocket迭代器 关于Django的Demo将会在下一章节结合paramiko以及xterm.js来进行一个webssh的实现","categories":[],"tags":[{"name":"Django","slug":"Django","permalink":"http://laxe.top/tags/Django/"}]}]}